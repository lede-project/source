From 0157efe2fbe2fe56c34727d326cd74284c06cbd5 Mon Sep 17 00:00:00 2001
From: Bhaskar Upadhaya <Bhaskar.Upadhaya@freescale.com>
Date: Wed, 24 Aug 2016 10:51:21 +0800
Subject: [PATCH 072/113] LS1012: Add PPFE driver in Linux

commit 7584b690d4c8e4e435c2e6abcdb38d6595a0c302
[context adjustment]
[don't apply fsl-ls1012a-rdb.dts and fsl-ls1012a.dtsi]
[Let PPFE driver can be selectd as a module]

Signed-off-by: Bhaskar Upadhaya <Bhaskar.Upadhaya@freescale.com>
Integrated-by: Zhao Qiang <qiang.zhao@nxp.com>
Integrated-by: Yutang Jiang <yutang.jiang@nxp.com>
---
 drivers/staging/Kconfig                            |    2 +
 drivers/staging/Makefile                           |    1 +
 drivers/staging/fsl_ppfe/Kconfig                   |    5 +
 drivers/staging/fsl_ppfe/Makefile                  |   44 +
 drivers/staging/fsl_ppfe/config.h                  |    8 +
 drivers/staging/fsl_ppfe/control_link.lds          |   32 +
 drivers/staging/fsl_ppfe/include/pfe/cbus.h        |   88 +
 drivers/staging/fsl_ppfe/include/pfe/cbus/bmu.h    |   55 +
 .../staging/fsl_ppfe/include/pfe/cbus/class_csr.h  |  242 ++
 drivers/staging/fsl_ppfe/include/pfe/cbus/emac.h   |  243 ++
 .../staging/fsl_ppfe/include/pfe/cbus/emac_mtip.h  |  250 ++
 drivers/staging/fsl_ppfe/include/pfe/cbus/gpi.h    |   78 +
 drivers/staging/fsl_ppfe/include/pfe/cbus/gpt.h    |   29 +
 drivers/staging/fsl_ppfe/include/pfe/cbus/hif.h    |   96 +
 .../staging/fsl_ppfe/include/pfe/cbus/hif_nocpy.h  |   51 +
 .../staging/fsl_ppfe/include/pfe/cbus/tmu_csr.h    |  128 +
 .../staging/fsl_ppfe/include/pfe/cbus/util_csr.h   |   61 +
 drivers/staging/fsl_ppfe/include/pfe/class.h       |  133 +
 drivers/staging/fsl_ppfe/include/pfe/class/ccu.h   |   28 +
 drivers/staging/fsl_ppfe/include/pfe/class/efet.h  |   44 +
 .../staging/fsl_ppfe/include/pfe/class/mac_hash.h  |   55 +
 drivers/staging/fsl_ppfe/include/pfe/class/perg.h  |   39 +
 .../staging/fsl_ppfe/include/pfe/class/vlan_hash.h |   46 +
 drivers/staging/fsl_ppfe/include/pfe/gpt.h         |   44 +
 drivers/staging/fsl_ppfe/include/pfe/pe.h          |  626 +++++
 drivers/staging/fsl_ppfe/include/pfe/pfe.h         |  444 +++
 drivers/staging/fsl_ppfe/include/pfe/tmu.h         |   68 +
 .../staging/fsl_ppfe/include/pfe/tmu/phy_queue.h   |   56 +
 drivers/staging/fsl_ppfe/include/pfe/tmu/sched.h   |   72 +
 drivers/staging/fsl_ppfe/include/pfe/tmu/shaper.h  |   37 +
 drivers/staging/fsl_ppfe/include/pfe/uart.h        |   31 +
 drivers/staging/fsl_ppfe/include/pfe/util.h        |   49 +
 drivers/staging/fsl_ppfe/include/pfe/util/eape.h   |   57 +
 drivers/staging/fsl_ppfe/include/pfe/util/efet.h   |  119 +
 drivers/staging/fsl_ppfe/include/pfe/util/inq.h    |   28 +
 drivers/staging/fsl_ppfe/pfe_ctrl.c                |  363 +++
 drivers/staging/fsl_ppfe/pfe_ctrl.h                |  111 +
 drivers/staging/fsl_ppfe/pfe_ctrl_hal.c            |  207 ++
 drivers/staging/fsl_ppfe/pfe_ctrl_hal.h            |  129 +
 drivers/staging/fsl_ppfe/pfe_debugfs.c             |  109 +
 drivers/staging/fsl_ppfe/pfe_debugfs.h             |    8 +
 drivers/staging/fsl_ppfe/pfe_eth.c                 | 2956 ++++++++++++++++++++
 drivers/staging/fsl_ppfe/pfe_eth.h                 |  384 +++
 drivers/staging/fsl_ppfe/pfe_firmware.c            |  322 +++
 drivers/staging/fsl_ppfe/pfe_firmware.h            |   41 +
 drivers/staging/fsl_ppfe/pfe_hal.c                 | 2217 +++++++++++++++
 drivers/staging/fsl_ppfe/pfe_hif.c                 |  939 +++++++
 drivers/staging/fsl_ppfe/pfe_hif.h                 |  322 +++
 drivers/staging/fsl_ppfe/pfe_hif_lib.c             |  658 +++++
 drivers/staging/fsl_ppfe/pfe_hif_lib.h             |  219 ++
 drivers/staging/fsl_ppfe/pfe_hw.c                  |  188 ++
 drivers/staging/fsl_ppfe/pfe_hw.h                  |   32 +
 drivers/staging/fsl_ppfe/pfe_ls1012a_platform.c    |  341 +++
 drivers/staging/fsl_ppfe/pfe_mod.c                 |  140 +
 drivers/staging/fsl_ppfe/pfe_mod.h                 |  163 ++
 drivers/staging/fsl_ppfe/pfe_perfmon.c             |  175 ++
 drivers/staging/fsl_ppfe/pfe_perfmon.h             |   41 +
 drivers/staging/fsl_ppfe/pfe_platform.c            |  358 +++
 drivers/staging/fsl_ppfe/pfe_sysfs.c               |  855 ++++++
 drivers/staging/fsl_ppfe/pfe_sysfs.h               |   34 +
 drivers/staging/fsl_ppfe/platform.h                |   25 +
 include/linux/skbuff.h                             |   11 +
 net/core/skbuff.c                                  |   84 +
 63 files changed, 14821 insertions(+)
 create mode 100644 drivers/staging/fsl_ppfe/Kconfig
 create mode 100644 drivers/staging/fsl_ppfe/Makefile
 create mode 100644 drivers/staging/fsl_ppfe/config.h
 create mode 100644 drivers/staging/fsl_ppfe/control_link.lds
 create mode 100644 drivers/staging/fsl_ppfe/include/pfe/cbus.h
 create mode 100644 drivers/staging/fsl_ppfe/include/pfe/cbus/bmu.h
 create mode 100644 drivers/staging/fsl_ppfe/include/pfe/cbus/class_csr.h
 create mode 100644 drivers/staging/fsl_ppfe/include/pfe/cbus/emac.h
 create mode 100644 drivers/staging/fsl_ppfe/include/pfe/cbus/emac_mtip.h
 create mode 100644 drivers/staging/fsl_ppfe/include/pfe/cbus/gpi.h
 create mode 100644 drivers/staging/fsl_ppfe/include/pfe/cbus/gpt.h
 create mode 100644 drivers/staging/fsl_ppfe/include/pfe/cbus/hif.h
 create mode 100644 drivers/staging/fsl_ppfe/include/pfe/cbus/hif_nocpy.h
 create mode 100644 drivers/staging/fsl_ppfe/include/pfe/cbus/tmu_csr.h
 create mode 100644 drivers/staging/fsl_ppfe/include/pfe/cbus/util_csr.h
 create mode 100644 drivers/staging/fsl_ppfe/include/pfe/class.h
 create mode 100644 drivers/staging/fsl_ppfe/include/pfe/class/ccu.h
 create mode 100644 drivers/staging/fsl_ppfe/include/pfe/class/efet.h
 create mode 100644 drivers/staging/fsl_ppfe/include/pfe/class/mac_hash.h
 create mode 100644 drivers/staging/fsl_ppfe/include/pfe/class/perg.h
 create mode 100644 drivers/staging/fsl_ppfe/include/pfe/class/vlan_hash.h
 create mode 100644 drivers/staging/fsl_ppfe/include/pfe/gpt.h
 create mode 100644 drivers/staging/fsl_ppfe/include/pfe/pe.h
 create mode 100644 drivers/staging/fsl_ppfe/include/pfe/pfe.h
 create mode 100644 drivers/staging/fsl_ppfe/include/pfe/tmu.h
 create mode 100644 drivers/staging/fsl_ppfe/include/pfe/tmu/phy_queue.h
 create mode 100644 drivers/staging/fsl_ppfe/include/pfe/tmu/sched.h
 create mode 100644 drivers/staging/fsl_ppfe/include/pfe/tmu/shaper.h
 create mode 100644 drivers/staging/fsl_ppfe/include/pfe/uart.h
 create mode 100644 drivers/staging/fsl_ppfe/include/pfe/util.h
 create mode 100644 drivers/staging/fsl_ppfe/include/pfe/util/eape.h
 create mode 100644 drivers/staging/fsl_ppfe/include/pfe/util/efet.h
 create mode 100644 drivers/staging/fsl_ppfe/include/pfe/util/inq.h
 create mode 100644 drivers/staging/fsl_ppfe/pfe_ctrl.c
 create mode 100644 drivers/staging/fsl_ppfe/pfe_ctrl.h
 create mode 100644 drivers/staging/fsl_ppfe/pfe_ctrl_hal.c
 create mode 100644 drivers/staging/fsl_ppfe/pfe_ctrl_hal.h
 create mode 100644 drivers/staging/fsl_ppfe/pfe_debugfs.c
 create mode 100644 drivers/staging/fsl_ppfe/pfe_debugfs.h
 create mode 100644 drivers/staging/fsl_ppfe/pfe_eth.c
 create mode 100644 drivers/staging/fsl_ppfe/pfe_eth.h
 create mode 100644 drivers/staging/fsl_ppfe/pfe_firmware.c
 create mode 100644 drivers/staging/fsl_ppfe/pfe_firmware.h
 create mode 100644 drivers/staging/fsl_ppfe/pfe_hal.c
 create mode 100644 drivers/staging/fsl_ppfe/pfe_hif.c
 create mode 100644 drivers/staging/fsl_ppfe/pfe_hif.h
 create mode 100644 drivers/staging/fsl_ppfe/pfe_hif_lib.c
 create mode 100644 drivers/staging/fsl_ppfe/pfe_hif_lib.h
 create mode 100644 drivers/staging/fsl_ppfe/pfe_hw.c
 create mode 100644 drivers/staging/fsl_ppfe/pfe_hw.h
 create mode 100644 drivers/staging/fsl_ppfe/pfe_ls1012a_platform.c
 create mode 100644 drivers/staging/fsl_ppfe/pfe_mod.c
 create mode 100644 drivers/staging/fsl_ppfe/pfe_mod.h
 create mode 100644 drivers/staging/fsl_ppfe/pfe_perfmon.c
 create mode 100644 drivers/staging/fsl_ppfe/pfe_perfmon.h
 create mode 100644 drivers/staging/fsl_ppfe/pfe_platform.c
 create mode 100644 drivers/staging/fsl_ppfe/pfe_sysfs.c
 create mode 100644 drivers/staging/fsl_ppfe/pfe_sysfs.h
 create mode 100644 drivers/staging/fsl_ppfe/platform.h

--- a/drivers/staging/Kconfig
+++ b/drivers/staging/Kconfig
@@ -112,4 +112,6 @@ source "drivers/staging/wilc1000/Kconfig
 
 source "drivers/staging/most/Kconfig"
 
+source "drivers/staging/fsl_ppfe/Kconfig"
+
 endif # STAGING
--- a/drivers/staging/Makefile
+++ b/drivers/staging/Makefile
@@ -48,3 +48,4 @@ obj-$(CONFIG_FSL_MC_BUS)	+= fsl-mc/
 obj-$(CONFIG_FSL_DPA)           += fsl_qbman/
 obj-$(CONFIG_WILC1000)		+= wilc1000/
 obj-$(CONFIG_MOST)		+= most/
+obj-$(CONFIG_FSL_PPFE)		+= fsl_ppfe/
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/Kconfig
@@ -0,0 +1,5 @@
+config FSL_PPFE
+	tristate "Freescale PPFE Driver"
+	default m
+	help
+	  only compiled as module !
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/Makefile
@@ -0,0 +1,44 @@
+#
+#  Copyright (C) 2007 Freescale Semiconductor, Inc.
+#
+# This program is free software; you can redistribute it and/or modify
+# it under the terms of the GNU General Public License as published by
+# the Free Software Foundation; either version 2 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU General Public License for more details.
+#
+# You should have received a copy of the GNU General Public License
+# along with this program; if not, write to the Free Software
+# Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ 
+
+all: modules
+
+modules clean:
+	make CROSS_COMPILE=$(CROSS_COMPILE)  ARCH=$(ARCH) -C $(KERNELDIR) M=`pwd` $@
+
+EXTRA_CFLAGS +=  -I$(src)/include  -I$(src) -DCOMCERTO_2000 -DCONFIG_PLATFORM_LS1012A -DGEMAC_MTIP -DCONFIG_UTIL_DISABLED
+
+EXTRA_LDFLAGS += -T$(srctree)/$(src)/control_link.lds
+
+#only compiled as module !
+obj-$(CONFIG_FSL_PPFE) += pfe.o
+
+pfe-y += pfe_mod.o \
+	pfe_hw.o \
+	pfe_firmware.o \
+	pfe_ctrl.o \
+	pfe_ctrl_hal.o \
+	pfe_hif.o \
+	pfe_hif_lib.o\
+	pfe_eth.o \
+	pfe_perfmon.o \
+	pfe_sysfs.o \
+	pfe_debugfs.o \
+	pfe_ls1012a_platform.o \
+	pfe_hal.o  \
+
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/config.h
@@ -0,0 +1,8 @@
+#ifndef _CONFIG_H_
+#define _CONFIG_H_
+#define CFG_WIFI_OFFLOAD		(1 << 1)
+#define CFG_ICC		(1 << 11)
+#define CFG_RTP		(1 << 14)
+#define CFG_ELLIPTIC		(1 << 15)
+#define CFG_ALL			(0 |  CFG_WIFI_OFFLOAD |  CFG_ICC |  CFG_RTP |  CFG_ELLIPTIC )
+#endif /* _CONFIG_H_ */
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/control_link.lds
@@ -0,0 +1,32 @@
+/*
+ *
+ *  Copyright (C) 2007 Freescale Semiconductor, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+
+SECTIONS
+{
+	.class_dmem_sh : SUBALIGN(8) {
+		__class_dmem_sh = .;
+		*(SORT(.class_dmem_sh_*))
+	}
+
+	.tmu_dmem_sh : SUBALIGN(8) {
+		__tmu_dmem_sh = .;
+		*(SORT(.tmu_dmem_sh_*))
+	}
+
+}
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/include/pfe/cbus.h
@@ -0,0 +1,88 @@
+/*
+ *  Copyright (c) 2011, 2014 Freescale Semiconductor, Inc.
+ *
+ *  This program is free software; you can redistribute it and/or
+ *  modify it under the terms of the GNU General Public License
+ *  as published by the Free Software Foundation; either version 2
+ *  of the License, or (at your option) any later version.
+ *
+ *  This program is distributed in the hope that it will be useful,
+ *  but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *  GNU General Public License for more details.
+ *
+ *  You should have received a copy of the GNU General Public License
+ *  along with this program; if not, write to the Free Software
+ *  Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
+ *
+*/
+#ifndef _CBUS_H_
+#define _CBUS_H_
+
+#define EMAC1_BASE_ADDR		(CBUS_BASE_ADDR + 0x200000)
+#define EGPI1_BASE_ADDR		(CBUS_BASE_ADDR + 0x210000)
+#define EMAC2_BASE_ADDR		(CBUS_BASE_ADDR + 0x220000)
+#define EGPI2_BASE_ADDR		(CBUS_BASE_ADDR + 0x230000)
+#define BMU1_BASE_ADDR		(CBUS_BASE_ADDR + 0x240000)
+#define BMU2_BASE_ADDR		(CBUS_BASE_ADDR + 0x250000)
+#define ARB_BASE_ADDR		(CBUS_BASE_ADDR + 0x260000) /* FIXME not documented */
+#define DDR_CONFIG_BASE_ADDR	(CBUS_BASE_ADDR + 0x270000) /* FIXME not documented */
+#define HIF_BASE_ADDR		(CBUS_BASE_ADDR + 0x280000)
+#define HGPI_BASE_ADDR		(CBUS_BASE_ADDR + 0x290000)
+#define LMEM_BASE_ADDR		(CBUS_BASE_ADDR + 0x300000)
+#define LMEM_SIZE		0x10000
+#define LMEM_END		(LMEM_BASE_ADDR + LMEM_SIZE)
+#define TMU_CSR_BASE_ADDR	(CBUS_BASE_ADDR + 0x310000)
+#define CLASS_CSR_BASE_ADDR	(CBUS_BASE_ADDR + 0x320000)
+#if defined(CONFIG_PLATFORM_C2000)
+#define EMAC3_BASE_ADDR		(CBUS_BASE_ADDR + 0x330000)
+#define EGPI3_BASE_ADDR		(CBUS_BASE_ADDR + 0x340000)
+#endif
+#define HIF_NOCPY_BASE_ADDR	(CBUS_BASE_ADDR + 0x350000)
+#define UTIL_CSR_BASE_ADDR	(CBUS_BASE_ADDR + 0x360000)
+#define CBUS_GPT_BASE_ADDR	(CBUS_BASE_ADDR + 0x370000)
+
+#define IS_LMEM(addr, len)	(((unsigned long)(addr) >= (unsigned long)LMEM_BASE_ADDR) && (((unsigned long)(addr) + (len)) <= (unsigned long)LMEM_END))
+
+/** 
+* \defgroup XXX_MEM_ACCESS_ADDR PE memory access through CSR 
+* XXX_MEM_ACCESS_ADDR register bit definitions. 
+* @{
+*/
+#define PE_MEM_ACCESS_WRITE		(1<<31)			/**< Internal Memory Write. */
+#define PE_MEM_ACCESS_IMEM		(1<<15)
+#define PE_MEM_ACCESS_DMEM		(1<<16)
+#define PE_MEM_ACCESS_BYTE_ENABLE(offset,size)	(((((1 << (size)) - 1) << (4 - (offset) - (size))) & 0xf) << 24)	/**< Byte Enables of the Internal memory access. These are interpred in BE */
+// @}
+#if defined(CONFIG_PLATFORM_LS1012A)
+#include "cbus/emac_mtip.h"
+#else
+#include "cbus/emac.h"
+#endif //CONFIG_PLATFORM_LS1012A
+#include "cbus/gpi.h"
+#include "cbus/bmu.h"
+#include "cbus/hif.h"
+#include "cbus/tmu_csr.h"
+#include "cbus/class_csr.h"
+#include "cbus/hif_nocpy.h"
+#include "cbus/util_csr.h"
+#include "cbus/gpt.h"
+
+
+/* PFE cores states */
+#define CORE_DISABLE	0x00000000 
+#define CORE_ENABLE	0x00000001
+#define CORE_SW_RESET	0x00000002
+
+/* LMEM defines */
+#define LMEM_HDR_SIZE		0x0010
+#define LMEM_BUF_SIZE_LN2	0x7
+#define LMEM_BUF_SIZE		(1 << LMEM_BUF_SIZE_LN2)
+
+/* DDR defines */
+#define DDR_HDR_SIZE		0x0100
+#define DDR_BUF_SIZE_LN2	0xb
+#define DDR_BUF_SIZE		(1 << DDR_BUF_SIZE_LN2)
+
+
+#endif /* _CBUS_H_ */
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/include/pfe/cbus/bmu.h
@@ -0,0 +1,55 @@
+/*
+ *  Copyright (c) 2011, 2014 Freescale Semiconductor, Inc.
+ *
+ *  This program is free software; you can redistribute it and/or
+ *  modify it under the terms of the GNU General Public License
+ *  as published by the Free Software Foundation; either version 2
+ *  of the License, or (at your option) any later version.
+ *
+ *  This program is distributed in the hope that it will be useful,
+ *  but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *  GNU General Public License for more details.
+ *
+ *  You should have received a copy of the GNU General Public License
+ *  along with this program; if not, write to the Free Software
+ *  Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
+ *
+*/
+#ifndef _BMU_H_
+#define _BMU_H_
+
+#define BMU_VERSION		0x000
+#define BMU_CTRL		0x004
+#define BMU_UCAST_CONFIG	0x008
+#define BMU_UCAST_BASE_ADDR	0x00c
+#define BMU_BUF_SIZE		0x010
+#define BMU_BUF_CNT		0x014
+#define BMU_THRES		0x018
+#define BMU_INT_SRC		0x020
+#define BMU_INT_ENABLE		0x024
+#define BMU_ALLOC_CTRL		0x030
+#define BMU_FREE_CTRL		0x034
+#define BMU_FREE_ERR_ADDR	0x038
+#define BMU_CURR_BUF_CNT	0x03c
+#define BMU_MCAST_CNT		0x040
+#define BMU_MCAST_ALLOC_CTRL	0x044
+#define BMU_REM_BUF_CNT		0x048
+#define BMU_LOW_WATERMARK	0x050
+#define BMU_HIGH_WATERMARK	0x054
+#define BMU_INT_MEM_ACCESS	0x100
+
+typedef struct {
+	unsigned long baseaddr;
+	u32 count;
+	u32 size;
+} BMU_CFG;
+
+
+#define BMU1_BUF_SIZE	LMEM_BUF_SIZE_LN2
+#define BMU2_BUF_SIZE	DDR_BUF_SIZE_LN2
+
+#define BMU2_MCAST_ALLOC_CTRL	BMU2_BASE_ADDR + BMU_MCAST_ALLOC_CTRL
+
+#endif /* _BMU_H_ */
+
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/include/pfe/cbus/class_csr.h
@@ -0,0 +1,242 @@
+/*
+ *  Copyright (c) 2011, 2014 Freescale Semiconductor, Inc.
+ *
+ *  This program is free software; you can redistribute it and/or
+ *  modify it under the terms of the GNU General Public License
+ *  as published by the Free Software Foundation; either version 2
+ *  of the License, or (at your option) any later version.
+ *
+ *  This program is distributed in the hope that it will be useful,
+ *  but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *  GNU General Public License for more details.
+ *
+ *  You should have received a copy of the GNU General Public License
+ *  along with this program; if not, write to the Free Software
+ *  Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
+ *
+*/
+#ifndef _CLASS_CSR_H_
+#define _CLASS_CSR_H_
+
+/** @file class_csr.h.
+ * class_csr - block containing all the classifier control and status register. Mapped on CBUS and accessible from all PE's and ARM.
+ */
+
+
+#define CLASS_VERSION			(CLASS_CSR_BASE_ADDR + 0x000)
+#define CLASS_TX_CTRL			(CLASS_CSR_BASE_ADDR + 0x004)
+#define CLASS_INQ_PKTPTR		(CLASS_CSR_BASE_ADDR + 0x010)
+#define CLASS_HDR_SIZE			(CLASS_CSR_BASE_ADDR + 0x014)	/**< (ddr_hdr_size[24:16], lmem_hdr_size[5:0]) */
+#define CLASS_HDR_SIZE_LMEM(off)	((off) & 0x3f)			/**< LMEM header size for the Classifier block.\ Data in the LMEM is written from this offset. */
+#define CLASS_HDR_SIZE_DDR(off)		(((off) & 0x1ff) << 16)		/**< DDR header size for the Classifier block.\ Data in the DDR is written from this offset. */
+
+#define CLASS_PE0_QB_DM_ADDR0		(CLASS_CSR_BASE_ADDR + 0x020)	/**< DMEM address of first [15:0] and second [31:16] buffers on QB side. */
+#define CLASS_PE0_QB_DM_ADDR1		(CLASS_CSR_BASE_ADDR + 0x024)	/**< DMEM address of third [15:0] and fourth [31:16] buffers on QB side. */
+
+#define CLASS_PE0_RO_DM_ADDR0		(CLASS_CSR_BASE_ADDR + 0x060)	/**< DMEM address of first [15:0] and second [31:16] buffers on RO side. */
+#define CLASS_PE0_RO_DM_ADDR1		(CLASS_CSR_BASE_ADDR + 0x064)	/**< DMEM address of third [15:0] and fourth [31:16] buffers on RO side. */
+
+/** @name Class PE memory access. Allows external PE's and HOST to read/write PMEM/DMEM memory ranges for each classifier PE.
+ */
+//@{
+#define CLASS_MEM_ACCESS_ADDR		(CLASS_CSR_BASE_ADDR + 0x100)	/**< {sr_pe_mem_cmd[31], csr_pe_mem_wren[27:24], csr_pe_mem_addr[23:0]}, See \ref XXX_MEM_ACCESS_ADDR for details. */ 
+#define CLASS_MEM_ACCESS_WDATA		(CLASS_CSR_BASE_ADDR + 0x104)	/**< Internal Memory Access Write Data [31:0] */
+#define CLASS_MEM_ACCESS_RDATA		(CLASS_CSR_BASE_ADDR + 0x108)	/**< Internal Memory Access Read Data [31:0] */
+//@}
+#define CLASS_TM_INQ_ADDR		(CLASS_CSR_BASE_ADDR + 0x114)
+#define CLASS_PE_STATUS			(CLASS_CSR_BASE_ADDR + 0x118)
+
+#define CLASS_PHY1_RX_PKTS		(CLASS_CSR_BASE_ADDR + 0x11c)
+#define CLASS_PHY1_TX_PKTS		(CLASS_CSR_BASE_ADDR + 0x120)
+#define CLASS_PHY1_LP_FAIL_PKTS		(CLASS_CSR_BASE_ADDR + 0x124)
+#define CLASS_PHY1_INTF_FAIL_PKTS	(CLASS_CSR_BASE_ADDR + 0x128)
+#define CLASS_PHY1_INTF_MATCH_PKTS	(CLASS_CSR_BASE_ADDR + 0x12c)
+#define CLASS_PHY1_L3_FAIL_PKTS		(CLASS_CSR_BASE_ADDR + 0x130)
+#define CLASS_PHY1_V4_PKTS		(CLASS_CSR_BASE_ADDR + 0x134)
+#define CLASS_PHY1_V6_PKTS		(CLASS_CSR_BASE_ADDR + 0x138)
+#define CLASS_PHY1_CHKSUM_ERR_PKTS	(CLASS_CSR_BASE_ADDR + 0x13c)
+#define CLASS_PHY1_TTL_ERR_PKTS		(CLASS_CSR_BASE_ADDR + 0x140)
+#define CLASS_PHY2_RX_PKTS		(CLASS_CSR_BASE_ADDR + 0x144)
+#define CLASS_PHY2_TX_PKTS		(CLASS_CSR_BASE_ADDR + 0x148)
+#define CLASS_PHY2_LP_FAIL_PKTS		(CLASS_CSR_BASE_ADDR + 0x14c)
+#define CLASS_PHY2_INTF_FAIL_PKTS	(CLASS_CSR_BASE_ADDR + 0x150)
+#define CLASS_PHY2_INTF_MATCH_PKTS	(CLASS_CSR_BASE_ADDR + 0x154)
+#define CLASS_PHY2_L3_FAIL_PKTS		(CLASS_CSR_BASE_ADDR + 0x158)
+#define CLASS_PHY2_V4_PKTS		(CLASS_CSR_BASE_ADDR + 0x15c)
+#define CLASS_PHY2_V6_PKTS		(CLASS_CSR_BASE_ADDR + 0x160)
+#define CLASS_PHY2_CHKSUM_ERR_PKTS	(CLASS_CSR_BASE_ADDR + 0x164)
+#define CLASS_PHY2_TTL_ERR_PKTS		(CLASS_CSR_BASE_ADDR + 0x168)
+#define CLASS_PHY3_RX_PKTS		(CLASS_CSR_BASE_ADDR + 0x16c)
+#define CLASS_PHY3_TX_PKTS		(CLASS_CSR_BASE_ADDR + 0x170)
+#define CLASS_PHY3_LP_FAIL_PKTS		(CLASS_CSR_BASE_ADDR + 0x174)
+#define CLASS_PHY3_INTF_FAIL_PKTS	(CLASS_CSR_BASE_ADDR + 0x178)
+#define CLASS_PHY3_INTF_MATCH_PKTS	(CLASS_CSR_BASE_ADDR + 0x17c)
+#define CLASS_PHY3_L3_FAIL_PKTS		(CLASS_CSR_BASE_ADDR + 0x180)
+#define CLASS_PHY3_V4_PKTS		(CLASS_CSR_BASE_ADDR + 0x184)
+#define CLASS_PHY3_V6_PKTS		(CLASS_CSR_BASE_ADDR + 0x188)
+#define CLASS_PHY3_CHKSUM_ERR_PKTS	(CLASS_CSR_BASE_ADDR + 0x18c)
+#define CLASS_PHY3_TTL_ERR_PKTS		(CLASS_CSR_BASE_ADDR + 0x190)
+#define CLASS_PHY1_ICMP_PKTS		(CLASS_CSR_BASE_ADDR + 0x194)
+#define CLASS_PHY1_IGMP_PKTS		(CLASS_CSR_BASE_ADDR + 0x198)
+#define CLASS_PHY1_TCP_PKTS		(CLASS_CSR_BASE_ADDR + 0x19c)
+#define CLASS_PHY1_UDP_PKTS		(CLASS_CSR_BASE_ADDR + 0x1a0)
+#define CLASS_PHY2_ICMP_PKTS		(CLASS_CSR_BASE_ADDR + 0x1a4)
+#define CLASS_PHY2_IGMP_PKTS		(CLASS_CSR_BASE_ADDR + 0x1a8)
+#define CLASS_PHY2_TCP_PKTS		(CLASS_CSR_BASE_ADDR + 0x1ac)
+#define CLASS_PHY2_UDP_PKTS		(CLASS_CSR_BASE_ADDR + 0x1b0)
+#define CLASS_PHY3_ICMP_PKTS		(CLASS_CSR_BASE_ADDR + 0x1b4)
+#define CLASS_PHY3_IGMP_PKTS		(CLASS_CSR_BASE_ADDR + 0x1b8)
+#define CLASS_PHY3_TCP_PKTS		(CLASS_CSR_BASE_ADDR + 0x1bc)
+#define CLASS_PHY3_UDP_PKTS		(CLASS_CSR_BASE_ADDR + 0x1c0)
+#define CLASS_PHY4_ICMP_PKTS		(CLASS_CSR_BASE_ADDR + 0x1c4)
+#define CLASS_PHY4_IGMP_PKTS		(CLASS_CSR_BASE_ADDR + 0x1c8)
+#define CLASS_PHY4_TCP_PKTS		(CLASS_CSR_BASE_ADDR + 0x1cc)
+#define CLASS_PHY4_UDP_PKTS		(CLASS_CSR_BASE_ADDR + 0x1d0)
+#define CLASS_PHY4_RX_PKTS		(CLASS_CSR_BASE_ADDR + 0x1d4)
+#define CLASS_PHY4_TX_PKTS		(CLASS_CSR_BASE_ADDR + 0x1d8)
+#define CLASS_PHY4_LP_FAIL_PKTS		(CLASS_CSR_BASE_ADDR + 0x1dc)
+#define CLASS_PHY4_INTF_FAIL_PKTS	(CLASS_CSR_BASE_ADDR + 0x1e0)
+#define CLASS_PHY4_INTF_MATCH_PKTS	(CLASS_CSR_BASE_ADDR + 0x1e4)
+#define CLASS_PHY4_L3_FAIL_PKTS		(CLASS_CSR_BASE_ADDR + 0x1e8)
+#define CLASS_PHY4_V4_PKTS		(CLASS_CSR_BASE_ADDR + 0x1ec)
+#define CLASS_PHY4_V6_PKTS		(CLASS_CSR_BASE_ADDR + 0x1f0)
+#define CLASS_PHY4_CHKSUM_ERR_PKTS	(CLASS_CSR_BASE_ADDR + 0x1f4)
+#define CLASS_PHY4_TTL_ERR_PKTS		(CLASS_CSR_BASE_ADDR + 0x1f8)
+
+#define CLASS_PE_SYS_CLK_RATIO		(CLASS_CSR_BASE_ADDR + 0x200)
+#define CLASS_AFULL_THRES		(CLASS_CSR_BASE_ADDR + 0x204)
+#define CLASS_GAP_BETWEEN_READS		(CLASS_CSR_BASE_ADDR + 0x208)
+#define CLASS_MAX_BUF_CNT		(CLASS_CSR_BASE_ADDR + 0x20c)
+#define CLASS_TSQ_FIFO_THRES		(CLASS_CSR_BASE_ADDR + 0x210)
+#define CLASS_TSQ_MAX_CNT		(CLASS_CSR_BASE_ADDR + 0x214)
+#define CLASS_IRAM_DATA_0		(CLASS_CSR_BASE_ADDR + 0x218)
+#define CLASS_IRAM_DATA_1		(CLASS_CSR_BASE_ADDR + 0x21c)
+#define CLASS_IRAM_DATA_2		(CLASS_CSR_BASE_ADDR + 0x220)
+#define CLASS_IRAM_DATA_3		(CLASS_CSR_BASE_ADDR + 0x224)
+
+#define CLASS_BUS_ACCESS_ADDR		(CLASS_CSR_BASE_ADDR + 0x228)
+
+#define CLASS_BUS_ACCESS_WDATA		(CLASS_CSR_BASE_ADDR + 0x22c)
+#define CLASS_BUS_ACCESS_RDATA		(CLASS_CSR_BASE_ADDR + 0x230)
+
+#define CLASS_ROUTE_HASH_ENTRY_SIZE	(CLASS_CSR_BASE_ADDR + 0x234)		/**< (route_entry_size[9:0], route_hash_size[23:16] (this is actually ln2(size))) */
+#define CLASS_ROUTE_ENTRY_SIZE(size)	 ((size) & 0x1ff)
+#define CLASS_ROUTE_HASH_SIZE(hash_bits) (((hash_bits) & 0xff) << 16)
+
+#define CLASS_ROUTE_TABLE_BASE		(CLASS_CSR_BASE_ADDR + 0x238)
+
+#define CLASS_ROUTE_MULTI		(CLASS_CSR_BASE_ADDR + 0x23c)
+#define CLASS_SMEM_OFFSET		(CLASS_CSR_BASE_ADDR + 0x240)
+#define CLASS_LMEM_BUF_SIZE		(CLASS_CSR_BASE_ADDR + 0x244)
+#define CLASS_VLAN_ID			(CLASS_CSR_BASE_ADDR + 0x248)
+#define CLASS_BMU1_BUF_FREE		(CLASS_CSR_BASE_ADDR + 0x24c)
+#define CLASS_USE_TMU_INQ		(CLASS_CSR_BASE_ADDR + 0x250)
+#define CLASS_VLAN_ID1			(CLASS_CSR_BASE_ADDR + 0x254)
+
+#define CLASS_BUS_ACCESS_BASE		(CLASS_CSR_BASE_ADDR + 0x258)
+#define CLASS_BUS_ACCESS_BASE_MASK	(0xFF000000)	//bit 31:24 of PE peripheral address are stored in CLASS_BUS_ACCESS_BASE
+
+#define CLASS_HIF_PARSE			(CLASS_CSR_BASE_ADDR + 0x25c)
+
+#define CLASS_HOST_PE0_GP		(CLASS_CSR_BASE_ADDR + 0x260)
+#define CLASS_PE0_GP			(CLASS_CSR_BASE_ADDR + 0x264)
+#define CLASS_HOST_PE1_GP		(CLASS_CSR_BASE_ADDR + 0x268)
+#define CLASS_PE1_GP			(CLASS_CSR_BASE_ADDR + 0x26c)
+#define CLASS_HOST_PE2_GP		(CLASS_CSR_BASE_ADDR + 0x270)
+#define CLASS_PE2_GP			(CLASS_CSR_BASE_ADDR + 0x274)
+#define CLASS_HOST_PE3_GP		(CLASS_CSR_BASE_ADDR + 0x278)
+#define CLASS_PE3_GP			(CLASS_CSR_BASE_ADDR + 0x27c)
+#define CLASS_HOST_PE4_GP		(CLASS_CSR_BASE_ADDR + 0x280)
+#define CLASS_PE4_GP			(CLASS_CSR_BASE_ADDR + 0x284)
+#define CLASS_HOST_PE5_GP		(CLASS_CSR_BASE_ADDR + 0x288)
+#define CLASS_PE5_GP			(CLASS_CSR_BASE_ADDR + 0x28c)
+
+#define CLASS_PE_INT_SRC		(CLASS_CSR_BASE_ADDR + 0x290)
+#define CLASS_PE_INT_ENABLE		(CLASS_CSR_BASE_ADDR + 0x294)
+
+#define CLASS_TPID0_TPID1		(CLASS_CSR_BASE_ADDR + 0x298)
+#define CLASS_TPID2			(CLASS_CSR_BASE_ADDR + 0x29c)
+
+#define CLASS_L4_CHKSUM_ADDR		(CLASS_CSR_BASE_ADDR + 0x2a0)
+
+#define CLASS_PE0_DEBUG			(CLASS_CSR_BASE_ADDR + 0x2a4)
+#define CLASS_PE1_DEBUG			(CLASS_CSR_BASE_ADDR + 0x2a8)
+#define CLASS_PE2_DEBUG			(CLASS_CSR_BASE_ADDR + 0x2ac)
+#define CLASS_PE3_DEBUG			(CLASS_CSR_BASE_ADDR + 0x2b0)
+#define CLASS_PE4_DEBUG			(CLASS_CSR_BASE_ADDR + 0x2b4)
+#define CLASS_PE5_DEBUG			(CLASS_CSR_BASE_ADDR + 0x2b8)
+
+#define CLASS_STATE			(CLASS_CSR_BASE_ADDR + 0x2bc)
+
+/* CLASS defines */
+#define CLASS_PBUF_SIZE			0x100	/* Fixed by hardware */
+#define CLASS_PBUF_HEADER_OFFSET	0x80	/* Can be configured */
+
+#define CLASS_PBUF0_BASE_ADDR		0x000						/* Can be configured */
+#define CLASS_PBUF1_BASE_ADDR		(CLASS_PBUF0_BASE_ADDR + CLASS_PBUF_SIZE)	/* Can be configured */
+#define CLASS_PBUF2_BASE_ADDR		(CLASS_PBUF1_BASE_ADDR + CLASS_PBUF_SIZE)	/* Can be configured */
+#define CLASS_PBUF3_BASE_ADDR		(CLASS_PBUF2_BASE_ADDR + CLASS_PBUF_SIZE)	/* Can be configured */
+
+#define CLASS_PBUF0_HEADER_BASE_ADDR	(CLASS_PBUF0_BASE_ADDR + CLASS_PBUF_HEADER_OFFSET)
+#define CLASS_PBUF1_HEADER_BASE_ADDR	(CLASS_PBUF1_BASE_ADDR + CLASS_PBUF_HEADER_OFFSET)
+#define CLASS_PBUF2_HEADER_BASE_ADDR	(CLASS_PBUF2_BASE_ADDR + CLASS_PBUF_HEADER_OFFSET)
+#define CLASS_PBUF3_HEADER_BASE_ADDR	(CLASS_PBUF3_BASE_ADDR + CLASS_PBUF_HEADER_OFFSET)
+
+#define CLASS_PE0_RO_DM_ADDR0_VAL	((CLASS_PBUF1_BASE_ADDR << 16) | CLASS_PBUF0_BASE_ADDR)
+#define CLASS_PE0_RO_DM_ADDR1_VAL	((CLASS_PBUF3_BASE_ADDR << 16) | CLASS_PBUF2_BASE_ADDR)
+
+#define CLASS_PE0_QB_DM_ADDR0_VAL	((CLASS_PBUF1_HEADER_BASE_ADDR << 16) | CLASS_PBUF0_HEADER_BASE_ADDR)
+#define CLASS_PE0_QB_DM_ADDR1_VAL	((CLASS_PBUF3_HEADER_BASE_ADDR << 16) | CLASS_PBUF2_HEADER_BASE_ADDR)
+
+#define CLASS_ROUTE_SIZE		128
+#define CLASS_MAX_ROUTE_SIZE		256
+#define CLASS_ROUTE_HASH_BITS		20
+#define CLASS_ROUTE_HASH_MASK		((1 << CLASS_ROUTE_HASH_BITS) - 1)
+
+#define	CLASS_ROUTE0_BASE_ADDR	0x400						/* Can be configured */
+#define CLASS_ROUTE1_BASE_ADDR	(CLASS_ROUTE0_BASE_ADDR + CLASS_ROUTE_SIZE)	/* Can be configured */
+#define CLASS_ROUTE2_BASE_ADDR	(CLASS_ROUTE1_BASE_ADDR + CLASS_ROUTE_SIZE)	/* Can be configured */
+#define CLASS_ROUTE3_BASE_ADDR	(CLASS_ROUTE2_BASE_ADDR + CLASS_ROUTE_SIZE)	/* Can be configured */
+
+#define CLASS_SA_SIZE		128
+#define CLASS_IPSEC_SA0_BASE_ADDR	0x600
+#define CLASS_IPSEC_SA1_BASE_ADDR	(CLASS_IPSEC_SA0_BASE_ADDR + CLASS_SA_SIZE)	/* not used */
+#define CLASS_IPSEC_SA2_BASE_ADDR	(CLASS_IPSEC_SA1_BASE_ADDR + CLASS_SA_SIZE)	/* not used */
+#define CLASS_IPSEC_SA3_BASE_ADDR	(CLASS_IPSEC_SA2_BASE_ADDR + CLASS_SA_SIZE)	/* not used */
+
+/* generic purpose free dmem buffer, last portion of 2K dmem pbuf */
+#define CLASS_GP_DMEM_BUF_SIZE	(2048 - (CLASS_PBUF_SIZE*4) - (CLASS_ROUTE_SIZE*4) - (CLASS_SA_SIZE))
+#define CLASS_GP_DMEM_BUF		((void *)(CLASS_IPSEC_SA0_BASE_ADDR + CLASS_SA_SIZE))
+
+
+#define TWO_LEVEL_ROUTE		(1 << 0)
+#define PHYNO_IN_HASH		(1 << 1)
+#define HW_ROUTE_FETCH		(1 << 3)
+#define HW_BRIDGE_FETCH		(1 << 5)
+#define IP_ALIGNED		(1 << 6)
+#define ARC_HIT_CHECK_EN	(1 << 7)
+#define CLASS_TOE		(1 << 11)
+#define HASH_NORMAL		(0 << 12)
+#define HASH_CRC_PORT		(1 << 12)
+#define HASH_CRC_IP		(2 << 12)
+#define HASH_CRC_PORT_IP	(3 << 12)
+#define QB2BUS_LE		(1 << 15)
+
+#define TCP_CHKSUM_DROP		(1 << 0)
+#define UDP_CHKSUM_DROP		(1 << 1)
+#define IPV4_CHKSUM_DROP	(1 << 9)
+
+/*CLASS_HIF_PARSE bits*/
+#define HIF_PKT_CLASS_EN	(1 << 0)
+#define HIF_PKT_OFFSET(ofst)	((ofst&0xF) << 1)
+
+typedef struct {
+	u32 toe_mode;
+	unsigned long route_table_baseaddr;
+	u32 route_table_hash_bits;
+	u32 pe_sys_clk_ratio;
+	u32 resume;
+} CLASS_CFG;
+
+#endif /* _CLASS_CSR_H_ */
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/include/pfe/cbus/emac.h
@@ -0,0 +1,243 @@
+/*
+ *  Copyright (c) 2011, 2014 Freescale Semiconductor, Inc.
+ *
+ *  This program is free software; you can redistribute it and/or
+ *  modify it under the terms of the GNU General Public License
+ *  as published by the Free Software Foundation; either version 2
+ *  of the License, or (at your option) any later version.
+ *
+ *  This program is distributed in the hope that it will be useful,
+ *  but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *  GNU General Public License for more details.
+ *
+ *  You should have received a copy of the GNU General Public License
+ *  along with this program; if not, write to the Free Software
+ *  Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
+ *
+*/
+#ifndef _EMAC_H_
+#define _EMAC_H_
+
+#define EMAC_NETWORK_CONTROL		0x000
+#define EMAC_NETWORK_CONFIG		0x004
+#define EMAC_NETWORK_STATUS		0x008
+#define EMAC_DMA_CONFIG			0x010
+
+#define EMAC_PHY_MANAGEMENT		0x034
+
+#define EMAC_HASH_BOT			0x080
+#define EMAC_HASH_TOP			0x084
+
+#define EMAC_SPEC1_ADD_BOT		0x088
+#define EMAC_SPEC1_ADD_TOP		0x08c
+#define EMAC_SPEC2_ADD_BOT		0x090
+#define EMAC_SPEC2_ADD_TOP		0x094
+#define EMAC_SPEC3_ADD_BOT		0x098
+#define EMAC_SPEC3_ADD_TOP		0x09c
+#define EMAC_SPEC4_ADD_BOT		0x0a0
+#define EMAC_SPEC4_ADD_TOP		0x0a4
+#define EMAC_WOL				0x0b8
+
+#define	EMAC_STACKED_VLAN_REG		0x0c0
+
+#define EMAC_SPEC1_ADD_MASK_BOT		0x0c8
+#define EMAC_SPEC1_ADD_MASK_TOP		0x0cc
+
+#define EMAC_RMON_BASE_OFST		0x100
+
+#define EMAC_SPEC5_ADD_BOT		0x300
+#define EMAC_SPEC5_ADD_TOP		0x304
+#define EMAC_SPEC6_ADD_BOT		0x308
+#define EMAC_SPEC6_ADD_TOP		0x30c
+#define EMAC_SPEC7_ADD_BOT		0x310
+#define EMAC_SPEC7_ADD_TOP		0x314
+#define EMAC_SPEC8_ADD_BOT		0x318
+#define EMAC_SPEC8_ADD_TOP		0x31c
+#define EMAC_SPEC9_ADD_BOT		0x320
+#define EMAC_SPEC9_ADD_TOP		0x324
+#define EMAC_SPEC10_ADD_BOT		0x328
+#define EMAC_SPEC10_ADD_TOP		0x32c
+#define EMAC_SPEC11_ADD_BOT		0x330
+#define EMAC_SPEC11_ADD_TOP		0x334
+#define EMAC_SPEC12_ADD_BOT		0x338
+#define EMAC_SPEC12_ADD_TOP		0x33c
+#define EMAC_SPEC13_ADD_BOT		0x340
+#define EMAC_SPEC13_ADD_TOP		0x344
+#define EMAC_SPEC14_ADD_BOT		0x348
+#define EMAC_SPEC14_ADD_TOP		0x34c
+#define EMAC_SPEC15_ADD_BOT		0x350
+#define EMAC_SPEC15_ADD_TOP		0x354
+#define EMAC_SPEC16_ADD_BOT		0x358
+#define EMAC_SPEC16_ADD_TOP		0x35c
+#define EMAC_SPEC17_ADD_BOT		0x360
+#define EMAC_SPEC17_ADD_TOP		0x364
+#define EMAC_SPEC18_ADD_BOT		0x368
+#define EMAC_SPEC18_ADD_TOP		0x36c
+#define EMAC_SPEC19_ADD_BOT		0x370
+#define EMAC_SPEC19_ADD_TOP		0x374
+#define EMAC_SPEC20_ADD_BOT		0x378
+#define EMAC_SPEC20_ADD_TOP		0x37c
+#define EMAC_SPEC21_ADD_BOT		0x380
+#define EMAC_SPEC21_ADD_TOP		0x384
+#define EMAC_SPEC22_ADD_BOT		0x388
+#define EMAC_SPEC22_ADD_TOP		0x38c
+#define EMAC_SPEC23_ADD_BOT		0x390
+#define EMAC_SPEC23_ADD_TOP		0x394
+#define EMAC_SPEC24_ADD_BOT		0x398
+#define EMAC_SPEC24_ADD_TOP		0x39c
+#define EMAC_SPEC25_ADD_BOT		0x3a0
+#define EMAC_SPEC25_ADD_TOP		0x3a4
+#define EMAC_SPEC26_ADD_BOT		0x3a8
+#define EMAC_SPEC26_ADD_TOP		0x3ac
+#define EMAC_SPEC27_ADD_BOT		0x3b0
+#define EMAC_SPEC27_ADD_TOP		0x3b4
+#define EMAC_SPEC28_ADD_BOT		0x3b8
+#define EMAC_SPEC28_ADD_TOP		0x3bc
+#define EMAC_SPEC29_ADD_BOT		0x3c0
+#define EMAC_SPEC29_ADD_TOP		0x3c4
+#define EMAC_SPEC30_ADD_BOT		0x3c8
+#define EMAC_SPEC30_ADD_TOP		0x3cc
+#define EMAC_SPEC31_ADD_BOT		0x3d0
+#define EMAC_SPEC31_ADD_TOP		0x3d4
+#define EMAC_SPEC32_ADD_BOT		0x3d8
+#define EMAC_SPEC32_ADD_TOP		0x3dc
+
+#define EMAC_SPEC_ADDR_MAX		32
+
+#define EMAC_CONTROL			0x7a0
+
+/* GEMAC definitions and settings */
+
+#define EMAC_PORT_0			0
+#define EMAC_PORT_1			1
+#define EMAC_PORT_2			2
+
+/* The possible operating speeds of the MAC, currently supporting 10, 100 and
+ * 1000Mb modes.
+ */
+typedef enum {SPEED_10M, SPEED_100M, SPEED_1000M, SPEED_1000M_PCS} MAC_SPEED;
+
+#define GMII	1
+#define MII	2
+#define RMII	3
+#define RGMII	4
+#define SGMII	5
+
+#define DUP_HALF	0x00
+#define DUP_FULL	0x01
+
+/* EMAC_NETWORK_CONTROL bits definition */
+#define EMAC_LB_PHY 			(1 << 0)
+#define EMAC_LB_MAC 			(1 << 1)
+#define EMAC_RX_ENABLE			(1 << 2)
+#define EMAC_TX_ENABLE			(1 << 3)
+#define EMAC_MDIO_EN         		(1 << 4)      /* Enable MDIO port */
+
+/* WoL (Wake on Lan bit definition) */
+#define EMAC_WOL_MAGIC                  (1 << 16)
+#define EMAC_WOL_ARP                    (1 << 17)
+#define EMAC_WOL_SPEC_ADDR              (1 << 18)
+#define EMAC_WOL_MULTI                  (1 << 19)
+
+/* EMAC_NETWORK_CONFIG bits definition */
+#define EMAC_SPEED_100		(1 << 0)
+#define EMAC_HALF_DUP		(0 << 1)
+#define EMAC_FULL_DUP		(1 << 1)
+#define EMAC_DUPLEX_MASK	(1 << 1)
+#define EMAC_ENABLE_JUMBO_FRAME (1 << 3)
+#define EMAC_ENABLE_COPY_ALL	(1 << 4)	
+#define EMAC_NO_BROADCAST	(1 << 5)
+#define EMAC_ENABLE_MULTICAST	(1 << 6)
+#define EMAC_ENABLE_UNICAST	(1 << 7)
+#define EMAC_ENABLE_1536_RX	(1 << 8)
+#define EMAC_SPEED_1000		(1 << 10)
+#define EMAC_PCS_ENABLE		(1 << 11)
+#define EMAC_ENABLE_PAUSE_RX	(1 << 13)
+#define EMAC_REMOVE_FCS		(1 << 17)
+#define EMAC_ENABLE_CHKSUM_RX	(1 << 24)
+#define EMAC_MDC_DIV_MASK    (0x7 << 18) /* PCLK divisor for MDC */
+#define EMAC_DATA_BUS_WIDTH_SHIFT       21
+#define EMAC_DATA_BUS_WIDTH_MASK (0x3 << EMAC_DATA_BUS_WIDTH_SHIFT)
+#define EMAC_DATA_BUS_WIDTH_32  (0x00 << EMAC_DATA_BUS_WIDTH_SHIFT)
+#define EMAC_DATA_BUS_WIDTH_64  (0x01 << EMAC_DATA_BUS_WIDTH_SHIFT)
+#define EMAC_DATA_BUS_WIDTH_128 (0x10 << EMAC_DATA_BUS_WIDTH_SHIFT)
+#define EMAC_ENABLE_FCS_RX	(1 << 26)
+#define EMAC_SGMII_MODE_ENABLE	(1 << 27)
+	
+#define EMAC_SPEED_MASK		(EMAC_SPEED_100 | EMAC_SPEED_1000)
+
+/* EMAC_STACKED_VLAN_REG bits definition */
+#define EMAC_ENABLE_STACKED_VLAN	(1 << 31)
+
+/* EMAC_CONTROL bits definition */
+#define EMAC_TWO_BYTES_IP_ALIGN		(1 << 0) // two bytes IP alignement
+
+/* EMAC_NET_STATUS bits  definition */
+#define EMAC_PHY_IDLE        (1<<2)      /* PHY management is idle */
+#define EMAC_MDIO_IN         (1<<1)      /* Status of mdio_in pin */
+#define EMAC_LINK_STATUS     (1<<0)      /* Status of link pin */
+
+/* EMAC_DMA_CONFIG Bit definitions */
+#define EMAC_ENABLE_CHKSUM_TX	(1<<11)
+
+//RMII enable – bit 1 / RGMII enable – bit 2
+#define EMAC_RMII_MODE_ENABLE		((1 << 1) | (0 << 2))
+#define EMAC_RMII_MODE_DISABLE		(0 << 1)
+#define EMAC_RGMII_MODE_ENABLE		((0 << 1) | (1 << 2))
+#define EMAC_RGMII_MODE_DISABLE		(0 << 2)
+#define EMAC_MII_MODE_ENABLE		(EMAC_RMII_MODE_DISABLE | EMAC_RGMII_MODE_DISABLE)
+#define EMAC_GMII_MODE_ENABLE		(EMAC_RMII_MODE_DISABLE | EMAC_RGMII_MODE_DISABLE)
+#define EMAC_MODE_MASK			(0x3 << 1)
+
+/* Default configuration */
+#define EMAC0_DEFAULT_DUPLEX_MODE	FULLDUPLEX 
+#define EMAC0_DEFAULT_EMAC_MODE		RGMII      
+#define EMAC0_DEFAULT_EMAC_SPEED	SPEED_1000M   
+
+#define EMAC1_DEFAULT_DUPLEX_MODE	FULLDUPLEX 
+#define EMAC1_DEFAULT_EMAC_MODE		RGMII      
+#define EMAC1_DEFAULT_EMAC_SPEED	SPEED_1000M   
+
+#define EMAC2_DEFAULT_DUPLEX_MODE	FULLDUPLEX 
+#define EMAC2_DEFAULT_EMAC_MODE		RGMII      
+#define EMAC2_DEFAULT_EMAC_SPEED	SPEED_1000M   
+
+/* EMAC Hash size */
+#define EMAC_HASH_REG_BITS       64
+
+/* The Address organisation for the MAC device.  All addresses are split into
+ * two 32-bit register fields.  The first one (bottom) is the lower 32-bits of
+ * the address and the other field are the high order bits - this may be 16-bits
+ * in the case of MAC addresses, or 32-bits for the hash address.
+ * In terms of memory storage, the first item (bottom) is assumed to be at a
+ * lower address location than 'top'. i.e. top should be at address location of
+ * 'bottom' + 4 bytes.
+ */
+typedef struct {
+	u32 bottom;     /* Lower 32-bits of address. */
+	u32 top;        /* Upper 32-bits of address. */
+} MAC_ADDR;
+
+
+/* The following is the organisation of the address filters section of the MAC
+ * registers.  The Cadence MAC contains four possible specific address match
+ * addresses, if an incoming frame corresponds to any one of these four
+ * addresses then the frame will be copied to memory.
+ * It is not necessary for all four of the address match registers to be
+ * programmed, this is application dependant.
+ */
+typedef struct {
+	MAC_ADDR one;        /* Specific address register 1. */
+	MAC_ADDR two;        /* Specific address register 2. */
+	MAC_ADDR three;      /* Specific address register 3. */
+	MAC_ADDR four;       /* Specific address register 4. */
+} SPEC_ADDR;
+
+typedef struct {
+	u32 mode; 
+	u32 speed;
+	u32 duplex;
+} GEMAC_CFG;
+
+#endif /* _EMAC_H_ */
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/include/pfe/cbus/emac_mtip.h
@@ -0,0 +1,250 @@
+/*
+ *  Copyright (c) 2011, 2014 Freescale Semiconductor, Inc.
+ *
+ *  This program is free software; you can redistribute it and/or
+ *  modify it under the terms of the GNU General Public License
+ *  as published by the Free Software Foundation; either version 2
+ *  of the License, or (at your option) any later version.
+ *
+ *  This program is distributed in the hope that it will be useful,
+ *  but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *  GNU General Public License for more details.
+ *
+ *  You should have received a copy of the GNU General Public License
+ *  along with this program; if not, write to the Free Software
+ *  Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
+ *
+*/
+#ifndef _EMAC_H_
+#define _EMAC_H_
+
+#define EMAC_IEVENT_REG	0x004
+#define EMAC_IMASK_REG	0x008
+#define EMAC_R_DES_ACTIVE_REG	0x010
+#define EMAC_X_DES_ACTIVE_REG	0x014
+#define EMAC_ECNTRL_REG		0x024
+#define EMAC_MII_DATA_REG	0x040
+#define EMAC_MII_CTRL_REG	0x044
+#define EMAC_MIB_CTRL_STS_REG	0x064
+#define EMAC_RCNTRL_REG		0x084
+#define EMAC_TCNTRL_REG		0x0C4
+#define EMAC_PHY_ADDR_LOW	0x0E4
+#define EMAC_PHY_ADDR_HIGH	0x0E8
+#define EMAC_GAUR		0x120
+#define EMAC_GALR		0x124
+#define EMAC_TFWR_STR_FWD	0x144
+#define EMAC_RX_SECTIOM_FULL	0x190
+#define EMAC_TX_SECTION_EMPTY	0x1A0
+#define EMAC_TRUNC_FL		0x1B0
+
+#define RMON_T_DROP		0x200 /* Count of frames not cntd correctly */
+#define RMON_T_PACKETS		0x204 /* RMON TX packet count */
+#define RMON_T_BC_PKT		0x208 /* RMON TX broadcast pkts */
+#define RMON_T_MC_PKT		0x20c /* RMON TX multicast pkts */
+#define RMON_T_CRC_ALIGN	0x210 /* RMON TX pkts with CRC align err */
+#define RMON_T_UNDERSIZE	0x214 /* RMON TX pkts < 64 bytes, good CRC */
+#define RMON_T_OVERSIZE		0x218 /* RMON TX pkts > MAX_FL bytes good CRC */
+#define RMON_T_FRAG		0x21c /* RMON TX pkts < 64 bytes, bad CRC */
+#define RMON_T_JAB		0x220 /* RMON TX pkts > MAX_FL bytes, bad CRC */
+#define RMON_T_COL		0x224 /* RMON TX collision count */
+#define RMON_T_P64		0x228 /* RMON TX 64 byte pkts */
+#define RMON_T_P65TO127		0x22c /* RMON TX 65 to 127 byte pkts */
+#define RMON_T_P128TO255	0x230 /* RMON TX 128 to 255 byte pkts */
+#define RMON_T_P256TO511	0x234 /* RMON TX 256 to 511 byte pkts */
+#define RMON_T_P512TO1023	0x238 /* RMON TX 512 to 1023 byte pkts */
+#define RMON_T_P1024TO2047	0x23c /* RMON TX 1024 to 2047 byte pkts */
+#define RMON_T_P_GTE2048	0x240 /* RMON TX pkts > 2048 bytes */
+#define RMON_T_OCTETS		0x244 /* RMON TX octets */
+#define IEEE_T_DROP		0x248 /* Count of frames not counted crtly */
+#define IEEE_T_FRAME_OK		0x24c /* Frames tx'd OK */
+#define IEEE_T_1COL		0x250 /* Frames tx'd with single collision */
+#define IEEE_T_MCOL		0x254 /* Frames tx'd with multiple collision */
+#define IEEE_T_DEF		0x258 /* Frames tx'd after deferral delay */
+#define IEEE_T_LCOL		0x25c /* Frames tx'd with late collision */
+#define IEEE_T_EXCOL		0x260 /* Frames tx'd with excesv collisions */
+#define IEEE_T_MACERR		0x264 /* Frames tx'd with TX FIFO underrun */
+#define IEEE_T_CSERR		0x268 /* Frames tx'd with carrier sense err */
+#define IEEE_T_SQE		0x26c /* Frames tx'd with SQE err */
+#define IEEE_T_FDXFC		0x270 /* Flow control pause frames tx'd */
+#define IEEE_T_OCTETS_OK	0x274 /* Octet count for frames tx'd w/o err */
+#define RMON_R_PACKETS		0x284 /* RMON RX packet count */
+#define RMON_R_BC_PKT		0x288 /* RMON RX broadcast pkts */
+#define RMON_R_MC_PKT		0x28c /* RMON RX multicast pkts */
+#define RMON_R_CRC_ALIGN	0x290 /* RMON RX pkts with CRC alignment err */
+#define RMON_R_UNDERSIZE	0x294 /* RMON RX pkts < 64 bytes, good CRC */
+#define RMON_R_OVERSIZE		0x298 /* RMON RX pkts > MAX_FL bytes good CRC */
+#define RMON_R_FRAG		0x29c /* RMON RX pkts < 64 bytes, bad CRC */
+#define RMON_R_JAB		0x2a0 /* RMON RX pkts > MAX_FL bytes, bad CRC */
+#define RMON_R_RESVD_O		0x2a4 /* Reserved */
+#define RMON_R_P64		0x2a8 /* RMON RX 64 byte pkts */
+#define RMON_R_P65TO127		0x2ac /* RMON RX 65 to 127 byte pkts */
+#define RMON_R_P128TO255	0x2b0 /* RMON RX 128 to 255 byte pkts */
+#define RMON_R_P256TO511	0x2b4 /* RMON RX 256 to 511 byte pkts */
+#define RMON_R_P512TO1023	0x2b8 /* RMON RX 512 to 1023 byte pkts */
+#define RMON_R_P1024TO2047	0x2bc /* RMON RX 1024 to 2047 byte pkts */
+#define RMON_R_P_GTE2048	0x2c0 /* RMON RX pkts > 2048 bytes */
+#define RMON_R_OCTETS		0x2c4 /* RMON RX octets */
+#define IEEE_R_DROP		0x2c8 /* Count frames not counted correctly */
+#define IEEE_R_FRAME_OK		0x2cc /* Frames rx'd OK */
+#define IEEE_R_CRC		0x2d0 /* Frames rx'd with CRC err */
+#define IEEE_R_ALIGN		0x2d4 /* Frames rx'd with alignment err */
+#define IEEE_R_MACERR		0x2d8 /* Receive FIFO overflow count */
+#define IEEE_R_FDXFC		0x2dc /* Flow control pause frames rx'd */
+#define IEEE_R_OCTETS_OK	0x2e0 /* Octet cnt for frames rx'd w/o err */
+
+#define EMAC_SMAC_0_0		0x500 /*Supplemental MAC Address 0 (RW).*/
+#define EMAC_SMAC_0_1		0x504 /*Supplemental MAC Address 0 (RW).*/
+
+/* GEMAC definitions and settings */
+
+#define EMAC_PORT_0			0
+#define EMAC_PORT_1			1
+
+/* GEMAC Bit definitions */
+#define EMAC_IEVENT_HBERR                0x80000000
+#define EMAC_IEVENT_BABR                 0x40000000
+#define EMAC_IEVENT_BABT                 0x20000000
+#define EMAC_IEVENT_GRA                  0x10000000
+#define EMAC_IEVENT_TXF                  0x08000000
+#define EMAC_IEVENT_TXB                  0x04000000
+#define EMAC_IEVENT_RXF                  0x02000000
+#define EMAC_IEVENT_RXB                  0x01000000
+#define EMAC_IEVENT_MII                  0x00800000
+#define EMAC_IEVENT_EBERR                0x00400000
+#define EMAC_IEVENT_LC                   0x00200000
+#define EMAC_IEVENT_RL                   0x00100000
+#define EMAC_IEVENT_UN                   0x00080000
+
+#define EMAC_IMASK_HBERR                 0x80000000
+#define EMAC_IMASK_BABR                  0x40000000
+#define EMAC_IMASKT_BABT                 0x20000000
+#define EMAC_IMASK_GRA                   0x10000000
+#define EMAC_IMASKT_TXF                  0x08000000
+#define EMAC_IMASK_TXB                   0x04000000
+#define EMAC_IMASKT_RXF                  0x02000000
+#define EMAC_IMASK_RXB                   0x01000000
+#define EMAC_IMASK_MII                   0x00800000
+#define EMAC_IMASK_EBERR                 0x00400000
+#define EMAC_IMASK_LC                    0x00200000
+#define EMAC_IMASKT_RL                   0x00100000
+#define EMAC_IMASK_UN                    0x00080000
+
+#define EMAC_RCNTRL_MAX_FL_SHIFT         16
+#define EMAC_RCNTRL_LOOP                 0x00000001
+#define EMAC_RCNTRL_DRT                  0x00000002
+#define EMAC_RCNTRL_MII_MODE             0x00000004
+#define EMAC_RCNTRL_PROM                 0x00000008
+#define EMAC_RCNTRL_BC_REJ               0x00000010
+#define EMAC_RCNTRL_FCE                  0x00000020
+#define EMAC_RCNTRL_RGMII                0x00000040
+#define EMAC_RCNTRL_SGMII                0x00000080
+#define EMAC_RCNTRL_RMII                 0x00000100
+#define EMAC_RCNTRL_RMII_10T             0x00000200
+#define EMAC_RCNTRL_CRC_FWD		 0x00004000
+
+#define EMAC_TCNTRL_GTS                  0x00000001
+#define EMAC_TCNTRL_HBC                  0x00000002
+#define EMAC_TCNTRL_FDEN                 0x00000004
+#define EMAC_TCNTRL_TFC_PAUSE            0x00000008
+#define EMAC_TCNTRL_RFC_PAUSE            0x00000010
+
+#define EMAC_ECNTRL_RESET                0x00000001      /* reset the EMAC */
+#define EMAC_ECNTRL_ETHER_EN             0x00000002      /* enable the EMAC */
+#define EMAC_ECNTRL_SPEED                0x00000020
+#define EMAC_ECNTRL_DBSWAP               0x00000100
+
+#define EMAC_X_WMRK_STRFWD               0x00000100
+
+#define EMAC_X_DES_ACTIVE_TDAR           0x01000000
+#define EMAC_R_DES_ACTIVE_RDAR           0x01000000
+
+
+
+/* The possible operating speeds of the MAC, currently supporting 10, 100 and
+ * 1000Mb modes.
+ */
+typedef enum {SPEED_10M, SPEED_100M, SPEED_1000M, SPEED_1000M_PCS} MAC_SPEED;
+
+#define GMII	1
+#define MII	2
+#define RMII	3
+#define RGMII	4
+#define SGMII	5
+
+#define DUPLEX_HALF	0x00
+#define DUPLEX_FULL	0x01
+
+
+/* Default configuration */
+#define EMAC0_DEFAULT_DUPLEX_MODE	FULLDUPLEX 
+#define EMAC0_DEFAULT_EMAC_MODE		RGMII      
+#define EMAC0_DEFAULT_EMAC_SPEED	SPEED_1000M   
+
+#define EMAC1_DEFAULT_DUPLEX_MODE	FULLDUPLEX 
+#define EMAC1_DEFAULT_EMAC_MODE		SGMII      
+#define EMAC1_DEFAULT_EMAC_SPEED	SPEED_1000M   
+
+/* MII-related definitios */
+#define EMAC_MII_DATA_ST         0x40000000      /* Start of frame delimiter */
+#define EMAC_MII_DATA_OP_RD      0x20000000      /* Perform a read operation */
+#define EMAC_MII_DATA_OP_WR      0x10000000      /* Perform a write operation */
+#define EMAC_MII_DATA_PA_MSK     0x0f800000      /* PHY Address field mask */
+#define EMAC_MII_DATA_RA_MSK     0x007c0000      /* PHY Register field mask */
+#define EMAC_MII_DATA_TA         0x00020000      /* Turnaround */
+#define EMAC_MII_DATA_DATAMSK    0x0000ffff      /* PHY data field */
+
+#define EMAC_MII_DATA_RA_SHIFT   18      /* MII Register address bits */
+#define EMAC_MII_DATA_RA_MASK	 0x1F      /* MII Register address mask */
+#define EMAC_MII_DATA_PA_SHIFT   23      /* MII PHY address bits */
+#define EMAC_MII_DATA_PA_MASK    0x1F      /* MII PHY address mask */
+
+#define EMAC_MII_DATA_RA(v) ((v & EMAC_MII_DATA_RA_MASK) << EMAC_MII_DATA_RA_SHIFT)
+#define EMAC_MII_DATA_PA(v) ((v & EMAC_MII_DATA_RA_MASK) << EMAC_MII_DATA_PA_SHIFT)
+#define EMAC_MII_DATA(v)    (v & 0xffff)
+
+#define EMAC_MII_SPEED_SHIFT	1
+#define EMAC_HOLDTIME_SHIFT	8
+#define EMAC_HOLDTIME_MASK	0x7
+#define EMAC_HOLDTIME(v)	((v & EMAC_HOLDTIME_MASK) << EMAC_HOLDTIME_SHIFT)
+
+/* The Address organisation for the MAC device.  All addresses are split into
+ * two 32-bit register fields.  The first one (bottom) is the lower 32-bits of
+ * the address and the other field are the high order bits - this may be 16-bits
+ * in the case of MAC addresses, or 32-bits for the hash address.
+ * In terms of memory storage, the first item (bottom) is assumed to be at a
+ * lower address location than 'top'. i.e. top should be at address location of
+ * 'bottom' + 4 bytes.
+ */
+typedef struct {
+	u32 bottom;     /* Lower 32-bits of address. */
+	u32 top;        /* Upper 32-bits of address. */
+} MAC_ADDR;
+
+
+/* The following is the organisation of the address filters section of the MAC
+ * registers.  The Cadence MAC contains four possible specific address match
+ * addresses, if an incoming frame corresponds to any one of these four
+ * addresses then the frame will be copied to memory.
+ * It is not necessary for all four of the address match registers to be
+ * programmed, this is application dependant.
+ */
+typedef struct {
+	MAC_ADDR one;        /* Specific address register 1. */
+	MAC_ADDR two;        /* Specific address register 2. */
+	MAC_ADDR three;      /* Specific address register 3. */
+	MAC_ADDR four;       /* Specific address register 4. */
+} SPEC_ADDR;
+
+typedef struct {
+	u32 mode; 
+	u32 speed;
+	u32 duplex;
+} GEMAC_CFG;
+
+/* EMAC Hash size */
+#define EMAC_HASH_REG_BITS       64
+
+#define EMAC_SPEC_ADDR_MAX		4
+
+#endif /* _EMAC_H_ */
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/include/pfe/cbus/gpi.h
@@ -0,0 +1,78 @@
+/*
+ *  Copyright (c) 2011, 2014 Freescale Semiconductor, Inc.
+ *
+ *  This program is free software; you can redistribute it and/or
+ *  modify it under the terms of the GNU General Public License
+ *  as published by the Free Software Foundation; either version 2
+ *  of the License, or (at your option) any later version.
+ *
+ *  This program is distributed in the hope that it will be useful,
+ *  but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *  GNU General Public License for more details.
+ *
+ *  You should have received a copy of the GNU General Public License
+ *  along with this program; if not, write to the Free Software
+ *  Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
+ *
+*/
+#ifndef _GPI_H_
+#define _GPI_H_
+
+#define GPI_VERSION			0x00
+#define GPI_CTRL			0x04
+#define GPI_RX_CONFIG			0x08
+#define GPI_HDR_SIZE			0x0c
+#define GPI_BUF_SIZE			0x10
+#define GPI_LMEM_ALLOC_ADDR		0x14
+#define GPI_LMEM_FREE_ADDR		0x18
+#define GPI_DDR_ALLOC_ADDR		0x1c
+#define GPI_DDR_FREE_ADDR		0x20
+#define GPI_CLASS_ADDR			0x24
+#define GPI_DRX_FIFO			0x28
+#define GPI_TRX_FIFO			0x2c
+#define GPI_INQ_PKTPTR			0x30
+#define GPI_DDR_DATA_OFFSET		0x34
+#define GPI_LMEM_DATA_OFFSET		0x38
+#define GPI_TMLF_TX			0x4c
+#define GPI_DTX_ASEQ			0x50
+#define GPI_FIFO_STATUS			0x54
+#define GPI_FIFO_DEBUG			0x58
+#define GPI_TX_PAUSE_TIME		0x5c
+#define GPI_LMEM_SEC_BUF_DATA_OFFSET	0x60
+#define GPI_DDR_SEC_BUF_DATA_OFFSET	0x64
+#define GPI_TOE_CHKSUM_EN		0x68
+#define GPI_OVERRUN_DROPCNT		0x6c
+
+typedef struct {
+	u32 lmem_rtry_cnt;
+	u32 tmlf_txthres;
+	u32 aseq_len;
+} GPI_CFG;
+
+
+/* GPI commons defines */ 
+#define GPI_LMEM_BUF_EN		0x1
+#define GPI_DDR_BUF_EN		0x1
+
+/* EGPI 1 defines */ 
+#define EGPI1_LMEM_RTRY_CNT	0x40
+#define EGPI1_TMLF_TXTHRES	0xBC
+#define EGPI1_ASEQ_LEN		0x50
+
+/* EGPI 2 defines */ 
+#define EGPI2_LMEM_RTRY_CNT	0x40
+#define EGPI2_TMLF_TXTHRES	0xBC
+#define EGPI2_ASEQ_LEN		0x40
+
+/* EGPI 3 defines */ 
+#define EGPI3_LMEM_RTRY_CNT	0x40
+#define EGPI3_TMLF_TXTHRES	0xBC
+#define EGPI3_ASEQ_LEN		0x40
+
+/* HGPI defines */ 
+#define HGPI_LMEM_RTRY_CNT	0x40
+#define HGPI_TMLF_TXTHRES	0xBC
+#define HGPI_ASEQ_LEN		0x40
+
+#endif /* _GPI_H_ */
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/include/pfe/cbus/gpt.h
@@ -0,0 +1,29 @@
+/*
+ *  Copyright (c) 2011, 2014 Freescale Semiconductor, Inc.
+ *
+ *  This program is free software; you can redistribute it and/or
+ *  modify it under the terms of the GNU General Public License
+ *  as published by the Free Software Foundation; either version 2
+ *  of the License, or (at your option) any later version.
+ *
+ *  This program is distributed in the hope that it will be useful,
+ *  but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *  GNU General Public License for more details.
+ *
+ *  You should have received a copy of the GNU General Public License
+ *  along with this program; if not, write to the Free Software
+ *  Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
+ *
+*/
+#ifndef _CBUS_GPT_H_
+#define _CBUS_GPT_H_
+
+#define CBUS_GPT_VERSION	 (CBUS_GPT_BASE_ADDR + 0x00)
+#define CBUS_GPT_STATUS		 (CBUS_GPT_BASE_ADDR + 0x04)
+#define CBUS_GPT_CONFIG		 (CBUS_GPT_BASE_ADDR + 0x08)
+#define CBUS_GPT_COUNTER	 (CBUS_GPT_BASE_ADDR + 0x0c)
+#define CBUS_GPT_PERIOD		 (CBUS_GPT_BASE_ADDR + 0x10)
+#define CBUS_GPT_WIDTH		 (CBUS_GPT_BASE_ADDR + 0x14)
+
+#endif /* _CBUS_GPT_H_ */
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/include/pfe/cbus/hif.h
@@ -0,0 +1,96 @@
+/*
+ *  Copyright (c) 2011, 2014 Freescale Semiconductor, Inc.
+ *
+ *  This program is free software; you can redistribute it and/or
+ *  modify it under the terms of the GNU General Public License
+ *  as published by the Free Software Foundation; either version 2
+ *  of the License, or (at your option) any later version.
+ *
+ *  This program is distributed in the hope that it will be useful,
+ *  but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *  GNU General Public License for more details.
+ *
+ *  You should have received a copy of the GNU General Public License
+ *  along with this program; if not, write to the Free Software
+ *  Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
+ *
+*/
+#ifndef _HIF_H_
+#define _HIF_H_
+
+/** @file hif.h.
+ * hif - PFE hif block control and status register. Mapped on CBUS and accessible from all PE's and ARM.
+ */
+#define HIF_VERSION		(HIF_BASE_ADDR + 0x00)
+#define HIF_TX_CTRL		(HIF_BASE_ADDR + 0x04)
+#define HIF_TX_CURR_BD_ADDR	(HIF_BASE_ADDR + 0x08)
+#define HIF_TX_ALLOC		(HIF_BASE_ADDR + 0x0c)
+#define HIF_TX_BDP_ADDR		(HIF_BASE_ADDR + 0x10)
+#define HIF_TX_STATUS		(HIF_BASE_ADDR + 0x14)
+#define HIF_RX_CTRL		(HIF_BASE_ADDR + 0x20)
+#define HIF_RX_BDP_ADDR		(HIF_BASE_ADDR + 0x24)
+#define HIF_RX_STATUS		(HIF_BASE_ADDR + 0x30)
+#define HIF_INT_SRC		(HIF_BASE_ADDR + 0x34)
+#define HIF_INT_ENABLE		(HIF_BASE_ADDR + 0x38)
+#define HIF_POLL_CTRL		(HIF_BASE_ADDR + 0x3c)
+#define HIF_RX_CURR_BD_ADDR	(HIF_BASE_ADDR + 0x40)
+#define HIF_RX_ALLOC		(HIF_BASE_ADDR + 0x44)
+#define HIF_TX_DMA_STATUS	(HIF_BASE_ADDR + 0x48)
+#define HIF_RX_DMA_STATUS	(HIF_BASE_ADDR + 0x4c)
+#define HIF_INT_COAL		(HIF_BASE_ADDR + 0x50)
+
+/*HIF_INT_SRC/ HIF_INT_ENABLE control bits */
+#define HIF_INT        		(1 << 0)
+#define HIF_RXBD_INT   		(1 << 1)
+#define HIF_RXPKT_INT  		(1 << 2)
+#define HIF_TXBD_INT   		(1 << 3)
+#define HIF_TXPKT_INT  		(1 << 4)
+
+/*HIF_TX_CTRL bits */
+#define HIF_CTRL_DMA_EN			(1<<0)
+#define HIF_CTRL_BDP_POLL_CTRL_EN	(1<<1)
+#define HIF_CTRL_BDP_CH_START_WSTB	(1<<2)
+
+/*HIF_INT_ENABLE bits */
+#define HIF_INT_EN		(1 << 0)
+#define HIF_RXBD_INT_EN		(1 << 1)
+#define HIF_RXPKT_INT_EN	(1 << 2)
+#define HIF_TXBD_INT_EN		(1 << 3)
+#define HIF_TXPKT_INT_EN	(1 << 4)
+
+/*HIF_POLL_CTRL bits*/
+#define HIF_RX_POLL_CTRL_CYCLE	0x0400
+#define HIF_TX_POLL_CTRL_CYCLE	0x0400
+
+/*HIF_INT_COAL bits*/
+#define HIF_INT_COAL_ENABLE	(1 << 31)
+
+/*Buffer descriptor control bits */
+#define BD_CTRL_BUFLEN_MASK	0x3fff
+#define BD_BUF_LEN(x)		(x & BD_CTRL_BUFLEN_MASK)
+#define BD_CTRL_CBD_INT_EN	(1 << 16)
+#define BD_CTRL_PKT_INT_EN	(1 << 17)
+#define BD_CTRL_LIFM		(1 << 18)
+#define BD_CTRL_LAST_BD		(1 << 19)
+#define BD_CTRL_DIR		(1 << 20)
+#define BD_CTRL_LMEM_CPY	(1 << 21) /*Valid only for HIF_NOCPY*/
+#define BD_CTRL_PKT_XFER	(1 << 24)
+#define BD_CTRL_DESC_EN		(1 << 31)
+#define BD_CTRL_PARSE_DISABLE	(1 << 25)
+#define BD_CTRL_BRFETCH_DISABLE	(1 << 26)
+#define BD_CTRL_RTFETCH_DISABLE	(1 << 27)
+
+/*Buffer descriptor status bits*/
+#define BD_STATUS_CONN_ID(x)	((x) & 0xffff)
+#define BD_STATUS_DIR_PROC_ID	(1 << 16)
+#define BD_STATUS_CONN_ID_EN	(1 << 17))
+#define BD_STATUS_PE2PROC_ID(x)	(((x) & 7) << 18)
+#define BD_STATUS_LE_DATA	(1 << 21)
+#define BD_STATUS_CHKSUM_EN	(1 << 22)
+
+/*HIF Buffer descriptor status bits */
+#define DIR_PROC_ID		(1 << 16)
+#define PROC_ID(id)		((id) << 18)
+
+#endif /* _HIF_H_ */
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/include/pfe/cbus/hif_nocpy.h
@@ -0,0 +1,51 @@
+/*
+ *  Copyright (c) 2011, 2014 Freescale Semiconductor, Inc.
+ *
+ *  This program is free software; you can redistribute it and/or
+ *  modify it under the terms of the GNU General Public License
+ *  as published by the Free Software Foundation; either version 2
+ *  of the License, or (at your option) any later version.
+ *
+ *  This program is distributed in the hope that it will be useful,
+ *  but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *  GNU General Public License for more details.
+ *
+ *  You should have received a copy of the GNU General Public License
+ *  along with this program; if not, write to the Free Software
+ *  Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
+ *
+*/
+#ifndef _HIF_NOCPY_H_
+#define _HIF_NOCPY_H_
+
+#define HIF_NOCPY_VERSION		(HIF_NOCPY_BASE_ADDR + 0x00)
+#define HIF_NOCPY_TX_CTRL		(HIF_NOCPY_BASE_ADDR + 0x04)
+#define HIF_NOCPY_TX_CURR_BD_ADDR	(HIF_NOCPY_BASE_ADDR + 0x08)
+#define HIF_NOCPY_TX_ALLOC		(HIF_NOCPY_BASE_ADDR + 0x0c)
+#define HIF_NOCPY_TX_BDP_ADDR		(HIF_NOCPY_BASE_ADDR + 0x10)
+#define HIF_NOCPY_TX_STATUS		(HIF_NOCPY_BASE_ADDR + 0x14)
+#define HIF_NOCPY_RX_CTRL		(HIF_NOCPY_BASE_ADDR + 0x20)
+#define HIF_NOCPY_RX_BDP_ADDR		(HIF_NOCPY_BASE_ADDR + 0x24)
+#define HIF_NOCPY_RX_STATUS		(HIF_NOCPY_BASE_ADDR + 0x30)
+#define HIF_NOCPY_INT_SRC		(HIF_NOCPY_BASE_ADDR + 0x34)
+#define HIF_NOCPY_INT_ENABLE		(HIF_NOCPY_BASE_ADDR + 0x38)
+#define HIF_NOCPY_POLL_CTRL		(HIF_NOCPY_BASE_ADDR + 0x3c)
+#define HIF_NOCPY_RX_CURR_BD_ADDR	(HIF_NOCPY_BASE_ADDR + 0x40)
+#define HIF_NOCPY_RX_ALLOC		(HIF_NOCPY_BASE_ADDR + 0x44)
+#define HIF_NOCPY_TX_DMA_STATUS		(HIF_NOCPY_BASE_ADDR + 0x48)
+#define HIF_NOCPY_RX_DMA_STATUS		(HIF_NOCPY_BASE_ADDR + 0x4c)
+#define HIF_NOCPY_RX_INQ0_PKTPTR	(HIF_NOCPY_BASE_ADDR + 0x50)
+#define HIF_NOCPY_RX_INQ1_PKTPTR	(HIF_NOCPY_BASE_ADDR + 0x54)
+#define HIF_NOCPY_TX_PORT_NO		(HIF_NOCPY_BASE_ADDR + 0x60)
+#define HIF_NOCPY_LMEM_ALLOC_ADDR	(HIF_NOCPY_BASE_ADDR + 0x64)
+#define HIF_NOCPY_CLASS_ADDR		(HIF_NOCPY_BASE_ADDR + 0x68)
+#define HIF_NOCPY_TMU_PORT0_ADDR	(HIF_NOCPY_BASE_ADDR + 0x70)
+#define HIF_NOCPY_TMU_PORT1_ADDR	(HIF_NOCPY_BASE_ADDR + 0x74)
+#define HIF_NOCPY_TMU_PORT2_ADDR	(HIF_NOCPY_BASE_ADDR + 0x7c)
+#define HIF_NOCPY_TMU_PORT3_ADDR	(HIF_NOCPY_BASE_ADDR + 0x80)
+#define HIF_NOCPY_TMU_PORT4_ADDR	(HIF_NOCPY_BASE_ADDR + 0x84)
+#define HIF_NOCPY_INT_COAL		(HIF_NOCPY_BASE_ADDR + 0x90)
+
+
+#endif /* _HIF_NOCPY_H_ */
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/include/pfe/cbus/tmu_csr.h
@@ -0,0 +1,128 @@
+/*
+ *  Copyright (c) 2011, 2014 Freescale Semiconductor, Inc.
+ *
+ *  This program is free software; you can redistribute it and/or
+ *  modify it under the terms of the GNU General Public License
+ *  as published by the Free Software Foundation; either version 2
+ *  of the License, or (at your option) any later version.
+ *
+ *  This program is distributed in the hope that it will be useful,
+ *  but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *  GNU General Public License for more details.
+ *
+ *  You should have received a copy of the GNU General Public License
+ *  along with this program; if not, write to the Free Software
+ *  Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
+ *
+*/
+#ifndef _TMU_CSR_H_
+#define _TMU_CSR_H_
+
+#define TMU_VERSION			(TMU_CSR_BASE_ADDR + 0x000)
+#define TMU_INQ_WATERMARK		(TMU_CSR_BASE_ADDR + 0x004)
+#define TMU_PHY_INQ_PKTPTR		(TMU_CSR_BASE_ADDR + 0x008)
+#define TMU_PHY_INQ_PKTINFO		(TMU_CSR_BASE_ADDR + 0x00c)
+#define TMU_PHY_INQ_FIFO_CNT		(TMU_CSR_BASE_ADDR + 0x010)
+#define TMU_SYS_GENERIC_CONTROL		(TMU_CSR_BASE_ADDR + 0x014)
+#define TMU_SYS_GENERIC_STATUS		(TMU_CSR_BASE_ADDR + 0x018)
+#define TMU_SYS_GEN_CON0		(TMU_CSR_BASE_ADDR + 0x01c)
+#define TMU_SYS_GEN_CON1		(TMU_CSR_BASE_ADDR + 0x020)
+#define TMU_SYS_GEN_CON2		(TMU_CSR_BASE_ADDR + 0x024)
+#define TMU_SYS_GEN_CON3		(TMU_CSR_BASE_ADDR + 0x028)
+#define TMU_SYS_GEN_CON4		(TMU_CSR_BASE_ADDR + 0x02c)
+#define TMU_TEQ_DISABLE_DROPCHK		(TMU_CSR_BASE_ADDR + 0x030)
+#define TMU_TEQ_CTRL			(TMU_CSR_BASE_ADDR + 0x034)
+#define TMU_TEQ_QCFG			(TMU_CSR_BASE_ADDR + 0x038)
+#define TMU_TEQ_DROP_STAT		(TMU_CSR_BASE_ADDR + 0x03c)
+#define TMU_TEQ_QAVG			(TMU_CSR_BASE_ADDR + 0x040)
+#define TMU_TEQ_WREG_PROB		(TMU_CSR_BASE_ADDR + 0x044)
+#define TMU_TEQ_TRANS_STAT		(TMU_CSR_BASE_ADDR + 0x048)
+#define TMU_TEQ_HW_PROB_CFG0		(TMU_CSR_BASE_ADDR + 0x04c)
+#define TMU_TEQ_HW_PROB_CFG1		(TMU_CSR_BASE_ADDR + 0x050)
+#define TMU_TEQ_HW_PROB_CFG2		(TMU_CSR_BASE_ADDR + 0x054)
+#define TMU_TEQ_HW_PROB_CFG3		(TMU_CSR_BASE_ADDR + 0x058)
+#define TMU_TEQ_HW_PROB_CFG4		(TMU_CSR_BASE_ADDR + 0x05c)
+#define TMU_TEQ_HW_PROB_CFG5		(TMU_CSR_BASE_ADDR + 0x060)
+#define TMU_TEQ_HW_PROB_CFG6		(TMU_CSR_BASE_ADDR + 0x064)
+#define TMU_TEQ_HW_PROB_CFG7		(TMU_CSR_BASE_ADDR + 0x068)
+#define TMU_TEQ_HW_PROB_CFG8		(TMU_CSR_BASE_ADDR + 0x06c)
+#define TMU_TEQ_HW_PROB_CFG9		(TMU_CSR_BASE_ADDR + 0x070)
+#define TMU_TEQ_HW_PROB_CFG10		(TMU_CSR_BASE_ADDR + 0x074)
+#define TMU_TEQ_HW_PROB_CFG11		(TMU_CSR_BASE_ADDR + 0x078)
+#define TMU_TEQ_HW_PROB_CFG12		(TMU_CSR_BASE_ADDR + 0x07c)
+#define TMU_TEQ_HW_PROB_CFG13		(TMU_CSR_BASE_ADDR + 0x080)
+#define TMU_TEQ_HW_PROB_CFG14		(TMU_CSR_BASE_ADDR + 0x084)
+#define TMU_TEQ_HW_PROB_CFG15		(TMU_CSR_BASE_ADDR + 0x088)
+#define TMU_TEQ_HW_PROB_CFG16		(TMU_CSR_BASE_ADDR + 0x08c)
+#define TMU_TEQ_HW_PROB_CFG17		(TMU_CSR_BASE_ADDR + 0x090)
+#define TMU_TEQ_HW_PROB_CFG18		(TMU_CSR_BASE_ADDR + 0x094)
+#define TMU_TEQ_HW_PROB_CFG19		(TMU_CSR_BASE_ADDR + 0x098)
+#define TMU_TEQ_HW_PROB_CFG20		(TMU_CSR_BASE_ADDR + 0x09c)
+#define TMU_TEQ_HW_PROB_CFG21		(TMU_CSR_BASE_ADDR + 0x0a0)
+#define TMU_TEQ_HW_PROB_CFG22		(TMU_CSR_BASE_ADDR + 0x0a4)
+#define TMU_TEQ_HW_PROB_CFG23		(TMU_CSR_BASE_ADDR + 0x0a8)
+#define TMU_TEQ_HW_PROB_CFG24		(TMU_CSR_BASE_ADDR + 0x0ac)
+#define TMU_TEQ_HW_PROB_CFG25		(TMU_CSR_BASE_ADDR + 0x0b0)
+#define TMU_TDQ_IIFG_CFG		(TMU_CSR_BASE_ADDR + 0x0b4)
+#define TMU_TDQ0_SCH_CTRL		(TMU_CSR_BASE_ADDR + 0x0b8)	/**< [9:0] Scheduler Enable for each of the scheduler in the TDQ. This is a global Enable for all schedulers in PHY0 */
+#define TMU_LLM_CTRL			(TMU_CSR_BASE_ADDR + 0x0bc)
+#define TMU_LLM_BASE_ADDR		(TMU_CSR_BASE_ADDR + 0x0c0)
+#define TMU_LLM_QUE_LEN			(TMU_CSR_BASE_ADDR + 0x0c4)
+#define TMU_LLM_QUE_HEADPTR		(TMU_CSR_BASE_ADDR + 0x0c8)
+#define TMU_LLM_QUE_TAILPTR		(TMU_CSR_BASE_ADDR + 0x0cc)
+#define TMU_LLM_QUE_DROPCNT		(TMU_CSR_BASE_ADDR + 0x0d0)
+#define TMU_INT_EN			(TMU_CSR_BASE_ADDR + 0x0d4)
+#define TMU_INT_SRC			(TMU_CSR_BASE_ADDR + 0x0d8)
+#define TMU_INQ_STAT			(TMU_CSR_BASE_ADDR + 0x0dc)
+#define TMU_CTRL			(TMU_CSR_BASE_ADDR + 0x0e0)
+
+#define TMU_MEM_ACCESS_ADDR		(TMU_CSR_BASE_ADDR + 0x0e4)	/**< [31] Mem Access Command. 0 = Internal Memory Read, 1 = Internal memory Write [27:24] Byte Enables of the Internal memory access [23:0] Address of the internal memory. This address is used to access both the PM and DM of all the PE's */
+#define TMU_MEM_ACCESS_WDATA		(TMU_CSR_BASE_ADDR + 0x0e8)	/**< Internal Memory Access Write Data */
+#define TMU_MEM_ACCESS_RDATA		(TMU_CSR_BASE_ADDR + 0x0ec)	/**< Internal Memory Access Read Data. The commands are blocked at the mem_access only */
+
+#define TMU_PHY0_INQ_ADDR		(TMU_CSR_BASE_ADDR + 0x0f0)	/**< [31:0] PHY0 in queue address (must be initialized with one of the xxx_INQ_PKTPTR cbus addresses) */
+#define TMU_PHY1_INQ_ADDR		(TMU_CSR_BASE_ADDR + 0x0f4)	/**< [31:0] PHY1 in queue address (must be initialized with one of the xxx_INQ_PKTPTR cbus addresses) */
+#define TMU_PHY2_INQ_ADDR		(TMU_CSR_BASE_ADDR + 0x0f8)	/**< [31:0] PHY2 in queue address (must be initialized with one of the xxx_INQ_PKTPTR cbus addresses) */
+#define TMU_PHY3_INQ_ADDR		(TMU_CSR_BASE_ADDR + 0x0fc)	/**< [31:0] PHY3 in queue address (must be initialized with one of the xxx_INQ_PKTPTR cbus addresses) */
+#define TMU_BMU_INQ_ADDR		(TMU_CSR_BASE_ADDR + 0x100)
+#define TMU_TX_CTRL			(TMU_CSR_BASE_ADDR + 0x104)
+
+#define TMU_BUS_ACCESS_WDATA		(TMU_CSR_BASE_ADDR + 0x108)
+#define TMU_BUS_ACCESS			(TMU_CSR_BASE_ADDR + 0x10c)
+#define TMU_BUS_ACCESS_RDATA		(TMU_CSR_BASE_ADDR + 0x110)
+
+#define TMU_PE_SYS_CLK_RATIO		(TMU_CSR_BASE_ADDR + 0x114)
+#define TMU_PE_STATUS			(TMU_CSR_BASE_ADDR + 0x118)
+#define TMU_TEQ_MAX_THRESHOLD		(TMU_CSR_BASE_ADDR + 0x11c)
+#define TMU_PHY4_INQ_ADDR		(TMU_CSR_BASE_ADDR + 0x134)	/**< [31:0] PHY4 in queue address (must be initialized with one of the xxx_INQ_PKTPTR cbus addresses) */
+#define TMU_TDQ1_SCH_CTRL		(TMU_CSR_BASE_ADDR + 0x138)	/**< [9:0] Scheduler Enable for each of the scheduler in the TDQ. This is a global Enable for all schedulers in PHY1 */
+#define TMU_TDQ2_SCH_CTRL		(TMU_CSR_BASE_ADDR + 0x13c)	/**< [9:0] Scheduler Enable for each of the scheduler in the TDQ. This is a global Enable for all schedulers in PHY2 */
+#define TMU_TDQ3_SCH_CTRL		(TMU_CSR_BASE_ADDR + 0x140)	/**< [9:0] Scheduler Enable for each of the scheduler in the TDQ. This is a global Enable for all schedulers in PHY3 */
+#define TMU_BMU_BUF_SIZE		(TMU_CSR_BASE_ADDR + 0x144)
+#define TMU_PHY5_INQ_ADDR		(TMU_CSR_BASE_ADDR + 0x148)	/**< [31:0] PHY5 in queue address (must be initialized with one of the xxx_INQ_PKTPTR cbus addresses) */
+
+#define SW_RESET	(1 << 0)	/**< Global software reset */
+#define INQ_RESET	(1 << 2)
+#define TEQ_RESET	(1 << 3)
+#define TDQ_RESET	(1 << 4)
+#define PE_RESET	(1 << 5)
+#define MEM_INIT	(1 << 6)
+#define MEM_INIT_DONE	(1 << 7)
+#define LLM_INIT	(1 << 8)
+#define LLM_INIT_DONE	(1 << 9)
+#define ECC_MEM_INIT_DONE	(1<<10)
+
+typedef struct {
+	u32 pe_sys_clk_ratio;
+	unsigned long llm_base_addr;
+	u32 llm_queue_len;
+} TMU_CFG;
+
+/* Not HW related for pfe_ctrl / pfe common defines */
+#define DEFAULT_MAX_QDEPTH	80
+#define DEFAULT_Q0_QDEPTH	511 //We keep one large queue for host tx qos
+#define DEFAULT_TMU3_QDEPTH	127
+
+
+#endif /* _TMU_CSR_H_ */
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/include/pfe/cbus/util_csr.h
@@ -0,0 +1,61 @@
+/*
+ *  Copyright (c) 2011, 2014 Freescale Semiconductor, Inc.
+ *
+ *  This program is free software; you can redistribute it and/or
+ *  modify it under the terms of the GNU General Public License
+ *  as published by the Free Software Foundation; either version 2
+ *  of the License, or (at your option) any later version.
+ *
+ *  This program is distributed in the hope that it will be useful,
+ *  but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *  GNU General Public License for more details.
+ *
+ *  You should have received a copy of the GNU General Public License
+ *  along with this program; if not, write to the Free Software
+ *  Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
+ *
+*/
+#ifndef _UTIL_CSR_H_
+#define _UTIL_CSR_H_
+
+#define UTIL_VERSION			(UTIL_CSR_BASE_ADDR + 0x000)
+#define UTIL_TX_CTRL			(UTIL_CSR_BASE_ADDR + 0x004)
+#define UTIL_INQ_PKTPTR			(UTIL_CSR_BASE_ADDR + 0x010)
+
+#define UTIL_HDR_SIZE			(UTIL_CSR_BASE_ADDR + 0x014)
+
+#define UTIL_PE0_QB_DM_ADDR0		(UTIL_CSR_BASE_ADDR + 0x020)
+#define UTIL_PE0_QB_DM_ADDR1		(UTIL_CSR_BASE_ADDR + 0x024)
+#define UTIL_PE0_RO_DM_ADDR0		(UTIL_CSR_BASE_ADDR + 0x060)
+#define UTIL_PE0_RO_DM_ADDR1		(UTIL_CSR_BASE_ADDR + 0x064)
+
+#define UTIL_MEM_ACCESS_ADDR		(UTIL_CSR_BASE_ADDR + 0x100)
+#define UTIL_MEM_ACCESS_WDATA		(UTIL_CSR_BASE_ADDR + 0x104)
+#define UTIL_MEM_ACCESS_RDATA		(UTIL_CSR_BASE_ADDR + 0x108)
+
+#define UTIL_TM_INQ_ADDR		(UTIL_CSR_BASE_ADDR + 0x114)
+#define UTIL_PE_STATUS			(UTIL_CSR_BASE_ADDR + 0x118)
+
+#define UTIL_PE_SYS_CLK_RATIO		(UTIL_CSR_BASE_ADDR + 0x200)
+#define UTIL_AFULL_THRES		(UTIL_CSR_BASE_ADDR + 0x204)
+#define UTIL_GAP_BETWEEN_READS		(UTIL_CSR_BASE_ADDR + 0x208)
+#define UTIL_MAX_BUF_CNT		(UTIL_CSR_BASE_ADDR + 0x20c)
+#define UTIL_TSQ_FIFO_THRES		(UTIL_CSR_BASE_ADDR + 0x210)
+#define UTIL_TSQ_MAX_CNT		(UTIL_CSR_BASE_ADDR + 0x214)
+#define UTIL_IRAM_DATA_0		(UTIL_CSR_BASE_ADDR + 0x218)
+#define UTIL_IRAM_DATA_1		(UTIL_CSR_BASE_ADDR + 0x21c)
+#define UTIL_IRAM_DATA_2		(UTIL_CSR_BASE_ADDR + 0x220)
+#define UTIL_IRAM_DATA_3		(UTIL_CSR_BASE_ADDR + 0x224)
+
+#define UTIL_BUS_ACCESS_ADDR		(UTIL_CSR_BASE_ADDR + 0x228)
+#define UTIL_BUS_ACCESS_WDATA		(UTIL_CSR_BASE_ADDR + 0x22c)
+#define UTIL_BUS_ACCESS_RDATA		(UTIL_CSR_BASE_ADDR + 0x230)
+
+#define UTIL_INQ_AFULL_THRES		(UTIL_CSR_BASE_ADDR + 0x234)
+
+typedef struct {
+	u32 pe_sys_clk_ratio;
+} UTIL_CFG;
+
+#endif /* _UTIL_CSR_H_ */
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/include/pfe/class.h
@@ -0,0 +1,133 @@
+/*
+ *  Copyright (c) 2011, 2014 Freescale Semiconductor, Inc.
+ *
+ *  This program is free software; you can redistribute it and/or
+ *  modify it under the terms of the GNU General Public License
+ *  as published by the Free Software Foundation; either version 2
+ *  of the License, or (at your option) any later version.
+ *
+ *  This program is distributed in the hope that it will be useful,
+ *  but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *  GNU General Public License for more details.
+ *
+ *  You should have received a copy of the GNU General Public License
+ *  along with this program; if not, write to the Free Software
+ *  Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
+ *
+*/
+#ifndef _CLASS_H_
+#define _CLASS_H_
+
+#include "pe.h"
+
+#define CLASS_DMEM_BASE_ADDR	0x00000000
+#define CLASS_DMEM_SIZE		0x2000
+#define CLASS_DMEM_END		(CLASS_DMEM_BASE_ADDR + CLASS_DMEM_SIZE)
+#define CLASS_PMEM_BASE_ADDR	0x00010000
+
+#define CBUS_BASE_ADDR		0xc0000000
+#define CLASS_APB_BASE_ADDR	0xc1000000
+#define CLASS_AHB1_BASE_ADDR	0xc2000000
+#define CLASS_AHB2_BASE_ADDR	0xc3000000
+
+#include "cbus.h"
+
+#define GPT_BASE_ADDR		(CLASS_APB_BASE_ADDR + 0x00000)
+#define UART_BASE_ADDR		(CLASS_APB_BASE_ADDR + 0x10000)
+#define PERG_BASE_ADDR		(CLASS_APB_BASE_ADDR + 0x20000)
+#define EFET_BASE_ADDR		(CLASS_APB_BASE_ADDR + 0x40000)
+
+#define MAC_HASH_BASE_ADDR	(CLASS_AHB1_BASE_ADDR + 0x30000)
+#define VLAN_HASH_BASE_ADDR	(CLASS_AHB1_BASE_ADDR + 0x50000)
+
+#define PE_LMEM_BASE_ADDR	(CLASS_AHB2_BASE_ADDR + 0x10000)
+#define PE_LMEM_SIZE		0x8000
+#define PE_LMEM_END		(PE_LMEM_BASE_ADDR + PE_LMEM_SIZE)
+#define CCU_BASE_ADDR		(CLASS_AHB2_BASE_ADDR + 0x20000)
+
+#define IS_DMEM(addr, len)	(((unsigned long)(addr) >= CLASS_DMEM_BASE_ADDR) && (((unsigned long)(addr) + (len)) <= CLASS_DMEM_END))
+#define IS_PE_LMEM(addr, len)	(((unsigned long)(addr) >= PE_LMEM_BASE_ADDR) && (((unsigned long)(addr) + (len)) <= PE_LMEM_END))
+
+
+#include "gpt.h"
+#include "uart.h"
+#include "class/perg.h"
+#include "class/efet.h"
+#include "class/mac_hash.h"
+#include "class/vlan_hash.h"
+#include "class/ccu.h"
+
+
+#define CLASS_MAX_PBUFFERS	4
+
+#define PBUF_HWPARSE_OFFSET	0x10	/* Fixed by hardware */
+
+#define PAYLOAD_DMEM_MAX_SIZE	(CLASS_PBUF_SIZE - CLASS_PBUF_HEADER_OFFSET - sizeof(class_rx_hdr_t))
+
+
+#define MIN_PKT_SIZE		56
+
+#define PARSE_ETH_TYPE		(1 << 0)
+#define PARSE_VLAN_TYPE		(1 << 1)
+#define PARSE_PPPOE_TYPE	(1 << 2)
+#define PARSE_ARP_TYPE		(1 << 3)
+#define PARSE_MCAST_TYPE	(1 << 4)
+#define PARSE_IP_TYPE		(1 << 5)
+#define PARSE_IPV6_TYPE		(1 << 6)
+#define PARSE_IPV4_TYPE		(1 << 7)
+
+#define PARSE_IPX_TYPE		(1 << 9)
+
+#define PARSE_UDP_FLOW		(1 << 11)
+#define PARSE_TCP_FLOW		(1 << 12)
+#define PARSE_ICMP_FLOW		(1 << 13)
+#define PARSE_IGMP_FLOW		(1 << 14)
+#define PARSE_FRAG_FLOW		(1 << 15)
+
+#define PARSE_HIF_PKT		(1 << 23)
+#define PARSE_ARC_HIT		(1 << 24)
+#define PARSE_PKT_OVERFLOW	(1 << 25)
+
+#define PARSE_PROTO_MISMATCH	(1 << 28)
+#define PARSE_L3_MISMATCH	(1 << 29)
+#define PARSE_L2_MISMATCH	(1 << 30)
+#define PARSE_INCOMPLETE	(1 << 31)
+
+
+typedef struct _hwparse_t {
+	u16	sid;
+	u16	connid;
+	u8	toevec;
+	u8	pLayer2Hdr;
+	u8	pLayer3Hdr;
+	u8	pLayer4Hdr;
+	u16	vlanid;
+	u16	ifParseFlags;
+	u32	parseFlags;
+	u16	srcport;
+	u16	dstport;
+	u32	proto:8;
+	u32	port:4;
+	u32	hash:20;
+	u64	rte_res_valid:1;
+	u64	vlan_res_valid:1;
+	u64	dst_res_valid:1;
+	u64	src_res_valid:1;
+	u64	vlan_lookup:20;
+	u64	dst_lookup:20;
+	u64	src_lookup:20;
+} hwparse_t;
+
+
+typedef struct {
+	u8	num_cpy;	/* no of copies to send out from RO block, for each there must be a corresponding tx pre-header */
+	u8	dma_len;	/* len to be DMAed to DDR mem, including all tx pre-headers */
+	u16	src_addr;	/* class dmem source address, pointing to first tx pre-header */
+	u32	dst_addr;	/* DDR memory destination address of first tx pre-header, must be so packet data is continuous in DDR */
+	u32	res1;		/* reserved for software usage - queue number? */
+	u16	res2;		/* reserved for software usage */
+	u16	tsv;		/* time stamp val */
+} class_tx_desc_t;
+
+#endif /* _CLASS_H_ */
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/include/pfe/class/ccu.h
@@ -0,0 +1,28 @@
+/*
+ *  Copyright (c) 2011, 2014 Freescale Semiconductor, Inc.
+ *
+ *  This program is free software; you can redistribute it and/or
+ *  modify it under the terms of the GNU General Public License
+ *  as published by the Free Software Foundation; either version 2
+ *  of the License, or (at your option) any later version.
+ *
+ *  This program is distributed in the hope that it will be useful,
+ *  but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *  GNU General Public License for more details.
+ *
+ *  You should have received a copy of the GNU General Public License
+ *  along with this program; if not, write to the Free Software
+ *  Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
+ *
+*/
+#ifndef _CCU_H_
+#define _CCU_H_
+
+#define CCU_ADDR	(CCU_BASE_ADDR + 0x00)
+#define CCU_CNT		(CCU_BASE_ADDR + 0x04)
+#define CCU_STATUS	(CCU_BASE_ADDR + 0x08)
+#define CCU_VAL		(CCU_BASE_ADDR + 0x0c)
+
+#endif /* _CCU_H_ */
+
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/include/pfe/class/efet.h
@@ -0,0 +1,44 @@
+/*
+ *  Copyright (c) 2011, 2014 Freescale Semiconductor, Inc.
+ *
+ *  This program is free software; you can redistribute it and/or
+ *  modify it under the terms of the GNU General Public License
+ *  as published by the Free Software Foundation; either version 2
+ *  of the License, or (at your option) any later version.
+ *
+ *  This program is distributed in the hope that it will be useful,
+ *  but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *  GNU General Public License for more details.
+ *
+ *  You should have received a copy of the GNU General Public License
+ *  along with this program; if not, write to the Free Software
+ *  Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
+ *
+*/
+#ifndef _CLASS_EFET_H_
+#define _CLASS_EFET_H_
+
+//#define CLASS_EFET_ASYNC	1
+
+#define CLASS_EFET_ENTRY_ADDR		(EFET_BASE_ADDR + 0x00)
+#define CLASS_EFET_ENTRY_SIZE		(EFET_BASE_ADDR + 0x04)
+#define CLASS_EFET_ENTRY_DMEM_ADDR	(EFET_BASE_ADDR + 0x08)
+#define CLASS_EFET_ENTRY_STATUS		(EFET_BASE_ADDR + 0x0c)
+#define CLASS_EFET_ENTRY_ENDIAN		(EFET_BASE_ADDR + 0x10)
+
+#define CBUS2DMEM	0
+#define DMEM2CBUS	1
+
+#define EFET2BUS_LE     (1 << 0)
+#define PE2BUS_LE	(1 << 1)
+
+#ifdef CLASS_EFET_ASYNC
+void class_efet_async(u32 cbus_addr, u32 dmem_addr, u32 len, u32 dir);
+#endif
+
+void class_efet_sync(u32 cbus_addr, u32 dmem_addr, u32 len, u32 dir);
+
+
+#endif /* _CLASS_EFET_H_ */
+
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/include/pfe/class/mac_hash.h
@@ -0,0 +1,55 @@
+/*
+ *  Copyright (c) 2011, 2014 Freescale Semiconductor, Inc.
+ *
+ *  This program is free software; you can redistribute it and/or
+ *  modify it under the terms of the GNU General Public License
+ *  as published by the Free Software Foundation; either version 2
+ *  of the License, or (at your option) any later version.
+ *
+ *  This program is distributed in the hope that it will be useful,
+ *  but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *  GNU General Public License for more details.
+ *
+ *  You should have received a copy of the GNU General Public License
+ *  along with this program; if not, write to the Free Software
+ *  Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
+ *
+*/
+#ifndef _MAC_HASH_H_
+#define _MAC_HASH_H_
+
+#define MAC_HASH_REQ1_BASE_ADDR		(MAC_HASH_BASE_ADDR + 0x000)
+#define MAC_HASH_REQ2_BASE_ADDR		(MAC_HASH_BASE_ADDR + 0x020)
+#define MAC_HASH_REQ3_BASE_ADDR		(MAC_HASH_BASE_ADDR + 0x040)
+#define MAC_HASH_REQ4_BASE_ADDR		(MAC_HASH_BASE_ADDR + 0x060)
+#define MAC_HASH_REQ5_BASE_ADDR		(MAC_HASH_BASE_ADDR + 0x080)
+#define MAC_HASH_REQ6_BASE_ADDR		(MAC_HASH_BASE_ADDR + 0x0a0)
+#define MAC_HASH_REQ7_BASE_ADDR		(MAC_HASH_BASE_ADDR + 0x0c0)
+#define MAC_HASH_REQ8_BASE_ADDR		(MAC_HASH_BASE_ADDR + 0x0e0)
+
+#define MAC_HASH_REQ_CMD(i)		(MAC_HASH_REQ##i##_BASE_ADDR + 0x000)
+#define MAC_HASH_REQ_MAC1_ADDR(i)	(MAC_HASH_REQ##i##_BASE_ADDR + 0x004)
+#define MAC_HASH_REQ_MAC2_ADDR(i)	(MAC_HASH_REQ##i##_BASE_ADDR + 0x008)
+#define MAC_HASH_REQ_MASK1_ADDR(i)	(MAC_HASH_REQ##i##_BASE_ADDR + 0x00c)
+#define MAC_HASH_REQ_MASK2_ADDR(i)	(MAC_HASH_REQ##i##_BASE_ADDR + 0x010)
+#define MAC_HASH_REQ_ENTRY(i)		(MAC_HASH_REQ##i##_BASE_ADDR + 0x014)
+#define MAC_HASH_REQ_STATUS(i)		(MAC_HASH_REQ##i##_BASE_ADDR + 0x018)
+#define MAC_HASH_REQ_ENTRY_MAYCH(i)	(MAC_HASH_REQ##i##_BASE_ADDR + 0x01c)
+
+
+#define MAC_HASH_FREELIST_PTR_HEAD	(MAC_HASH_BASE_ADDR + 0x100)
+#define MAC_HASH_FREELIST_PTR_TAIL	(MAC_HASH_BASE_ADDR + 0x104)
+#define MAC_HASH_FREELIST_ENTRIES_ADDR	(MAC_HASH_BASE_ADDR + 0x108)
+
+
+#define HASH_CMD_INIT		1
+#define HASH_CMD_ADD		2
+#define HASH_CMD_DELETE		3
+#define HASH_CMD_UPDATE		4
+#define HASH_CMD_SEARCH		5
+#define HASH_CMD_MEM_READ	6
+#define HASH_CMD_MEM_WRITE	7
+
+#endif /* _MAC_HASH_H_ */
+
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/include/pfe/class/perg.h
@@ -0,0 +1,39 @@
+/*
+ *  Copyright (c) 2011, 2014 Freescale Semiconductor, Inc.
+ *
+ *  This program is free software; you can redistribute it and/or
+ *  modify it under the terms of the GNU General Public License
+ *  as published by the Free Software Foundation; either version 2
+ *  of the License, or (at your option) any later version.
+ *
+ *  This program is distributed in the hope that it will be useful,
+ *  but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *  GNU General Public License for more details.
+ *
+ *  You should have received a copy of the GNU General Public License
+ *  along with this program; if not, write to the Free Software
+ *  Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
+ *
+*/
+#ifndef _PERG_H_
+#define _PERG_H_
+
+#define PERG_QB_BUF_STATUS		(PERG_BASE_ADDR + 0x00)
+#define PERG_RO_BUF_STATUS		(PERG_BASE_ADDR + 0x04)
+#define PERG_CLR_QB_BUF_STATUS		(PERG_BASE_ADDR + 0x08)
+#define PERG_SET_RO_BUF_STATUS		(PERG_BASE_ADDR + 0x0c)
+#define PERG_CLR_RO_ERR_PKT		(PERG_BASE_ADDR + 0x10)
+#define PERG_CLR_BMU2_ERR_PKT		(PERG_BASE_ADDR + 0x14)
+
+#define PERG_ID				(PERG_BASE_ADDR + 0x18)
+#define PERG_TIMER1			(PERG_BASE_ADDR + 0x1c)
+//FIXME #define PERG_TIMER2			(PERG_BASE_ADDR + 0x20)
+#define PERG_BMU1_CURRDEPTH		(PERG_BASE_ADDR + 0x20)
+#define PERG_BMU2_CURRDEPTH		(PERG_BASE_ADDR + 0x24)
+#define PERG_HOST_GP			(PERG_BASE_ADDR + 0x2c)
+#define PERG_PE_GP			(PERG_BASE_ADDR + 0x30)
+#define PERG_INT_ENABLE			(PERG_BASE_ADDR + 0x34)
+#define PERG_INT_SRC			(PERG_BASE_ADDR + 0x38)
+
+#endif /* _PERG_H_ */
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/include/pfe/class/vlan_hash.h
@@ -0,0 +1,46 @@
+/*
+ *  Copyright (c) 2011, 2014 Freescale Semiconductor, Inc.
+ *
+ *  This program is free software; you can redistribute it and/or
+ *  modify it under the terms of the GNU General Public License
+ *  as published by the Free Software Foundation; either version 2
+ *  of the License, or (at your option) any later version.
+ *
+ *  This program is distributed in the hope that it will be useful,
+ *  but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *  GNU General Public License for more details.
+ *
+ *  You should have received a copy of the GNU General Public License
+ *  along with this program; if not, write to the Free Software
+ *  Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
+ *
+*/
+#ifndef _VLAN_HASH_H_
+#define _VLAN_HASH_H_
+
+#define VLAN_HASH_REQ1_BASE_ADDR	(VLAN_HASH_BASE_ADDR + 0x000)
+#define VLAN_HASH_REQ2_BASE_ADDR	(VLAN_HASH_BASE_ADDR + 0x020)
+#define VLAN_HASH_REQ3_BASE_ADDR	(VLAN_HASH_BASE_ADDR + 0x040)
+#define VLAN_HASH_REQ4_BASE_ADDR	(VLAN_HASH_BASE_ADDR + 0x060)
+#define VLAN_HASH_REQ5_BASE_ADDR	(VLAN_HASH_BASE_ADDR + 0x080)
+#define VLAN_HASH_REQ6_BASE_ADDR	(VLAN_HASH_BASE_ADDR + 0x0a0)
+#define VLAN_HASH_REQ7_BASE_ADDR	(VLAN_HASH_BASE_ADDR + 0x0c0)
+#define VLAN_HASH_REQ8_BASE_ADDR	(VLAN_HASH_BASE_ADDR + 0x0e0)
+
+#define VLAN_HASH_REQ_CMD(i)		(VLAN_HASH_REQ##i##_BASE_ADDR + 0x000)
+#define VLAN_HASH_REQ_MAC1_ADDR(i)	(VLAN_HASH_REQ##i##_BASE_ADDR + 0x004)
+#define VLAN_HASH_REQ_MAC2_ADDR(i)	(VLAN_HASH_REQ##i##_BASE_ADDR + 0x008)
+#define VLAN_HASH_REQ_MASK1_ADDR(i)	(VLAN_HASH_REQ##i##_BASE_ADDR + 0x00c)
+#define VLAN_HASH_REQ_MASK2_ADDR(i)	(VLAN_HASH_REQ##i##_BASE_ADDR + 0x010)
+#define VLAN_HASH_REQ_ENTRY(i)		(VLAN_HASH_REQ##i##_BASE_ADDR + 0x014)
+#define VLAN_HASH_REQ_STATUS(i)		(VLAN_HASH_REQ##i##_BASE_ADDR + 0x018)
+#define VLAN_HASH_REQ_ENTRY_MAYCH(i)	(VLAN_HASH_REQ##i##_BASE_ADDR + 0x01c)
+
+
+#define VLAN_HASH_FREELIST_PTR_HEAD	(VLAN_HASH_BASE_ADDR + 0x100)
+#define VLAN_HASH_FREELIST_PTR_TAIL	(VLAN_HASH_BASE_ADDR + 0x104)
+#define VLAN_HASH_FREELIST_ENTRIES_ADDR	(VLAN_HASH_BASE_ADDR + 0x108)
+
+#endif /* _VLAN_HASH_H_ */
+
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/include/pfe/gpt.h
@@ -0,0 +1,44 @@
+/*
+ *  Copyright (c) 2011, 2014 Freescale Semiconductor, Inc.
+ *
+ *  This program is free software; you can redistribute it and/or
+ *  modify it under the terms of the GNU General Public License
+ *  as published by the Free Software Foundation; either version 2
+ *  of the License, or (at your option) any later version.
+ *
+ *  This program is distributed in the hope that it will be useful,
+ *  but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *  GNU General Public License for more details.
+ *
+ *  You should have received a copy of the GNU General Public License
+ *  along with this program; if not, write to the Free Software
+ *  Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
+ *
+*/
+#ifndef _GPT_H_
+#define _GPT_H_
+
+#define GPT_VERSION		 (GPT_BASE_ADDR + 0x00)
+#define GPT_STATUS		 (GPT_BASE_ADDR + 0x04)
+#define GPT_CONFIG		 (GPT_BASE_ADDR + 0x08)
+#define GPT_COUNTER		 (GPT_BASE_ADDR + 0x0c)
+#define GPT_PERIOD		 (GPT_BASE_ADDR + 0x10)
+#define GPT_WIDTH		 (GPT_BASE_ADDR + 0x14)
+
+/*** These bits are defined for GPT_STATUS register */
+#define GPT_STAT_IRQ            (1<<0)
+#define GPT_STAT_OVERFLOW_ERR   (1<<4)
+#define GPT_STAT_TMR_ENABLE     (1<<8)
+#define GPT_STAT_TMR_DISABLE    (1<<9)
+
+/*** These bits are defined for GPT_CONFIG register */
+#define GPT_CONFIG_PWM_MODE             0x1
+#define GPT_CONFIG_WCAP_MODE            0x2
+#define GPT_CONFIG_CAP_PULSE_OUT        (1<<2)
+#define GPT_CONFIG_PERIOD_CNT           (1<<3)
+#define GPT_CONFIG_INTR_ENABLE          (1<<4)
+#define GPT_CONFIG_AUX_SEL              (1<<5)
+
+
+#endif /* _GPT_H_ */
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/include/pfe/pe.h
@@ -0,0 +1,626 @@
+/*
+ *  Copyright (c) 2011, 2014 Freescale Semiconductor, Inc.
+ *
+ *  This program is free software; you can redistribute it and/or
+ *  modify it under the terms of the GNU General Public License
+ *  as published by the Free Software Foundation; either version 2
+ *  of the License, or (at your option) any later version.
+ *
+ *  This program is distributed in the hope that it will be useful,
+ *  but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *  GNU General Public License for more details.
+ *
+ *  You should have received a copy of the GNU General Public License
+ *  along with this program; if not, write to the Free Software
+ *  Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
+ *
+*/
+#ifndef _PE_H_
+#define _PE_H_
+
+#include "hal.h"
+
+#if defined(COMCERTO_2000_CLASS)
+#include "pfe/class.h"
+#elif defined(COMCERTO_2000_TMU)
+#include "pfe/tmu.h"
+#elif defined(COMCERTO_2000_UTIL)
+#include "pfe/util.h"
+#endif
+
+enum {
+	CLASS0_ID = 0,
+	CLASS1_ID,
+	CLASS2_ID,
+	CLASS3_ID,
+	CLASS4_ID,
+	CLASS5_ID,
+	TMU0_ID,
+	TMU1_ID,
+	TMU2_ID,
+	TMU3_ID,
+	UTIL_ID,
+	MAX_PE
+};
+#define PE_ID_ANY MAX_PE
+
+/* Hardware definition of physical ports */
+/* CLASS rx header phy number */
+enum CLASS_RX_PHY {
+	RX_PHY_0 = 0x0,
+	RX_PHY_1,
+	RX_PHY_2,
+	RX_PHY_HIF,
+	RX_PHY_HIF_NOCPY,
+	RX_PHY_CLASS = 1 << 14, /**< Control bit (in PHYNO field) used to inform CLASS PE that packet comes from Class. */
+	RX_PHY_UTIL = 1 << 15 /**< Control bit (in PHYNO field) used to inform CLASS PE that packet comes from UtilPE. */
+};
+
+#define RX_PHY_SW_INPUT_PORT_OFFSET		11	/**< Offset in PHYNO field where the original input port will be stored for packets coming directly from software (UtilPE or Class). */
+
+
+/* CLASS/TMU tx header phy number */
+enum TMU_TX_PHY {
+	TX_PHY_TMU0 = 0x0,
+	TX_PHY_TMU1,
+	TX_PHY_TMU2,
+	TX_PHY_TMU3
+};
+
+
+// NOTE: Any changes to the following drop counter definitions must also
+//	be reflected in the pfe/pfe.h file and in pfe_ctrl/pfe_sysfs.c.
+
+#if defined(COMCERTO_2000_CLASS)
+
+#define	CLASS_DROP_ICC			0
+#define	CLASS_DROP_HOST_PKT_ERROR	1
+#define	CLASS_DROP_RX_ERROR		2
+#define	CLASS_DROP_IPSEC_OUT		3
+#define	CLASS_DROP_IPSEC_IN		4
+#define	CLASS_DROP_EXPT_IPSEC		5
+#define	CLASS_DROP_REASSEMBLY		6
+#define	CLASS_DROP_FRAGMENTER		7
+#define	CLASS_DROP_NATT			8
+#define	CLASS_DROP_SOCKET		9
+#define	CLASS_DROP_MULTICAST		10
+#define	CLASS_DROP_NATPT		11
+#define	CLASS_DROP_TX_DISABLE		12
+
+#define	CLASS_NUM_DROP_COUNTERS		13
+
+extern U32 drop_counter[CLASS_NUM_DROP_COUNTERS];
+#define	DROP_PACKET(pmtd, counter) free_packet(pmtd, CLASS_DROP_##counter)
+#define DROP_BUFFER(addr, counter) free_buffer(addr, CLASS_DROP_##counter)
+
+#elif defined(COMCERTO_2000_UTIL)
+
+#define	UTIL_DROP_IPSEC_OUT		0
+#define	UTIL_DROP_IPSEC_IN		1
+#define	UTIL_DROP_IPSEC_RATE_LIMIT	2
+#define	UTIL_DROP_FRAGMENTER		3
+#define	UTIL_DROP_SOCKET		4
+#define	UTIL_DROP_TX_DISABLE		5
+#define	UTIL_DROP_RX_ERROR		6
+#define	UTIL_DROP_NO_MTD		7
+
+#define	UTIL_NUM_DROP_COUNTERS		8
+
+extern U32 drop_counter[UTIL_NUM_DROP_COUNTERS];
+#define	DROP_PACKET(pmtd, counter) free_packet(pmtd, UTIL_DROP_##counter)
+#define DROP_BUFFER(addr, counter) free_buffer(addr, UTIL_DROP_##counter)
+
+#endif
+
+
+
+#define DDR_BASE_ADDR		0x00020000
+#define DDR_END			0x86000000 /* This includes ACP and IRAM areas */
+#define IRAM_BASE_ADDR		0x83000000
+
+#define IS_DDR(addr, len)	(((unsigned long)(addr) >= DDR_BASE_ADDR) && (((unsigned long)(addr) + (len)) <= DDR_END))
+/* action bits of act_phyno is defined as follows */
+
+#define ACT_SRC_MAC_REPLACE     (1 << (4 + 0))
+#define ACT_VLAN_ADD            (1 << (4 + 1))
+#define ACT_TCPCHKSUM_REPLACE   (1 << (4 + 2))
+#define ACT_VLAN_REPLACE        (1 << (4 + 3))
+#define ACT_DONT_FREE_BUFFER    (1 << (4 + 5))
+#define ACT_IPCHKSUM_REPLACE    (1 << (4 + 6))
+
+typedef struct {
+	u8	start_data_off;		/* packet data start offset, relative to start of this tx pre-header */
+	u8	start_buf_off;		/* this tx pre-header start offset, relative to start of DDR buffer */
+	u16	pkt_length;		/* total packet length */
+	u8	act_phyno;		/* action / phy number */
+	u8	queueno;		/* queueno */
+	u16	unused;
+} class_tx_hdr_t;
+
+typedef struct {
+	u8	start_data_off;		/* packet data start offset, relative to start of this tx pre-header */
+	u8	start_buf_off;		/* this tx pre-header start offset, relative to start of DDR buffer */
+	u16	pkt_length;		/* total packet length */
+	u8	act_phyno;		/* action / phy number */
+	u8	queueno;		/* queueno */
+	u16	src_mac_msb;		/* indicates src_mac 47:32 */
+	u32	src_mac_lsb;		/* indicates src_mac 31:0 */
+	u32	vlanid;			/* vlanid */
+} class_tx_hdr_mc_t;
+
+typedef struct {
+        u32     next_ptr;       /* ptr to the start of the first DDR buffer */
+        u16     length;         /* total packet length */
+        u16     phyno;          /* input physical port number */
+        u32     status;         /* gemac status bits bits[32:63]*/
+        u32     status2;        /* gemac status bits bits[0:31] */
+} class_rx_hdr_t;
+/* class_rx_hdr status bits  (status0 bits in hardware blocks)
+ * from hif_top/dma_dxr_dtx.v
+ * STATUS[9:0] is the encoding of bits in the LMEM buffer as seen by the QB block,
+ * NOT the encoding of bits as seen by the Class PEs in the DMEM rx header */
+#define STATUS_PARSE_DISABLE		(1 << 0)
+#define STATUS_BRFETCH_DISABLE		(1 << 1)
+#define STATUS_RTFETCH_DISABLE		(1 << 2)
+#define STATUS_DIR_PROC_ID		(1 << 3)
+#define STATUS_CONN_ID_EN		(1 << 4))
+#define STATUS_PE2PROC_ID(x)		(((x) & 7) << 5)
+#define STATUS_LE_DATA			(1 << 8)
+#define STATUS_CHKSUM_EN		(1 << 9)
+
+/* from gpi/gpi_rmlf.v */
+#define STATUS_CUMULATIVE_ERR		(1 << 16)
+#define STATUS_LENGTH_ERR		(1 << 17)
+#define STATUS_CRC_ERR			(1 << 18)
+#define STATUS_TOO_SHORT_ERR		(1 << 19)
+#define STATUS_TOO_LONG_ERR		(1 << 20)
+#define STATUS_CODE_ERR			(1 << 21)
+#define STATUS_MC_HASH_MATCH		(1 << 22)
+#define STATUS_CUMULATIVE_ARC_HIT	(1 << 23)
+#define STATUS_UNICAST_HASH_MATCH	(1 << 24)
+#define STATUS_IP_CHECKSUM_CORRECT	(1 << 25)
+#define STATUS_TCP_CHECKSUM_CORRECT	(1 << 26)
+#define STATUS_UDP_CHECKSUM_CORRECT	(1 << 27)
+#define STATUS_OVERFLOW_ERR		(1 << 28)
+
+#define UTIL_MAGIC_NUM	0xffd8ffe000104a46
+#define UTIL_DDRC_WA
+
+/* The following structure is filled by class-pe when the packet
+ * has to be sent to util-pe, by filling the required information */
+typedef struct {
+	u32 mtd_flags : 16;
+	u32 packet_type : 8;
+	u32 input_port : 4;
+	u32 data_offset : 4;
+	u32 word[MTD_PRIV];
+#ifdef UTIL_DDRC_WA
+	u64 magic_num; // magic_number to verify the data validity in utilpe
+#endif
+} __attribute__((aligned(8))) util_rx_hdr_t; // Size must be a multiple of 64-bit to allow copies using EFET.
+
+#define UTIL_RX_IPS_IN_PKT		EVENT_IPS_IN
+#define UTIL_RX_IPS_OUT_PKT		EVENT_IPS_OUT
+#define UTIL_RX_RTP_PKT			EVENT_RTP_RELAY
+#define UTIL_RX_RTP_QOS_PKT		EVENT_RTP_QOS
+#define UTIL_RX_FRAG4_PKT		EVENT_FRAG4
+#define UTIL_RX_FRAG6_PKT		EVENT_FRAG6
+
+/** Structure passed from UtilPE to Class, stored at the end of the LMEM buffer. Defined and used by software only.
+ *
+ */
+
+typedef struct
+{
+	void *next;
+	u16 next_length;
+	u8 next_l3offset;
+	u8 next_l4offset;
+} frag_info;
+
+typedef struct {
+	u8 packet_type	: 6;
+	u8 padding	: 2;
+
+	u8 offset	: 3;
+	u8 ddr_offset	: 5;
+
+	u16 mtd_flags;
+	union {
+		u16 half[6];
+		u8 byte[12];
+
+		struct {
+			u16 sa_handle[2]; // SA_MAX_OP value should be used here instead of 2
+			u8 proto;
+			S8 sa_op;
+			u8 l2hdr_len;
+			u8 adj_dmem;
+		} ipsec;
+
+		struct {
+			u16 l4offset;
+			u16 socket_id;
+			BOOL update;
+			u8 reserved;
+			u32 payload_diff;
+		} relay;
+
+		struct {
+			u16 l3offset;
+			u16 l4offset;
+
+			frag_info frag;
+		} ipv6;
+
+		struct {
+			u16 l3offset;
+		} ipv4;
+
+		struct {
+			u32 ddr_addr;
+			u16 length;
+			u8 port;
+			u8 queue;
+			u8 action;
+		} tx;
+	};
+} lmem_trailer_t;
+
+/* The following values are defined for packet_type of lmem_trailer_t.
+ * These represent different types of packets sent from util to class
+ * for processing */
+enum {
+	UTIL_TX_IPS_IN = 0,
+	UTIL_TX_IPV4_RTP_PKT,
+	UTIL_TX_IPV6_RTP_PKT,
+	UTIL_TX_IPV4_PKT,
+	UTIL_TX_IPV6_PKT,
+	UTIL_TX_EXPT_PKT,
+#ifdef CFG_PCAP
+	UTIL_TX_PKT,
+#endif
+	UTIL_TX_MAX_PKT
+};
+
+
+#define UTIL_TX_TRAILER_SIZE	sizeof(lmem_trailer_t)
+#define UTIL_TX_TRAILER(mtd)	((lmem_trailer_t *)ROUND_UP32((u32)(mtd)->rx_dmem_end))
+
+typedef struct {
+	u32 pkt_ptr;
+	u8  phyno;
+	u8  queueno;
+	u16 len;
+} tmu_tx_hdr_t;
+
+struct hif_pkt_hdr {		
+	u8	client_id;
+	u8	qNo;
+	u16	client_ctrl_le_lsw;
+	u16	client_ctrl_le_msw;
+};
+
+
+#if defined(CFG_WIFI_OFFLOAD)
+#define	MAX_WIFI_VAPS	3
+#define PFE_WIFI_PKT_HEADROOM	96 /*PFE inserts this headroom for WiFi tx packets only in lro mode */
+#else
+#define	MAX_WIFI_VAPS	0
+#endif
+
+/* HIF header client id */
+enum HIF_CLIENT_ID {
+	CLIENT_ID_GEM0 = 0,
+	CLIENT_ID_GEM1,
+	CLIENT_ID_GEM2,
+	CLIENT_ID_WIFI0,
+	CLIENT_ID_WIFI_LAST = MAX_WIFI_VAPS + CLIENT_ID_GEM2,
+	CLIENT_ID_PCAP,
+	CLIENT_ID_UNKNOWN = 0xff,
+};
+
+
+#define IS_WIFI_CLIENT_ID(_clid) (((_clid) >= CLIENT_ID_WIFI0) && ((_clid) <= CLIENT_ID_WIFI_LAST))
+
+/* These match LE definition */
+#define HIF_CTRL_TX_TSO_NOCPY		__cpu_to_le32(1 << 8)
+#define HIF_CTRL_TX_IPSEC_OUT		__cpu_to_le32(1 << 7)
+#define HIF_CTRL_TX_WIFI_OWNMAC		__cpu_to_le32(1 << 6)
+#define HIF_CTRL_TX_TSO_END		__cpu_to_le32(1 << 5)
+#define HIF_CTRL_TX_TSO6		__cpu_to_le32(1 << 4)
+#define HIF_CTRL_TX_TSO			__cpu_to_le32(1 << 3)
+#define HIF_CTRL_TX_CHECKSUM		__cpu_to_le32(1 << 2)
+#define HIF_CTRL_TX_CSUM_VALIDATE	__cpu_to_le32(1 << 1)
+#define HIF_CTRL_TX_WIFI_TXOFLD		__cpu_to_le32(1 << 0)
+
+#define HIF_CTRL_RX_OFFSET_MASK		__cpu_to_le32(0xf << 24)
+#define HIF_CTRL_RX_PE_ID_MASK		__cpu_to_le32(0xf << 16)
+#define HIF_CTRL_RX_IPSEC_IN		__cpu_to_le32(1 << 4)
+#define HIF_CTRL_RX_WIFI_EXPT		__cpu_to_le32(1 << 3)
+#define HIF_CTRL_RX_CHECKSUMMED		__cpu_to_le32(1 << 2)
+#define HIF_CTRL_RX_CONTINUED		__cpu_to_le32(1 << 1)
+#define HIF_CTRL_RX_WIFI_HEADROOM	__cpu_to_le32(1 << 0)
+
+#ifdef CFG_LRO
+struct hif_lro_hdr {
+	u16 data_offset;
+	u16 mss;
+};
+#endif
+
+struct hif_ipsec_hdr {
+	u16 sa_handle[2];
+};
+
+#define MAX_TSO_BUF_DESCS 5
+struct hif_tso_buf_desc {
+	u32     addr;
+	u32     ctrl;
+#define TSO_CTRL_LAST_BUFFER (1 << 31)
+};
+
+struct hif_tso_hdr {
+	u16 ip_off;
+	u16 ip_id;
+	u16 ip_len;
+	u16 tcp_off;
+	u32 tcp_seq;
+};
+
+struct hif_tso_hdr_nocpy {
+	u16 ip_off;
+	u16 ip_id;
+	u16 ip_len;
+	u16 tcp_off;
+	u32 tcp_seq;
+	struct hif_tso_buf_desc bdesc[MAX_TSO_BUF_DESCS];
+};
+
+struct hif_pcap_hdr {
+        u8      ifindex;
+        u8      unused;
+        u16     seqno;
+        u32     timestamp;
+};
+
+
+struct pe_sync_mailbox
+{
+	u32 stop;
+	u32 stopped;
+};
+
+struct pe_msg_mailbox
+{
+	u32 dst;
+	u32 src;
+	u32 len;
+	u32 request;
+};
+
+
+/** Basic busy loop delay function
+*
+* @param cycles		Number of cycles to delay (actual cpu cycles should be close to 3 x cycles)
+*
+*/
+static inline void delay(u32 cycles)
+{
+	volatile int i;
+
+	for (i = 0; i < cycles; i++);
+}
+
+
+/** Read PE id
+*
+* @return	PE id (0 - 5 for CLASS-PE's, 6 - 9 for TMU-PE's, 10 for UTIL-PE)
+*
+*/
+static inline u32 esi_get_mpid(void)
+{
+	u32 mpid;
+
+	asm ("rcsr %0, Configuration, MPID" : "=d" (mpid));
+
+	return mpid;
+}
+
+
+#define esi_get_csr(bank, csr) \
+({ \
+	u32 res; \
+	asm ("rcsr %0, " #bank ", " #csr : "=d" (res)); \
+	res; \
+})
+
+#define esi_get_isa0() esi_get_csr(Configuration, ISA0)
+#define esi_get_isa1() esi_get_csr(Configuration, ISA1)
+#define esi_get_isa2() esi_get_csr(Configuration, ISA2)
+#define esi_get_isa3() esi_get_csr(Configuration, ISA3)
+#define esi_get_epc() esi_get_csr(Thread, EPC)
+#define esi_get_ecas() esi_get_csr(Thread, ECAS)
+#define esi_get_eid() esi_get_csr(Thread, EID)
+#define esi_get_ed() esi_get_csr(Thread, ED)
+
+static inline void esi_pe_stop(U32 state)
+{
+	PESTATUS_SETSTATE(state);
+	while (1)
+	{
+		asm("stop");
+	}
+}
+
+
+/** Same 64bit alignment memory copy using efet.
+* Either the source or destination address must be in DMEM, the other address can be in LMEM or DDR.
+* Both the source and destination must have the same 64bit alignment, length should be more than four bytes
+* or dst/src must be 32bit aligned. Otherwise use efet_memcpy_any()
+* Uses efet synchronous interface to copy the data.
+*
+* @param dst	Destination address to write to (must have the same 64bit alignment as src)
+* @param src	Source address to read from (must have the same 64bit alignment as dst)
+* @param len	Number of bytes to copy
+*
+*/
+void efet_memcpy(void *dst, void *src, unsigned int len);
+
+/** Same 64bit alignment memory copy using efet.
+* Either the source or destination address must be in DMEM, the other address can be in LMEM or DDR.
+* Both the source and destination must have the same 64bit alignment, there is no restriction on length.
+* For UTIL-PE revA0, this function will still fail to handle small/unaligned writes.
+* Uses efet synchronous interface to copy the data.
+*
+* @param dst	Destination address to write to (must have the same 64bit alignment as src)
+* @param src	Source address to read from (must have the same 64bit alignment as dst)
+* @param len	Number of bytes to copy
+*
+*/
+void efet_memcpy_any(void *dst, void *src, unsigned int len);
+
+/** Same 64bit alignment memory copy using efet.
+* Either the source or destination address must be in DMEM, the other address can be in LMEM or DDR.
+* Both the source and destination must have the same 64bit alignment, length should be more than four bytes
+* or dst/src must be 32bit aligned.
+* Uses efet asynchronous interface to copy the data.
+*
+* @param dst	Destination address to write to (must have the same 64bit alignment as src)
+* @param src	Source address to read from (must have the same 64bit alignment as dst)
+* @param len	Number of bytes to copy
+*
+*/
+void efet_memcpy_nowait(void *dst, void *src, unsigned int len);
+
+/** Unaligned memory copy using efet.
+* Either the source or destination address must be in DMEM, the other address can be in LMEM or DDR.
+* There is not restriction on source and destination, nor on length.
+*
+* @param dst		Destination address to write to
+* @param src		Source address to read from
+* @param len		Number of bytes to copy
+* @param dmem_buf	temp dmem buffer to use, must be 64bit aligned
+* @param dmem_len	length of dmem buffer, must be 64bit aligned and at least 16 bytes
+*
+*/
+void efet_memcpy_unaligned(void *dst, void *src, unsigned int len, void *dmem_buf, unsigned int dmem_len);
+
+/** Aligned memory copy of 4 bytes to register address.
+* Register address must be 32 bit aligned.
+*
+* @param val		value to be copied.       
+* @param reg_addr	Register address (must be 16bit aligned)
+*
+*/
+void __efet_writel(u32 val, void *addr);
+
+#ifdef REVA_WA
+#define efet_writel(val, addr)	__efet_writel((u32)(val), (void *) (addr))
+#else
+#define efet_writel(val, addr)	writel((u32)(val), (void *) (addr))
+#endif
+
+
+/** 32bit aligned memory copy.
+* Source and destination addresses must be 32bit aligned, there is no restriction on the length.
+*
+* @param dst		Destination address (must be 32bit aligned)
+* @param src		Source address (must be 32bit aligned)
+* @param len		Number of bytes to copy
+*
+*/
+void memcpy_aligned32(void *dst, void *src, unsigned int len);
+
+/** Aligned memory copy.
+* Source and destination addresses must have the same alignment
+* relative to 32bit boundaries (but otherwsie may have any alignment),
+* there is no restriction on the length.
+*
+* @param dst		Destination address
+* @param src		Source address (must have same 32bit alignment as dst)
+* @param len		Number of bytes to copy
+*
+*/
+void memcpy_aligned(void *dst, void *src, unsigned int len);
+
+/** Unaligned memory copy.
+* Implements unaligned memory copy. We first align the destination
+* to a 32bit boundary (using byte copies) then the src, and finally use a loop
+* of read, shift, write
+*
+* @param dst		Destination address
+* @param src		Source address (must have same 32bit alignment as dst)
+* @param len		Number of bytes to copy
+*
+*/
+void memcpy_unaligned(void *dst, void *src, unsigned int len);
+
+/** Generic memory set.
+* Implements a generic memory set. Not very optimal (uses byte writes for the entire range)
+*
+*
+* @param dst		Destination address
+* @param val		Value to set memory to
+* @param len		Number of bytes to set
+*
+*/
+void memset(void *dst, u8 val, unsigned int len);
+
+/** Generic memory copy.
+* Implements generic memory copy. If source and destination have the same
+* alignment memcpy_aligned() is used, otherwise memcpy_unaligned()
+*
+* @param dst		Destination address
+* @param src		Source address
+* @param len		Number of bytes to copy
+*
+*/
+void memcpy(void *dst, void *src, unsigned int len);
+
+/** Generic memorymove.
+* Implements generic memorymove, where copies across overlapping
+* memory regions is supported.
+* Uses the dmem_buf passed as a parameter as a temporary buffer.
+* Includes two copies, forces one of the copies to be definitely aligned.
+* The "dmem_len" being passed should be atleast 3 bytes greater than "len"
+* The 3 bytes here are shift bytes used to ensure one aligned copy.
+*
+* @param dst		Destination address
+* @param src		Source address
+* @param len		Number of bytes to copy
+* @param dmem_buf	temp dmem buffer to use, must be 32bit aligned
+* @param dmem_len	length of dmem buffer, must be 32bit aligned and at least 3 bytes greater
+*			than @param len
+*
+*/
+
+void *memorymove(void * dst, void * src, unsigned int len, void *dmem_buf, unsigned int dmem_len);
+
+/** Aligned memory copy in DDR memory.
+ * Implements aligned memory copy between two DDR buffers using efet_memcpy64 and DMEM
+ * Both the source and destination must have the same 64bit alignment, there is no restriction on length.
+ * If start or end are not 64bit aligned, data in destination buffer before start/after end will be corrupted.
+ *
+ * @param dst 		DDR Destination address
+ * @param src		DDR Source address
+ * @param len		Number of bytes to copy
+ * @param dmem_buf	temp dmem buffer to use, must be 64bit aligned
+ * @param dmem_len	length of dmem buffer, must be 64bit aligned and at least 16 bytes
+ */
+void memcpy_ddr_to_ddr(void *dst, void *src, unsigned int len, void *dmem_buf, unsigned int dmem_len);
+
+/** Unaligned memory copy in DDR memory.
+ * Implements generic memory copy between two DDR buffers using efet_memcpy and DMEM
+ * There is no restriction on the source, destination and length alignments.
+ *
+ * @param dst 		DDR Destination address
+ * @param src		DDR Source address
+ * @param len		Number of bytes to copy
+ * @param dmem_buf	temp dmem buffer to use, must be 64bit aligned
+ * @param dmem_len	length of dmem buffer, must be 64bit aligned and at least 16 bytes
+ */
+void memcpy_ddr_to_ddr_unaligned(void *dst, void *src, unsigned int len, void *dmem_buf, unsigned int dmem_len);
+
+#endif /* _PE_H_ */
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/include/pfe/pfe.h
@@ -0,0 +1,444 @@
+/*
+ *  Copyright (c) 2011, 2014 Freescale Semiconductor, Inc.
+ *
+ *  This program is free software; you can redistribute it and/or
+ *  modify it under the terms of the GNU General Public License
+ *  as published by the Free Software Foundation; either version 2
+ *  of the License, or (at your option) any later version.
+ *
+ *  This program is distributed in the hope that it will be useful,
+ *  but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *  GNU General Public License for more details.
+ *
+ *  You should have received a copy of the GNU General Public License
+ *  along with this program; if not, write to the Free Software
+ *  Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
+ *
+*/
+#ifndef _PFE_H_
+#define _PFE_H_
+
+#define CLASS_DMEM_BASE_ADDR(i)	(0x00000000 | ((i) << 20))
+#define CLASS_IMEM_BASE_ADDR(i)	(0x00000000 | ((i) << 20)) /* Only valid for mem access register interface */
+#define CLASS_DMEM_SIZE		0x00002000
+#define CLASS_IMEM_SIZE		0x00008000
+
+#define TMU_DMEM_BASE_ADDR(i)	(0x00000000 + ((i) << 20))
+#define TMU_IMEM_BASE_ADDR(i)	(0x00000000 + ((i) << 20)) /* Only valid for mem access register interface */
+#define TMU_DMEM_SIZE		0x00000800
+#define TMU_IMEM_SIZE		0x00002000
+
+#define UTIL_DMEM_BASE_ADDR	0x00000000
+#define UTIL_DMEM_SIZE		0x00002000
+
+#define PE_LMEM_BASE_ADDR	0xc3010000
+#define PE_LMEM_SIZE		0x8000
+#define PE_LMEM_END		(PE_LMEM_BASE_ADDR + PE_LMEM_SIZE)
+
+#define DMEM_BASE_ADDR		0x00000000
+#define DMEM_SIZE		0x2000		/**< TMU has less... */
+#define DMEM_END		(DMEM_BASE_ADDR + DMEM_SIZE)
+
+#define PMEM_BASE_ADDR		0x00010000
+#define PMEM_SIZE		0x8000		/**< TMU has less... */
+#define PMEM_END		(PMEM_BASE_ADDR + PMEM_SIZE)
+
+
+/* These check memory ranges from PE point of view/memory map */
+#define IS_DMEM(addr, len)	(((unsigned long)(addr) >= DMEM_BASE_ADDR) && (((unsigned long)(addr) + (len)) <= DMEM_END))
+#define IS_PMEM(addr, len)	(((unsigned long)(addr) >= PMEM_BASE_ADDR) && (((unsigned long)(addr) + (len)) <= PMEM_END))
+#define IS_PE_LMEM(addr, len)	(((unsigned long)(addr) >= PE_LMEM_BASE_ADDR) && (((unsigned long)(addr) + (len)) <= PE_LMEM_END))
+
+#define IS_PFE_LMEM(addr, len)	(((unsigned long)(addr) >= CBUS_VIRT_TO_PFE(LMEM_BASE_ADDR)) && (((unsigned long)(addr) + (len)) <= CBUS_VIRT_TO_PFE(LMEM_END)))
+#define __IS_PHYS_DDR(addr, len)	(((unsigned long)(addr) >= DDR_PHYS_BASE_ADDR) && (((unsigned long)(addr) + (len)) <= DDR_PHYS_END))
+#define IS_PHYS_DDR(addr, len)	__IS_PHYS_DDR(DDR_PFE_TO_PHYS(addr), len)
+
+/* If using a run-time virtual address for the cbus base address use this code */
+extern void *cbus_base_addr;
+extern void *ddr_base_addr;
+extern unsigned long ddr_phys_base_addr;
+extern unsigned int ddr_size;
+
+#if defined(COMCERTO_2000_CONTROL)
+#include <linux/version.h>
+#if defined (CONFIG_PLATFORM_C2000)
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,6,0)
+/*This is copied from arch/arm/include/asm/system_info.h */
+extern unsigned int system_rev;
+#endif
+#endif
+#endif
+
+#define CBUS_BASE_ADDR		cbus_base_addr
+#define DDR_PHYS_BASE_ADDR	ddr_phys_base_addr
+#define DDR_BASE_ADDR		ddr_base_addr
+#define DDR_SIZE		ddr_size
+
+#define DDR_PHYS_END	(DDR_PHYS_BASE_ADDR + DDR_SIZE)
+
+#if defined(CONFIG_PLATFORM_C2000)
+#define PFE_CBUS_PHYS_BASE_ADDR	0xc0000000	/**< CBUS physical base address as seen by PE's. */
+#define DDR_PHYS_TO_PFE(p)	(p)
+#define DDR_PFE_TO_PHYS(p)	(p)
+#define CBUS_PHYS_TO_PFE(p)	(p)
+#else
+#define LS1012A_PFE_RESET_WA	/*PFE doesn't have global reset and re-init should takecare few things to make PFE functional after reset */
+#define PFE_CBUS_PHYS_BASE_ADDR	0xc0000000	/**< CBUS physical base address as seen by PE's. */
+#define PFE_CBUS_PHYS_BASE_ADDR_FROM_PFE	0xc0000000	/**< CBUS physical base address as seen by PE's. */
+#define DDR_PHYS_TO_PFE(p)	(((unsigned long int) (p)) & 0x7FFFFFFF)
+#define DDR_PFE_TO_PHYS(p)	(((unsigned long int) (p)) | 0x80000000)
+#define CBUS_PHYS_TO_PFE(p)	(((p) - PFE_CBUS_PHYS_BASE_ADDR) + PFE_CBUS_PHYS_BASE_ADDR_FROM_PFE) /*Translates to PFE address map */
+#endif
+
+#define DDR_PHYS_TO_VIRT(p)	(((p) - DDR_PHYS_BASE_ADDR) + DDR_BASE_ADDR)
+#define DDR_VIRT_TO_PHYS(v)	(((v) - DDR_BASE_ADDR) + DDR_PHYS_BASE_ADDR)
+#define DDR_VIRT_TO_PFE(p)	(DDR_PHYS_TO_PFE(DDR_VIRT_TO_PHYS(p)))
+
+#define CBUS_VIRT_TO_PFE(v)	(((v) - CBUS_BASE_ADDR) + PFE_CBUS_PHYS_BASE_ADDR)
+#define CBUS_PFE_TO_VIRT(p)	(((p) - PFE_CBUS_PHYS_BASE_ADDR) + CBUS_BASE_ADDR)
+
+/* The below part of the code is used in QOS control driver from host */
+#define TMU_APB_BASE_ADDR       0xc1000000      /** TMU base address seen by pe's */
+
+#define SHAPER0_BASE_ADDR       (TMU_APB_BASE_ADDR + 0x020000)
+#define SHAPER1_BASE_ADDR       (TMU_APB_BASE_ADDR + 0x030000)
+#define SHAPER2_BASE_ADDR       (TMU_APB_BASE_ADDR + 0x040000)
+#define SHAPER3_BASE_ADDR       (TMU_APB_BASE_ADDR + 0x050000)
+#define SHAPER4_BASE_ADDR       (TMU_APB_BASE_ADDR + 0x060000)
+#define SHAPER5_BASE_ADDR       (TMU_APB_BASE_ADDR + 0x070000)
+#define SHAPER6_BASE_ADDR       (TMU_APB_BASE_ADDR + 0x080000)
+#define SHAPER7_BASE_ADDR       (TMU_APB_BASE_ADDR + 0x090000)
+#define SHAPER8_BASE_ADDR       (TMU_APB_BASE_ADDR + 0x0a0000)
+#define SHAPER9_BASE_ADDR       (TMU_APB_BASE_ADDR + 0x0b0000)
+
+#define SCHED0_BASE_ADDR        (TMU_APB_BASE_ADDR + 0x1c0000)
+#define SCHED1_BASE_ADDR        (TMU_APB_BASE_ADDR + 0x1d0000)
+#define SCHED2_BASE_ADDR        (TMU_APB_BASE_ADDR + 0x1e0000)
+#define SCHED3_BASE_ADDR        (TMU_APB_BASE_ADDR + 0x1f0000)
+#define SCHED4_BASE_ADDR        (TMU_APB_BASE_ADDR + 0x200000)
+#define SCHED5_BASE_ADDR        (TMU_APB_BASE_ADDR + 0x210000)
+#define SCHED6_BASE_ADDR        (TMU_APB_BASE_ADDR + 0x220000)
+#define SCHED7_BASE_ADDR        (TMU_APB_BASE_ADDR + 0x230000)
+
+#define PHY_QUEUE_BASE_ADDR     (TMU_APB_BASE_ADDR + 0x260000)
+#define QUEUE_RESULT0           (PHY_QUEUE_BASE_ADDR + 0x48)    /**< [7] set to one to indicate output PHY (TMU0->PHY0, TMU1->PHY1, TMU2->PHY2, TMU3->PHY3), [6:0] winner input queue number */
+#define QUEUE_RESULT1           (PHY_QUEUE_BASE_ADDR + 0x4c)    /**< [7] set to one to indicate output PHY (TMU0->PHY0, TMU1->PHY1, TMU2->PHY2, TMU3->PHY4), [6:0] winner input queue number */
+#define QUEUE_RESULT2           (PHY_QUEUE_BASE_ADDR + 0x50)    /**< [7] set to one to indicate output PHY (TMU0->PHY0, TMU1->PHY1, TMU2->PHY2, TMU3->PHY5), [6:0] winner input queue number */
+
+#define QUEUE_RESULT0_REGOFFSET	(QUEUE_RESULT0 - QUEUE_RESULT0)
+#define QUEUE_RESULT1_REGOFFSET	(QUEUE_RESULT1 - QUEUE_RESULT0)
+#define QUEUE_RESULT2_REGOFFSET	(QUEUE_RESULT2 - QUEUE_RESULT0)
+
+
+#include "cbus.h"
+
+enum {
+	CLASS0_ID = 0,
+	CLASS1_ID,
+	CLASS2_ID,
+	CLASS3_ID,
+#if !defined(CONFIG_PLATFORM_PCI)
+	CLASS4_ID,
+	CLASS5_ID,
+#endif
+#if !defined(CONFIG_TMU_DUMMY)
+	TMU0_ID,
+	TMU1_ID,
+	TMU2_ID,
+	TMU3_ID,
+#else
+	TMU0_ID,
+#endif
+#if !defined(CONFIG_UTIL_DISABLED)
+	UTIL_ID,
+#endif
+	MAX_PE
+};
+
+enum {
+	CLASS_TYPE = 0,
+	TMU_TYPE,
+	UTIL_TYPE
+};
+
+#if !defined(CONFIG_PLATFORM_PCI)
+#define CLASS_MASK	((1 << CLASS0_ID) | (1 << CLASS1_ID) | (1 << CLASS2_ID) | (1 << CLASS3_ID) | (1 << CLASS4_ID) | (1 << CLASS5_ID))
+#define CLASS_MAX_ID	CLASS5_ID
+#else
+#define CLASS_MASK      ((1 << CLASS0_ID) | (1 << CLASS1_ID) | (1 << CLASS2_ID) | (1 << CLASS3_ID))
+#define CLASS_MAX_ID	CLASS3_ID
+#endif
+
+#if !defined(CONFIG_TMU_DUMMY)
+#if defined(CONFIG_PLATFORM_LS1012A)
+#define TMU_MASK	((1 << TMU0_ID) | (1 << TMU1_ID) | (1 << TMU3_ID))
+#else
+#define TMU_MASK	((1 << TMU0_ID) | (1 << TMU1_ID) | (1 << TMU2_ID) | (1 << TMU3_ID))
+#endif
+#define TMU_MAX_ID	TMU3_ID
+#else
+#define TMU_MASK        (1 << TMU0_ID)
+#define TMU_MAX_ID	TMU0_ID
+#endif
+
+#if !defined(CONFIG_UTIL_DISABLED)
+#define UTIL_MASK	(1 << UTIL_ID)
+#endif
+
+typedef struct tPE_STATUS
+{
+	u32	cpu_state;
+	u32	activity_counter;
+	u32	rx;
+	union {
+		u32	tx;
+		u32	tmu_qstatus;
+	};
+	u32	drop;
+#if defined(CFG_PE_DEBUG)
+	u32	debug_indicator;
+	u32	debug[16];
+#endif
+} __attribute__((aligned(16))) PE_STATUS;
+
+
+struct pe_sync_mailbox
+{
+	u32 stop;
+	u32 stopped;
+};
+
+struct pe_msg_mailbox
+{
+	u32 dst;
+	u32 src;
+	u32 len;
+	u32 request;
+};
+
+// Drop counter definitions
+
+#define	CLASS_NUM_DROP_COUNTERS		13
+#define	UTIL_NUM_DROP_COUNTERS		8
+
+
+/** PE information.
+ * Structure containing PE's specific information. It is used to create
+ * generic C functions common to all PE's.
+ * Before using the library functions this structure needs to be initialized with the different registers virtual addresses
+ * (according to the ARM MMU mmaping). The default initialization supports a virtual == physical mapping.
+ *
+ */
+struct pe_info
+{
+	u32 dmem_base_addr;		/**< PE's dmem base address */
+	u32 pmem_base_addr;		/**< PE's pmem base address */
+	u32 pmem_size;			/**< PE's pmem size */
+
+	void *mem_access_wdata;		/**< PE's _MEM_ACCESS_WDATA register address */
+	void *mem_access_addr;		/**< PE's _MEM_ACCESS_ADDR register address */
+	void *mem_access_rdata;		/**< PE's _MEM_ACCESS_RDATA register address */
+};
+
+
+void pe_lmem_read(u32 *dst, u32 len, u32 offset);
+void pe_lmem_write(u32 *src, u32 len, u32 offset);
+
+void pe_dmem_memcpy_to32(int id, u32 dst, const void *src, unsigned int len);
+void pe_pmem_memcpy_to32(int id, u32 dst, const void *src, unsigned int len);
+
+u32 pe_pmem_read(int id, u32 addr, u8 size);
+
+void pe_dmem_write(int id, u32 val, u32 addr, u8 size);
+u32 pe_dmem_read(int id, u32 addr, u8 size);
+void class_pe_lmem_memcpy_to32(u32 dst, const void *src, unsigned int len);
+void class_pe_lmem_memset(u32 dst, int val, unsigned int len);
+void class_bus_write(u32 val, u32 addr, u8 size);
+u32 class_bus_read(u32 addr, u8 size);
+
+
+#define class_bus_readl(addr)			class_bus_read(addr, 4)
+#define class_bus_readw(addr)			class_bus_read(addr, 2)
+#define class_bus_readb(addr)			class_bus_read(addr, 1)
+
+#define class_bus_writel(val, addr)		class_bus_write(val, addr, 4)
+#define class_bus_writew(val, addr)		class_bus_write(val, addr, 2)
+#define class_bus_writeb(val, addr)		class_bus_write(val, addr, 1)
+
+#define pe_dmem_readl(id, addr)			pe_dmem_read(id, addr, 4)
+#define pe_dmem_readw(id, addr)			pe_dmem_read(id, addr, 2)
+#define pe_dmem_readb(id, addr)			pe_dmem_read(id, addr, 1)
+
+#define pe_dmem_writel(id, val, addr)		pe_dmem_write(id, val, addr, 4)
+#define pe_dmem_writew(id, val, addr)		pe_dmem_write(id, val, addr, 2)
+#define pe_dmem_writeb(id, val, addr)		pe_dmem_write(id, val, addr, 1)
+
+//int pe_load_elf_section(int id, const void *data, Elf32_Shdr *shdr);
+int pe_load_elf_section(int id, const void *data, Elf32_Shdr *shdr, struct device *dev);
+
+void pfe_lib_init(void *cbus_base, void *ddr_base, unsigned long ddr_phys_base, unsigned int ddr_size);
+void bmu_init(void *base, BMU_CFG *cfg);
+void bmu_reset(void *base);
+void bmu_enable(void *base);
+void bmu_disable(void *base);
+void bmu_set_config(void *base, BMU_CFG *cfg);
+
+/* An enumerated type for loopback values.  This can be one of three values, no
+ * loopback -normal operation, local loopback with internal loopback module of
+ * MAC or PHY loopback which is through the external PHY.
+ */
+#ifndef __MAC_LOOP_ENUM__
+#define __MAC_LOOP_ENUM__
+typedef enum {LB_NONE, LB_EXT, LB_LOCAL} MAC_LOOP;
+#endif
+
+
+void gemac_init(void *base, void *config);
+void gemac_disable_rx_checksum_offload(void *base);
+void gemac_enable_rx_checksum_offload(void *base);
+void gemac_set_mdc_div(void *base, int mdc_div);
+void gemac_set_speed(void *base, MAC_SPEED gem_speed);
+void gemac_set_duplex(void *base, int duplex);
+void gemac_set_mode(void *base, int mode);
+void gemac_enable(void *base);
+void gemac_tx_disable(void *base);
+void gemac_disable(void *base);
+void gemac_reset(void *base);
+void gemac_set_address(void *base, SPEC_ADDR *addr);
+SPEC_ADDR gemac_get_address(void *base);
+void gemac_set_loop( void *base, MAC_LOOP gem_loop );
+void gemac_set_laddr1(void *base, MAC_ADDR *address);
+void gemac_set_laddr2(void *base, MAC_ADDR *address);
+void gemac_set_laddr3(void *base, MAC_ADDR *address);
+void gemac_set_laddr4(void *base, MAC_ADDR *address);
+void gemac_set_laddrN(void *base, MAC_ADDR *address, unsigned int entry_index);
+void gemac_clear_laddr1(void *base);
+void gemac_clear_laddr2(void *base);
+void gemac_clear_laddr3(void *base);
+void gemac_clear_laddr4(void *base);
+void gemac_clear_laddrN(void *base, unsigned int entry_index);
+MAC_ADDR gemac_get_hash( void *base );
+void gemac_set_hash( void *base, MAC_ADDR *hash );
+MAC_ADDR gem_get_laddr1(void *base);
+MAC_ADDR gem_get_laddr2(void *base);
+MAC_ADDR gem_get_laddr3(void *base);
+MAC_ADDR gem_get_laddr4(void *base);
+MAC_ADDR gem_get_laddrN(void *base, unsigned int entry_index);
+void gemac_set_config(void *base, GEMAC_CFG *cfg);
+void gemac_allow_broadcast(void *base);
+void gemac_no_broadcast(void *base);
+void gemac_enable_unicast(void *base);
+void gemac_disable_unicast(void *base);
+void gemac_enable_multicast(void *base);
+void gemac_disable_multicast(void *base);
+void gemac_enable_fcs_rx(void *base);
+void gemac_disable_fcs_rx(void *base);
+void gemac_enable_1536_rx(void *base);
+void gemac_disable_1536_rx(void *base);
+void gemac_enable_rx_jmb(void *base);
+void gemac_disable_rx_jmb(void *base);
+void gemac_enable_stacked_vlan(void *base);
+void gemac_disable_stacked_vlan(void *base);
+void gemac_enable_pause_rx(void *base);
+void gemac_disable_pause_rx(void *base);
+void gemac_enable_copy_all(void *base);
+void gemac_disable_copy_all(void *base);
+void gemac_set_bus_width(void *base, int width);
+void gemac_set_wol(void *base, u32 wol_conf);
+
+void gpi_init(void *base, GPI_CFG *cfg);
+void gpi_reset(void *base);
+void gpi_enable(void *base);
+void gpi_disable(void *base);
+void gpi_set_config(void *base, GPI_CFG *cfg);
+
+void class_init(CLASS_CFG *cfg);
+void class_reset(void);
+void class_enable(void);
+void class_disable(void);
+void class_set_config(CLASS_CFG *cfg);
+
+void tmu_reset(void);
+void tmu_init(TMU_CFG *cfg);
+void tmu_enable(u32 pe_mask);
+void tmu_disable(u32 pe_mask);
+u32  tmu_qstatus(u32 if_id);
+u32  tmu_pkts_processed(u32 if_id);
+
+void util_init(UTIL_CFG *cfg);
+void util_reset(void);
+void util_enable(void);
+void util_disable(void);
+
+void hif_nocpy_init(void);
+void hif_nocpy_tx_enable(void);
+void hif_nocpy_tx_disable(void);
+void hif_nocpy_rx_enable(void);
+void hif_nocpy_rx_disable(void);
+
+void hif_init(void);
+void hif_tx_enable(void);
+void hif_tx_disable(void);
+void hif_rx_enable(void);
+void hif_rx_disable(void);
+
+
+/** Get Chip Revision level
+*
+*/
+
+static inline unsigned int CHIP_REVISION(void)
+{
+#if defined (CONFIG_PLATFORM_C2000)
+#if 1
+	return system_rev;
+	//return 0;
+#else
+	return (readl(COMCERTO_GPIO_DEVICE_ID_REG) >> 24) & 0xf;
+#endif
+
+#else
+	/*For LS1012A return always 1 */
+	return 1;
+#endif
+}
+
+/** Start HIF rx DMA
+*
+*/
+static inline void hif_rx_dma_start(void)
+{
+	/*TODO not sure poll_cntrl_en is required or not */
+	writel(HIF_CTRL_DMA_EN | HIF_CTRL_BDP_CH_START_WSTB, HIF_RX_CTRL);
+}
+
+/** Start HIF tx DMA
+*
+*/
+static inline void hif_tx_dma_start(void)
+{
+	/*TODO not sure poll_cntrl_en is required or not */
+	writel(HIF_CTRL_DMA_EN | HIF_CTRL_BDP_CH_START_WSTB, HIF_TX_CTRL);
+}
+
+/** Start HIF_NOCPY rx DMA
+*
+*/
+static inline void hif_nocpy_rx_dma_start(void)
+{
+	/*TODO not sure poll_cntrl_en is required or not */
+	writel((HIF_CTRL_DMA_EN | HIF_CTRL_BDP_CH_START_WSTB), HIF_NOCPY_RX_CTRL);
+}
+
+/** Start HIF_NOCPY tx DMA
+*
+*/
+static inline void hif_nocpy_tx_dma_start(void)
+{
+	/*TODO not sure poll_cntrl_en is required or not */
+	writel(HIF_CTRL_DMA_EN | HIF_CTRL_BDP_CH_START_WSTB, HIF_NOCPY_TX_CTRL);
+}
+
+#endif /* _PFE_H_ */
+
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/include/pfe/tmu.h
@@ -0,0 +1,68 @@
+/*
+ *  Copyright (c) 2011, 2014 Freescale Semiconductor, Inc.
+ *
+ *  This program is free software; you can redistribute it and/or
+ *  modify it under the terms of the GNU General Public License
+ *  as published by the Free Software Foundation; either version 2
+ *  of the License, or (at your option) any later version.
+ *
+ *  This program is distributed in the hope that it will be useful,
+ *  but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *  GNU General Public License for more details.
+ *
+ *  You should have received a copy of the GNU General Public License
+ *  along with this program; if not, write to the Free Software
+ *  Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
+ *
+*/
+#ifndef _TMU_H_
+#define _TMU_H_
+
+#define TMU_DMEM_BASE_ADDR	0x00000000
+#define TMU_PMEM_BASE_ADDR	0x00010000
+
+#define CBUS_BASE_ADDR		0xc0000000
+#define TMU_APB_BASE_ADDR	0xc1000000
+
+#if defined (COMCERTO_2000_TMU) || defined (COMCERTO_2000_CONTROL)
+
+#include "cbus.h"
+
+#define GPT_BASE_ADDR		(TMU_APB_BASE_ADDR + 0x00000)
+#define UART_BASE_ADDR		(TMU_APB_BASE_ADDR + 0x10000)
+
+#define SHAPER0_BASE_ADDR	(TMU_APB_BASE_ADDR + 0x020000)
+#define SHAPER1_BASE_ADDR	(TMU_APB_BASE_ADDR + 0x030000)
+#define SHAPER2_BASE_ADDR	(TMU_APB_BASE_ADDR + 0x040000)
+#define SHAPER3_BASE_ADDR	(TMU_APB_BASE_ADDR + 0x050000)
+#define SHAPER4_BASE_ADDR	(TMU_APB_BASE_ADDR + 0x060000)
+#define SHAPER5_BASE_ADDR	(TMU_APB_BASE_ADDR + 0x070000)
+#define SHAPER6_BASE_ADDR	(TMU_APB_BASE_ADDR + 0x080000)
+#define SHAPER7_BASE_ADDR	(TMU_APB_BASE_ADDR + 0x090000)
+#define SHAPER8_BASE_ADDR	(TMU_APB_BASE_ADDR + 0x0a0000)
+#define SHAPER9_BASE_ADDR	(TMU_APB_BASE_ADDR + 0x0b0000)
+
+#define SCHED0_BASE_ADDR	(TMU_APB_BASE_ADDR + 0x1c0000)
+#define SCHED1_BASE_ADDR	(TMU_APB_BASE_ADDR + 0x1d0000)
+#define SCHED2_BASE_ADDR	(TMU_APB_BASE_ADDR + 0x1e0000)
+#define SCHED3_BASE_ADDR	(TMU_APB_BASE_ADDR + 0x1f0000)
+#define SCHED4_BASE_ADDR	(TMU_APB_BASE_ADDR + 0x200000)
+#define SCHED5_BASE_ADDR	(TMU_APB_BASE_ADDR + 0x210000)
+#define SCHED6_BASE_ADDR	(TMU_APB_BASE_ADDR + 0x220000)
+#define SCHED7_BASE_ADDR	(TMU_APB_BASE_ADDR + 0x230000)
+
+#define SHAPER_STATUS		(TMU_APB_BASE_ADDR + 0x270000) /**< [9:0] bitmask of shapers that have positive credit */
+
+#include "gpt.h"
+#include "uart.h"
+#include "tmu/shaper.h"
+#include "tmu/sched.h"
+
+#endif
+
+#define PHY_QUEUE_BASE_ADDR (TMU_APB_BASE_ADDR + 0x260000)
+
+#include "tmu/phy_queue.h"
+
+#endif /* _TMU_H_ */
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/include/pfe/tmu/phy_queue.h
@@ -0,0 +1,56 @@
+/*
+ *  Copyright (c) 2011, 2014 Freescale Semiconductor, Inc.
+ *
+ *  This program is free software; you can redistribute it and/or
+ *  modify it under the terms of the GNU General Public License
+ *  as published by the Free Software Foundation; either version 2
+ *  of the License, or (at your option) any later version.
+ *
+ *  This program is distributed in the hope that it will be useful,
+ *  but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *  GNU General Public License for more details.
+ *
+ *  You should have received a copy of the GNU General Public License
+ *  along with this program; if not, write to the Free Software
+ *  Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
+ *
+*/
+#ifndef _PHY_QUEUE_H_
+#define _PHY_QUEUE_H_
+
+#define PHY_QUEUE_SHAPER_STATUS	(PHY_QUEUE_BASE_ADDR + 0x00)	/**< [28:19] same as SHAPER_STATUS, [18:3] same as QUEUE_STATUS, [2:0] must be zero before a new packet may be dequeued */
+#define QUEUE_STATUS		(PHY_QUEUE_BASE_ADDR + 0x04)	/**< [15:0] bit mask of input queues with pending packets */
+
+#define QUEUE0_PKT_LEN		(PHY_QUEUE_BASE_ADDR + 0x08)
+#define QUEUE1_PKT_LEN		(PHY_QUEUE_BASE_ADDR + 0x0c)
+#define QUEUE2_PKT_LEN		(PHY_QUEUE_BASE_ADDR + 0x10)
+#define QUEUE3_PKT_LEN		(PHY_QUEUE_BASE_ADDR + 0x14)
+#define QUEUE4_PKT_LEN		(PHY_QUEUE_BASE_ADDR + 0x18)
+#define QUEUE5_PKT_LEN		(PHY_QUEUE_BASE_ADDR + 0x1c)
+#define QUEUE6_PKT_LEN		(PHY_QUEUE_BASE_ADDR + 0x20)
+#define QUEUE7_PKT_LEN		(PHY_QUEUE_BASE_ADDR + 0x24)
+#define QUEUE8_PKT_LEN		(PHY_QUEUE_BASE_ADDR + 0x28)
+#define QUEUE9_PKT_LEN		(PHY_QUEUE_BASE_ADDR + 0x2c)
+#define QUEUE10_PKT_LEN		(PHY_QUEUE_BASE_ADDR + 0x30)
+#define QUEUE11_PKT_LEN		(PHY_QUEUE_BASE_ADDR + 0x34)
+#define QUEUE12_PKT_LEN		(PHY_QUEUE_BASE_ADDR + 0x38)
+#define QUEUE13_PKT_LEN		(PHY_QUEUE_BASE_ADDR + 0x3c)
+#define QUEUE14_PKT_LEN		(PHY_QUEUE_BASE_ADDR + 0x40)
+#define QUEUE15_PKT_LEN		(PHY_QUEUE_BASE_ADDR + 0x44)
+#define QUEUE_RESULT0		(PHY_QUEUE_BASE_ADDR + 0x48)	/**< [7] set to one to indicate output PHY (TMU0->PHY0, TMU1->PHY1, TMU2->PHY2, TMU3->PHY3), [6:0] winner input queue number */
+#define QUEUE_RESULT1		(PHY_QUEUE_BASE_ADDR + 0x4c)	/**< [7] set to one to indicate output PHY (TMU0->PHY0, TMU1->PHY1, TMU2->PHY2, TMU3->PHY4), [6:0] winner input queue number */
+#define QUEUE_RESULT2		(PHY_QUEUE_BASE_ADDR + 0x50)	/**< [7] set to one to indicate output PHY (TMU0->PHY0, TMU1->PHY1, TMU2->PHY2, TMU3->PHY5), [6:0] winner input queue number */
+#define TMU_PE_GP_REG		(PHY_QUEUE_BASE_ADDR + 0x54)
+#define QUEUE_GBL_PKTLEN	(PHY_QUEUE_BASE_ADDR + 0x5c)
+#define QUEUE_GBL_PKTLEN_MASK	(PHY_QUEUE_BASE_ADDR + 0x60)
+
+#define QUEUE_RESULT0_REGOFFSET	(QUEUE_RESULT0 - QUEUE_RESULT0)
+#define QUEUE_RESULT1_REGOFFSET	(QUEUE_RESULT1 - QUEUE_RESULT0)
+#define QUEUE_RESULT2_REGOFFSET	(QUEUE_RESULT2 - QUEUE_RESULT0)
+
+#define TEQ_HTD                 (1 << 22)
+#define TEQ_HWRED               (1 << 21)
+
+
+#endif /* _PHY_QUEUE_H_ */
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/include/pfe/tmu/sched.h
@@ -0,0 +1,72 @@
+/*
+ *  Copyright (c) 2011, 2014 Freescale Semiconductor, Inc.
+ *
+ *  This program is free software; you can redistribute it and/or
+ *  modify it under the terms of the GNU General Public License
+ *  as published by the Free Software Foundation; either version 2
+ *  of the License, or (at your option) any later version.
+ *
+ *  This program is distributed in the hope that it will be useful,
+ *  but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *  GNU General Public License for more details.
+ *
+ *  You should have received a copy of the GNU General Public License
+ *  along with this program; if not, write to the Free Software
+ *  Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
+ *
+*/
+#ifndef _SCHED_H_
+#define _SCHED_H_
+
+/* Offsets from SCHEDx_BASE_ADDR */
+#define SCHED_CTRL			0x00
+#define SCHED_SLOT_TIME			0x04
+#define SCHED_RES			0x08
+#define SCHED_QUEUE_ALLOC0		0x0c
+#define SCHED_QUEUE_ALLOC1		0x10
+#define SCHED_BW			0x14
+#define SCHED_GUR_DEF_CTR		0x18
+#define SCHED_AVL_CTR			0x1c
+#define SCHED_QU0_WGHT			0x20
+#define SCHED_QU1_WGHT			0x24
+#define SCHED_QU2_WGHT			0x28
+#define SCHED_QU3_WGHT			0x2c
+#define SCHED_QU4_WGHT			0x30
+#define SCHED_QU5_WGHT			0x34
+#define SCHED_QU6_WGHT			0x38
+#define SCHED_QU7_WGHT			0x3c
+#define SCHED_QUE0_DEFICIT_CNT		0x40
+#define SCHED_QUE1_DEFICIT_CNT		0x44
+#define SCHED_QUE2_DEFICIT_CNT		0x48
+#define SCHED_QUE3_DEFICIT_CNT		0x4c
+#define SCHED_QUE4_DEFICIT_CNT		0x50
+#define SCHED_QUE5_DEFICIT_CNT		0x54
+#define SCHED_QUE6_DEFICIT_CNT		0x58
+#define SCHED_QUE7_DEFICIT_CNT		0x5c
+#define SCHED_PKT_LEN			0x60
+
+#define SCHED_CTRL_ALGOTYPE(x) 		(((x) & 0xf) << 0)
+#define SCHED_CTRL_CALQUOTA(x) 		(((x) & 0x1) << 4)
+#define SCHED_CTRL_ACTIVE_Q(x) 		(((x) & 0xff) << 8)
+#define SCHED_CTRL_SHARE_BW(x) 		(((x) & 0xff) << 16)
+#define SCHED_CTRL_BARROW_BW(x) 	(((x) & 0xff) << 24)
+
+#define SCHED_QUEUE_ALLOC(x, b)	 	(((x) & 0x1f) << (b))
+
+#define SCHED_QUEUE_ALLOC0_QUEUEA(x)	(((x) & 0x1f) << 0)
+#define SCHED_QUEUE_ALLOC0_QUEUEB(x)	(((x) & 0x1f) << 8)
+#define SCHED_QUEUE_ALLOC0_QUEUEC(x)	(((x) & 0x1f) << 16)
+#define SCHED_QUEUE_ALLOC0_QUEUED(x)	(((x) & 0x1f) << 24)
+
+#define SCHED_QUEUE_ALLOC0_RES0(x)	(((x) & 0x7) << 5)
+#define SCHED_QUEUE_ALLOC0_RES1(x)	(((x) & 0x7) << 13)
+#define SCHED_QUEUE_ALLOC0_RES2(x)	(((x) & 0x7) << 21)
+#define SCHED_QUEUE_ALLOC0_RES3(x)	(((x) & 0x7) << 29)
+
+#define SCHED_QUEUE_ALLOC1_QUEUEA(x)	(((x) & 0x1f) << 0)
+#define SCHED_QUEUE_ALLOC1_QUEUEB(x)	(((x) & 0x1f) << 8)
+#define SCHED_QUEUE_ALLOC1_QUEUEC(x)	(((x) & 0x1f) << 16)
+#define SCHED_QUEUE_ALLOC1_QUEUED(x)	(((x) & 0x1f) << 24)
+
+#endif /* _SCHED_H_ */
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/include/pfe/tmu/shaper.h
@@ -0,0 +1,37 @@
+/*
+ *  Copyright (c) 2011, 2014 Freescale Semiconductor, Inc.
+ *
+ *  This program is free software; you can redistribute it and/or
+ *  modify it under the terms of the GNU General Public License
+ *  as published by the Free Software Foundation; either version 2
+ *  of the License, or (at your option) any later version.
+ *
+ *  This program is distributed in the hope that it will be useful,
+ *  but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *  GNU General Public License for more details.
+ *
+ *  You should have received a copy of the GNU General Public License
+ *  along with this program; if not, write to the Free Software
+ *  Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
+ *
+*/
+#ifndef _SHAPER_H_
+#define _SHAPER_H_
+
+/* Offsets from SHAPPERx_BASE_ADDR */
+#define SHAPER_CTRL		0x00
+#define SHAPER_WEIGHT		0x04
+#define SHAPER_PKT_LEN		0x08
+
+#define SHAPER_CTRL_ENABLE(x) 	(((x) & 0x1) << 0)
+#define SHAPER_CTRL_QNO(x) 	(((x) & 0x3f) << 1)
+#define SHAPER_CTRL_CLKDIV(x) 	(((x) & 0xffff) << 16)
+
+#define SHAPER_WEIGHT_FRACWT(x) 	(((x) & 0xff) << 0)
+#define SHAPER_WEIGHT_INTWT(x) 		(((x) & 0x3) << 8)
+#define SHAPER_WEIGHT_MAXCREDIT(x) 	(((x) & 0x3fffff) << 10)
+
+#define PORT_SHAPER_MASK (1 << 0)
+
+#endif /* _SHAPER_H_ */
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/include/pfe/uart.h
@@ -0,0 +1,31 @@
+/*
+ *  Copyright (c) 2011, 2014 Freescale Semiconductor, Inc.
+ *
+ *  This program is free software; you can redistribute it and/or
+ *  modify it under the terms of the GNU General Public License
+ *  as published by the Free Software Foundation; either version 2
+ *  of the License, or (at your option) any later version.
+ *
+ *  This program is distributed in the hope that it will be useful,
+ *  but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *  GNU General Public License for more details.
+ *
+ *  You should have received a copy of the GNU General Public License
+ *  along with this program; if not, write to the Free Software
+ *  Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
+ *
+*/
+#ifndef _UART_H_
+#define _UART_H_
+
+#define UART_THR	(UART_BASE_ADDR + 0x00)
+#define UART_IER	(UART_BASE_ADDR + 0x04)
+#define UART_IIR	(UART_BASE_ADDR + 0x08)
+#define UART_LCR	(UART_BASE_ADDR + 0x0c)
+#define UART_MCR	(UART_BASE_ADDR + 0x10)
+#define UART_LSR	(UART_BASE_ADDR + 0x14)
+#define UART_MDR	(UART_BASE_ADDR + 0x18)
+#define UART_SCRATCH	(UART_BASE_ADDR + 0x1c)
+
+#endif /* _UART_H_ */
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/include/pfe/util.h
@@ -0,0 +1,49 @@
+/*
+ *  Copyright (c) 2011, 2014 Freescale Semiconductor, Inc.
+ *
+ *  This program is free software; you can redistribute it and/or
+ *  modify it under the terms of the GNU General Public License
+ *  as published by the Free Software Foundation; either version 2
+ *  of the License, or (at your option) any later version.
+ *
+ *  This program is distributed in the hope that it will be useful,
+ *  but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *  GNU General Public License for more details.
+ *
+ *  You should have received a copy of the GNU General Public License
+ *  along with this program; if not, write to the Free Software
+ *  Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
+ *
+*/
+#ifndef _UTIL_H_
+#define _UTIL_H_
+
+#define UTIL_DMEM_BASE_ADDR	0x00000000
+#define UTIL_DMEM_SIZE		0x00002000
+#define UTIL_DMEM_END		(UTIL_DMEM_BASE_ADDR + UTIL_DMEM_SIZE)
+
+#define IS_DMEM(addr, len)	(((unsigned long)(addr) >= UTIL_DMEM_BASE_ADDR) && (((unsigned long)(addr) + (len)) <= UTIL_DMEM_END))
+
+#define CBUS_BASE_ADDR		0xc0000000
+#define UTIL_APB_BASE_ADDR	0xc1000000
+
+#include "cbus.h"
+
+#define GPT_BASE_ADDR		(UTIL_APB_BASE_ADDR + 0x00000)
+#define UART_BASE_ADDR		(UTIL_APB_BASE_ADDR + 0x10000)
+#define EAPE_BASE_ADDR		(UTIL_APB_BASE_ADDR + 0x20000)
+#define INQ_BASE_ADDR		(UTIL_APB_BASE_ADDR + 0x30000)
+#define EFET1_BASE_ADDR		(UTIL_APB_BASE_ADDR + 0x40000)
+#define EFET2_BASE_ADDR		(UTIL_APB_BASE_ADDR + 0x50000)
+#define EFET3_BASE_ADDR		(UTIL_APB_BASE_ADDR + 0x60000)
+
+
+#include "gpt.h"
+#include "uart.h"
+#include "util/eape.h"
+#include "util/inq.h"
+#include "util/efet.h"
+
+
+#endif /* _UTIL_H_ */
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/include/pfe/util/eape.h
@@ -0,0 +1,57 @@
+/*
+ *  Copyright (c) 2011, 2014 Freescale Semiconductor, Inc.
+ *
+ *  This program is free software; you can redistribute it and/or
+ *  modify it under the terms of the GNU General Public License
+ *  as published by the Free Software Foundation; either version 2
+ *  of the License, or (at your option) any later version.
+ *
+ *  This program is distributed in the hope that it will be useful,
+ *  but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *  GNU General Public License for more details.
+ *
+ *  You should have received a copy of the GNU General Public License
+ *  along with this program; if not, write to the Free Software
+ *  Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
+ *
+*/
+#ifndef _EAPE_H_
+#define _EAPE_H_
+
+#define EAPE_STATUS		(EAPE_BASE_ADDR + 0x0)
+#define EAPE_INT_ENABLE		(EAPE_BASE_ADDR + 0x4)
+#define EAPE_INT_SRC		(EAPE_BASE_ADDR + 0x8)
+#define EAPE_HOST_INT_ENABLE	(EAPE_BASE_ADDR + 0xc)
+
+/** The following bits represents to enable interrupts from host and to host
+* from / to utilpe */
+
+#define IRQ_EN_EFET_TO_UTIL	0x1
+#define IRQ_EN_QB_TO_UTIL	0x2
+#define IRQ_EN_INQ_TO_UTIL	0x4
+#define IRQ_EN_EAPE_TO_UTIL	0x8
+#define IRQ_EN_GPT_TMR_TO_UTIL	0x10
+#define IRQ_EN_UART_TO_UTIL	0x20
+#define IRQ_EN_SYSLP_TO_UTIL	0x40
+#define IRQ_EN_UPEGP_TO_UTIL	0x80
+
+/** Out interrupts */
+
+#define IRQ_EN_EFET_OUT		0x100
+#define IRQ_EN_QB_OUT		0x200
+#define IRQ_EN_INQ_OUT		0x400
+#define IRQ_EN_EAPE_OUT		0x800
+#define IRQ_EN_GPT_TMR_OUT	0x1000
+#define IRQ_EN_UART_OUT		0x2000
+#define IRQ_EN_SYSLP_OUT	0x4000
+#define IRQ_EN_UPEGP_OUT	0x8000
+
+/** The following bits are enabled in the status register
+ * which are mapped to IPSEC status register bits */
+#define EAPE_IN_STAT_AVAIL      0x1
+#define EAPE_OUT_STAT_AVAIL     0x2
+#define EAPE_IN_CMD_AVAIL       0x4
+#define EAPE_OUT_CMD_AVAIL      0x8
+
+#endif /* _EAPE_H_ */
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/include/pfe/util/efet.h
@@ -0,0 +1,119 @@
+/*
+ *  Copyright (c) 2011, 2014 Freescale Semiconductor, Inc.
+ *
+ *  This program is free software; you can redistribute it and/or
+ *  modify it under the terms of the GNU General Public License
+ *  as published by the Free Software Foundation; either version 2
+ *  of the License, or (at your option) any later version.
+ *
+ *  This program is distributed in the hope that it will be useful,
+ *  but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *  GNU General Public License for more details.
+ *
+ *  You should have received a copy of the GNU General Public License
+ *  along with this program; if not, write to the Free Software
+ *  Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
+ *
+*/
+#ifndef _UTIL_EFET_H_
+#define _UTIL_EFET_H_
+
+#define EFET_ENTRY_ADDR		0x00
+#define EFET_ENTRY_SIZE		0x04
+#define EFET_ENTRY_DMEM_ADDR	0x08
+#define EFET_ENTRY_STATUS	0x0c
+#define EFET_ENTRY_ENDIAN	0x10
+
+#define CBUS2DMEM	0
+#define DMEM2CBUS	1
+
+#define EFET2BUS_LE     (1 << 0)
+
+#define EFET1		0
+#define EFET2		1
+#define EFET3		2
+#define MAX_UTIL_EFET_LEN	128
+
+extern const unsigned long util_efet_baseaddr[3];
+extern u32 util_efet_status;
+
+/* The barrier call is an empirical work-around for an unknown bug: for some unknown reason, it solves
+ * a UtilPE crash observed with LRO and packet steering. Other solutions also worked (e.g. barrier,
+ * nop calls in other positions). However, no common pattern could be extracted from those solutions
+ * to narrow down the source of the crash.
+ */
+
+#define __UTIL_EFET(i, cbus_addr, dmem_addr,len,dir) do { \
+	__writel((len & 0x3FF) | (dir << 16), util_efet_baseaddr[i] + EFET_ENTRY_SIZE); \
+	__writel(dmem_addr, util_efet_baseaddr[i] + EFET_ENTRY_DMEM_ADDR);\
+	__writel(cbus_addr, util_efet_baseaddr[i] + EFET_ENTRY_ADDR);\
+	nop();\
+	}while(0)
+
+#define UTIL_EFET(i, cbus_addr, dmem_addr,len,dir) do { \
+	__UTIL_EFET(i, cbus_addr, dmem_addr, len, dir);	\
+	util_efet_status |= (1 << i);			\
+	} while(0)
+
+
+/** Waits for the util efet to finish a transaction, blocking the caller
+* (without updating the status).
+* Can be called at any time.
+*
+* @param i      Efet index
+*
+*
+*/
+static inline void __util_efet_wait(int i)
+{
+        while (!(readl(util_efet_baseaddr[i] + EFET_ENTRY_STATUS) & 0x1)) ;
+}
+
+/** Waits for the util efet to finish a transaction, blocking the caller.
+* Can be called at any time.
+*
+* @param i      Efet index
+*
+*/
+static inline void util_efet_wait(int i)
+{
+	__util_efet_wait(i);
+	
+	util_efet_status &= ~(1 << i);
+}
+
+/** Asynchronous interface to util efet read/write functions.
+* It will wait for the efet to finish previous transaction, but does not wait for the current transaction to finish.
+*
+* @param i              Efet index
+* @param cbus_addr      Cbus address (must be 64bits aligned)
+* @param dmem_addr      DMEM address (must be 64bits aligned)
+* @param len            Number of bytes to copy (must be 64bits aligned size)
+* @param dir            Direction of the transaction (0 - cbus to dmem, 1 - dmem to cbus)
+*
+*/
+static inline void util_efet_async(int i, u32 cbus_addr, u32 dmem_addr, u32 len, u8 dir)
+{
+	if (util_efet_status & (1 << i))
+		util_efet_wait(i);
+
+	UTIL_EFET(i, cbus_addr, dmem_addr, len, dir);
+}
+
+
+static inline void util_efet_async0( u32 cbus_addr, u32 dmem_addr, u32 len, u8 dir)
+{
+	util_efet_async(0, cbus_addr, dmem_addr, len,dir);
+}
+
+/* EFET 2 is aways used for SYNC operations */
+static inline void util_efet_sync2(u32 cbus_addr, u32 dmem_addr, u32 len, u8 dir)
+{
+	__UTIL_EFET(2, cbus_addr, dmem_addr, len,dir);
+	__util_efet_wait(2);
+}
+
+void util_efet_sync0(u32 cbus_addr, u32 dmem_addr, u32 len, u8 dir);
+#endif /* _UTIL_EFET_H_ */
+
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/include/pfe/util/inq.h
@@ -0,0 +1,28 @@
+/*
+ *  Copyright (c) 2011, 2014 Freescale Semiconductor, Inc.
+ *
+ *  This program is free software; you can redistribute it and/or
+ *  modify it under the terms of the GNU General Public License
+ *  as published by the Free Software Foundation; either version 2
+ *  of the License, or (at your option) any later version.
+ *
+ *  This program is distributed in the hope that it will be useful,
+ *  but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *  GNU General Public License for more details.
+ *
+ *  You should have received a copy of the GNU General Public License
+ *  along with this program; if not, write to the Free Software
+ *  Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
+ *
+*/
+#ifndef _INQ_H_
+#define _INQ_H_
+
+#define INQ_HOST_GP	(INQ_BASE_ADDR + 0x00) /* FIXME what are these for ? */
+#define INQ_UPE_GP	(INQ_BASE_ADDR + 0x04) /* FIXME what are these for ? */
+
+#define INQ_QB_PKTPTR	(INQ_BASE_ADDR + 0x08)
+#define INQ_FIFO_CNT	(INQ_BASE_ADDR + 0x0c)
+
+#endif /* _INQ_H_ */
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/pfe_ctrl.c
@@ -0,0 +1,363 @@
+/*
+ *
+ *  Copyright (C) 2007 Freescale Semiconductor, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+
+#ifdef __KERNEL__
+#include <linux/kernel.h>
+#include <linux/sched.h>
+#include <linux/module.h>
+#include <linux/list.h>
+#include <linux/kthread.h>
+#else
+#include "platform.h"
+#endif
+
+#include "pfe_mod.h"
+#include "pfe_ctrl.h"
+
+#include "pfe_ctrl_hal.h"
+
+static struct pe_sync_mailbox CLASS_DMEM_SH2(sync_mailbox);
+static struct pe_sync_mailbox TMU_DMEM_SH2(sync_mailbox);
+
+static struct pe_msg_mailbox CLASS_DMEM_SH2(msg_mailbox);
+static struct pe_msg_mailbox TMU_DMEM_SH2(msg_mailbox);
+
+#if !defined(CONFIG_PLATFORM_LS1012A)
+static u32 CLASS_DMEM_SH2(resume);
+static u32 TMU_DMEM_SH2(resume);
+#endif
+
+#if !defined(CONFIG_UTIL_DISABLED)
+static struct pe_sync_mailbox UTIL_DMEM_SH2(sync_mailbox);
+static struct pe_msg_mailbox UTIL_DMEM_SH2(msg_mailbox);
+static u32 UTIL_DMEM_SH2(resume);
+#endif
+
+static int pfe_ctrl_timer(void *data);
+
+static int initialized = 0;
+
+#define TIMEOUT_MS	1000
+
+int relax(unsigned long end)
+{
+#ifdef __KERNEL__
+	if (time_after(jiffies, end)) {
+		if (time_after(jiffies, end + (TIMEOUT_MS * HZ) / 1000)) {
+			return -1;
+		}
+
+		if (need_resched())
+			schedule();
+	}
+#else
+                udelay(1);
+#endif
+
+	return 0;
+}
+
+#if !defined(CONFIG_PLATFORM_LS1012A)
+void pfe_ctrl_suspend(struct pfe_ctrl *ctrl)
+{
+	int id;
+
+	kthread_stop(ctrl->timer_thread);
+
+	mutex_lock(&ctrl->mutex);
+
+	initialized = 0;
+	for (id = CLASS0_ID; id <= CLASS_MAX_ID; id++)
+			pe_dmem_write(id, cpu_to_be32(0x1), (unsigned long)virt_to_class_dmem(&class_resume), 4);
+
+	for (id = TMU0_ID; id <= TMU_MAX_ID; id++) {
+#if defined(CONFIG_PLATFORM_LS1012A)
+		if(id == TMU2_ID) continue;
+#endif
+		pe_dmem_write(id, cpu_to_be32(0x1), (unsigned long)virt_to_class_dmem(&tmu_resume), 4);
+	}
+
+#if !defined(CONFIG_UTIL_DISABLED)
+	pe_dmem_write(UTIL_ID, cpu_to_be32(0x1), (unsigned long)virt_to_class_dmem(&util_resume), 4);
+#endif
+
+	pe_sync_stop(&pfe->ctrl, 0xFF);
+
+	mutex_unlock(&ctrl->mutex);
+}
+
+void pfe_ctrl_resume(struct pfe_ctrl *ctrl)
+{
+	mutex_lock(&ctrl->mutex);
+	initialized = 1;
+	pe_start(&pfe->ctrl, 0xFF);
+	mutex_unlock(&ctrl->mutex);
+
+	ctrl->timer_thread = kthread_create(pfe_ctrl_timer, ctrl, "pfe_ctrl_timer");
+
+	wake_up_process(ctrl->timer_thread);
+}
+#endif
+
+/** PE sync stop.
+* Stops packet processing for a list of PE's (specified using a bitmask).
+* The caller must hold ctrl->mutex.
+*
+* @param ctrl		Control context
+* @param pe_mask	Mask of PE id's to stop
+*
+*/
+int pe_sync_stop(struct pfe_ctrl *ctrl, int pe_mask)
+{
+	struct pe_sync_mailbox *mbox;
+	int pe_stopped = 0;
+	unsigned long end = jiffies + 2;
+	int i;
+
+#if defined(CONFIG_PLATFORM_LS1012A)
+	//TODO Util should be removed after IPSec is ported
+	pe_mask &= 0x2FF;  //Exclude Util + TMU2 
+#endif
+	for (i = 0; i < MAX_PE; i++)
+		if (pe_mask & (1 << i)) {
+			mbox = (void *)ctrl->sync_mailbox_baseaddr[i];
+
+			pe_dmem_write(i, cpu_to_be32(0x1), (unsigned long)&mbox->stop, 4);
+		}
+
+	while (pe_stopped != pe_mask) {
+		for (i = 0; i < MAX_PE; i++)
+			if ((pe_mask & (1 << i)) && !(pe_stopped & (1 << i))) {
+				mbox = (void *)ctrl->sync_mailbox_baseaddr[i];
+
+				if (pe_dmem_read(i, (unsigned long)&mbox->stopped, 4) & cpu_to_be32(0x1))
+					pe_stopped |= (1 << i);
+			}
+
+		if (relax(end) < 0)
+			goto err;
+	}
+
+	return 0;
+
+err:
+	printk(KERN_ERR "%s: timeout, %x %x\n", __func__, pe_mask, pe_stopped);
+
+	for (i = 0; i < MAX_PE; i++)
+		if (pe_mask & (1 << i)) {
+			mbox = (void *)ctrl->sync_mailbox_baseaddr[i];
+
+			pe_dmem_write(i, cpu_to_be32(0x0), (unsigned long)&mbox->stop, 4);
+	}
+
+	return -EIO;
+}
+
+/** PE start.
+* Starts packet processing for a list of PE's (specified using a bitmask).
+* The caller must hold ctrl->mutex.
+*
+* @param ctrl		Control context
+* @param pe_mask	Mask of PE id's to start
+*
+*/
+void pe_start(struct pfe_ctrl *ctrl, int pe_mask)
+{
+	struct pe_sync_mailbox *mbox;
+	int i;
+
+#if defined(CONFIG_PLATFORM_LS1012A)
+	//TODO Util should be removed after IPSec is ported
+	pe_mask &= 0x2FF;  //Exclude Util + TMU2 
+#endif
+	for (i = 0; i < MAX_PE; i++)
+		if (pe_mask & (1 << i)) {
+
+			mbox = (void *)ctrl->sync_mailbox_baseaddr[i];
+
+			pe_dmem_write(i, cpu_to_be32(0x0), (unsigned long)&mbox->stop, 4);
+		}
+}
+
+
+/** Sends a control request to a given PE (to copy data to/from internal memory from/to DDR).
+* The caller must hold ctrl->mutex.
+*
+* @param ctrl		Control context
+* @param id		PE id
+* @param dst		Physical destination address of data
+* @param src		Physical source address of data
+* @param len		Data length
+*
+*/
+int pe_request(struct pfe_ctrl *ctrl, int id, unsigned short cmd_type, unsigned long dst, unsigned long src, int len)
+{
+	struct pe_msg_mailbox mbox = {
+		.dst = cpu_to_be32(dst),
+		.src = cpu_to_be32(src),
+		.len = cpu_to_be32(len),
+		.request = cpu_to_be32((cmd_type << 16) | 0x1),
+	};
+	struct pe_msg_mailbox *pmbox = (void *)ctrl->msg_mailbox_baseaddr[id];
+	unsigned long end = jiffies + 2;
+	u32 rc;
+
+	/* This works because .request is written last */
+	pe_dmem_memcpy_to32(id, (unsigned long)pmbox, &mbox, sizeof(mbox));
+
+	while ((rc = pe_dmem_read(id, (unsigned long)&pmbox->request, 4)) & cpu_to_be32(0xffff)) {
+		if (relax(end) < 0)
+			goto err;
+	}
+
+	rc = be32_to_cpu(rc);
+
+	return rc >> 16;
+
+err:
+	printk(KERN_ERR "%s: timeout, %x\n", __func__, be32_to_cpu(rc));
+	pe_dmem_write(id, cpu_to_be32(0), (unsigned long)&pmbox->request, 4);
+	return -EIO;
+}
+
+
+/** Control code timer thread.
+*
+* A kernel thread is used so that the timer code can be run under the control path mutex.
+* The thread wakes up regularly and checks if any timer in the timer list as expired.
+* The timers are re-started automatically.
+* The code tries to keep the number of times a timer runs per unit time constant on average,
+* if the thread scheduling is delayed, it's possible for a particular timer to be scheduled in
+* quick succession to make up for the lost time.
+*
+* @param data	Pointer to the control context structure
+*
+* @return	0 on sucess, a negative value on error
+*
+*/
+static int pfe_ctrl_timer(void *data)
+{
+	struct pfe_ctrl *ctrl = data;
+	TIMER_ENTRY *timer, *next;
+
+	printk(KERN_INFO "%s\n", __func__);
+
+	while (1)
+	{
+		schedule_timeout_uninterruptible(ctrl->timer_period);
+
+		mutex_lock(&ctrl->mutex);
+
+		list_for_each_entry_safe(timer, next, &ctrl->timer_list, list)
+		{
+			if (time_after(jiffies, timer->timeout))
+			{
+				timer->timeout += timer->period;
+
+				timer->handler();
+			}
+		}
+
+		mutex_unlock(&ctrl->mutex);
+
+		if (kthread_should_stop())
+			break;
+	}
+
+	printk(KERN_INFO "%s exiting\n", __func__);
+
+	return 0;
+}
+
+
+int pfe_ctrl_init(struct pfe *pfe)
+{
+	struct pfe_ctrl *ctrl = &pfe->ctrl;
+	int id;
+	int rc;
+
+	printk(KERN_INFO "%s\n", __func__);
+
+	mutex_init(&ctrl->mutex);
+	spin_lock_init(&ctrl->lock);
+
+	ctrl->timer_period = HZ / TIMER_TICKS_PER_SEC;
+
+	INIT_LIST_HEAD(&ctrl->timer_list);
+
+	/*INIT_WORK(&ctrl->work, comcerto_fpp_workqueue);*/
+
+	INIT_LIST_HEAD(&ctrl->msg_list);
+
+	for (id = CLASS0_ID; id <= CLASS_MAX_ID; id++) {
+		ctrl->sync_mailbox_baseaddr[id] = virt_to_class_dmem(&class_sync_mailbox);
+		ctrl->msg_mailbox_baseaddr[id] = virt_to_class_dmem(&class_msg_mailbox);
+	}
+
+	for (id = TMU0_ID; id <= TMU_MAX_ID; id++) {
+#if defined(CONFIG_PLATFORM_LS1012A)
+		if(id == TMU2_ID) continue;
+#endif
+		ctrl->sync_mailbox_baseaddr[id] = virt_to_tmu_dmem(&tmu_sync_mailbox);
+		ctrl->msg_mailbox_baseaddr[id] = virt_to_tmu_dmem(&tmu_msg_mailbox);
+	}
+
+#if !defined(CONFIG_UTIL_DISABLED)
+	ctrl->sync_mailbox_baseaddr[UTIL_ID] = virt_to_util_dmem(&util_sync_mailbox);
+	ctrl->msg_mailbox_baseaddr[UTIL_ID] = virt_to_util_dmem(&util_msg_mailbox);
+#endif
+
+	ctrl->hash_array_baseaddr = pfe->ddr_baseaddr + ROUTE_TABLE_BASEADDR;
+	ctrl->hash_array_phys_baseaddr = pfe->ddr_phys_baseaddr + ROUTE_TABLE_BASEADDR;
+	ctrl->ipsec_lmem_phys_baseaddr =  CBUS_VIRT_TO_PFE(LMEM_BASE_ADDR + IPSEC_LMEM_BASEADDR);
+	ctrl->ipsec_lmem_baseaddr = (LMEM_BASE_ADDR + IPSEC_LMEM_BASEADDR);
+
+	ctrl->timer_thread = kthread_create(pfe_ctrl_timer, ctrl, "pfe_ctrl_timer");
+	if (IS_ERR(ctrl->timer_thread))
+	{
+		printk (KERN_ERR "%s: kthread_create() failed\n", __func__);
+		rc = PTR_ERR(ctrl->timer_thread);
+		goto err0;
+	}
+	
+	ctrl->dev = pfe->dev;
+
+	wake_up_process(ctrl->timer_thread);
+
+	printk(KERN_INFO "%s finished\n", __func__);
+
+	initialized = 1;
+
+	return 0;
+
+err0:
+	return rc;
+}
+
+
+void pfe_ctrl_exit(struct pfe *pfe)
+{
+	struct pfe_ctrl *ctrl = &pfe->ctrl;
+
+	printk(KERN_INFO "%s\n", __func__);
+
+	initialized = 0;
+
+	kthread_stop(ctrl->timer_thread);
+}
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/pfe_ctrl.h
@@ -0,0 +1,111 @@
+/*
+ *
+ *  Copyright (C) 2007 Freescale Semiconductor, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+
+#ifndef _PFE_CTRL_H_
+#define _PFE_CTRL_H_
+
+#include <linux/dmapool.h>
+
+#include "pfe_mod.h"
+#include "pfe/pfe.h"
+
+#define DMA_BUF_SIZE_128	0x80	/* enough for 1 conntracks */
+#define DMA_BUF_SIZE_256	0x100	/* enough for 2 conntracks, 1 bridge entry or 1 multicast entry */
+#define DMA_BUF_SIZE_512	0x200	/* 512bytes dma allocated buffers used by rtp relay feature */
+#define DMA_BUF_MIN_ALIGNMENT	8
+#define DMA_BUF_BOUNDARY	(4 * 1024) /* bursts can not cross 4k boundary */
+
+#define CMD_TX_ENABLE	0x0501
+#define CMD_TX_DISABLE	0x0502
+
+#define CMD_RX_LRO		0x0011
+#define CMD_PKTCAP_ENABLE       0x0d01
+#define CMD_QM_EXPT_RATE	0x020c
+
+#define EXPT_TYPE_PCAP		0x3
+
+struct pfe_ctrl {
+	struct mutex mutex;
+	spinlock_t lock;
+
+	void *dma_pool;
+	void *dma_pool_512;
+	void *dma_pool_128;
+
+	struct device *dev;
+
+	void *hash_array_baseaddr;		/** Virtual base address of the conntrack hash array */
+	unsigned long hash_array_phys_baseaddr; /** Physical base address of the conntrack hash array */
+
+	struct task_struct *timer_thread;
+	struct list_head timer_list;
+	unsigned long timer_period;
+
+	int (*event_cb)(u16, u16, u16*);
+
+	unsigned long sync_mailbox_baseaddr[MAX_PE]; /* Sync mailbox PFE internal address, initialized when parsing elf images */
+	unsigned long msg_mailbox_baseaddr[MAX_PE]; /* Msg mailbox PFE internal address, initialized when parsing elf images */
+
+	unsigned long class_dmem_sh;
+	unsigned long class_pe_lmem_sh;
+	unsigned long tmu_dmem_sh;
+	unsigned long util_dmem_sh;
+	unsigned long util_ddr_sh;
+	struct clk *clk_axi;
+	unsigned int sys_clk;			// AXI clock value, in KHz
+	void *ipsec_lmem_baseaddr;
+	unsigned long ipsec_lmem_phys_baseaddr;
+	
+	/* used for asynchronous message transfer to PFE */
+	struct list_head msg_list;
+	struct work_struct work;
+};
+
+int pfe_ctrl_init(struct pfe *pfe);
+void pfe_ctrl_exit(struct pfe *pfe);
+
+int pe_send_cmd(unsigned short cmd_type, unsigned short action, unsigned long param1, unsigned long param2);
+int pe_sync_stop(struct pfe_ctrl *ctrl, int pe_mask);
+void pe_start(struct pfe_ctrl *ctrl, int pe_mask);
+int pe_request(struct pfe_ctrl *ctrl, int id,unsigned short cmd_type, unsigned long dst, unsigned long src, int len);
+int pe_read(struct pfe_ctrl *ctrl, int id, u32 *dst, unsigned long src, int len, int clear_flag);
+int tmu_pe_request(struct pfe_ctrl *ctrl, int id, unsigned int tmu_cmd_bitmask);
+
+int pfe_ctrl_set_eth_state(int id, unsigned int state, unsigned char *mac_addr);
+int pfe_ctrl_set_lro(char enable);
+#ifdef CFG_PCAP
+int pfe_ctrl_set_pcap(char enable);
+int pfe_ctrl_set_pcap_ratelimit(u32 pkts_per_msec);
+#endif
+void pfe_ctrl_suspend(struct pfe_ctrl *ctrl);
+void pfe_ctrl_resume(struct pfe_ctrl *ctrl);
+int relax(unsigned long end);
+
+/* used for asynchronous message transfer to PFE */
+#define FPP_MAX_MSG_LENGTH	256 /* expressed in U8 -> 256 bytes*/
+struct fpp_msg {
+        struct list_head list;
+        void (*callback)(unsigned long, int, u16, u16 *);
+        unsigned long data;
+        u16 fcode;
+        u16 length;
+        u16 *payload;
+};
+
+#endif /* _PFE_CTRL_H_ */
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/pfe_ctrl_hal.c
@@ -0,0 +1,207 @@
+/*
+ *
+ *  Copyright (C) 2007 Freescale Semiconductor, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+
+/* OS abstraction functions used by PFE control code */
+
+#include <linux/slab.h>
+
+#include "pfe_ctrl_hal.h"
+
+#include "pfe_mod.h"
+
+extern char *__class_dmem_sh;
+extern char *__tmu_dmem_sh;
+#if !defined(CONFIG_UTIL_DISABLED)
+extern char *__util_dmem_sh;
+extern char *__util_ddr_sh;
+#endif
+
+HostMessage msg_buf;
+static int msg_buf_used = 0;
+unsigned long virt_to_class_dmem(void *p)
+{
+	struct pfe_ctrl *ctrl = &pfe->ctrl;
+
+	if (p)
+		return (unsigned long)p - (unsigned long)&__class_dmem_sh + ctrl->class_dmem_sh;
+	else
+		return 0;
+}
+unsigned long virt_to_tmu_dmem(void *p)
+{
+	struct pfe_ctrl *ctrl = &pfe->ctrl;
+
+	if (p)
+		return (unsigned long)p - (unsigned long)&__tmu_dmem_sh + ctrl->tmu_dmem_sh;
+	else
+		return 0;
+}
+
+
+#if !defined(CONFIG_UTIL_DISABLED)
+unsigned long virt_to_util_dmem(void *p)
+{
+	struct pfe_ctrl *ctrl = &pfe->ctrl;
+
+	if (p)
+		return (unsigned long)p - (unsigned long)&__util_dmem_sh + ctrl->util_dmem_sh;
+	else
+		return 0;
+}
+
+/** Returns the DDR physical address of a Util PE shared DDR variable.
+ *
+ * @param p	pointer (kernel space, virtual) to be converted to a physical address.
+ */
+unsigned long virt_to_util_ddr(void *p)
+{
+	struct pfe_ctrl *ctrl = &pfe->ctrl;
+
+	if (p)
+		return (unsigned long)p - (unsigned long)&__util_ddr_sh + ctrl->util_ddr_sh;
+	else
+		return 0;
+}
+/** Returns the virtual address of a Util PE shared DDR variable.
+ *
+ * @param p pointer (kernel space, virtual) to be converted to a pointer (usable in kernel space)
+ * pointing to the actual data.
+ */
+
+void * virt_to_util_virt(void *p)
+{
+	if (p)
+		return DDR_PHYS_TO_VIRT(virt_to_util_ddr(p));
+	else
+		return NULL;
+}
+#endif
+unsigned long virt_to_phys_iram(void *p)
+{
+	if (p)
+		return (p - pfe->iram_baseaddr) + pfe->iram_phys_baseaddr;
+	else
+		return 0;
+}
+
+unsigned long virt_to_phys_ipsec_lmem(void *p)
+{
+	struct pfe_ctrl *ctrl = &pfe->ctrl;
+
+	if (p)
+		return (p - ctrl->ipsec_lmem_baseaddr) + ctrl->ipsec_lmem_phys_baseaddr;
+	else
+		return 0;
+}
+
+unsigned long virt_to_phys_ipsec_axi(void *p)
+{
+	if (p)
+		return (p - pfe->ipsec_baseaddr) + pfe->ipsec_phys_baseaddr;
+	else
+		return 0;
+}
+
+
+HostMessage *msg_alloc(void)
+{
+	if (msg_buf_used)
+	{
+		printk(KERN_ERR "%s: failed\n", __func__);
+		return NULL;
+	}
+
+	msg_buf_used = 1;
+
+	return &msg_buf;
+}
+
+void msg_free(HostMessage *msg)
+{
+	if (!msg_buf_used)
+		printk(KERN_ERR "%s: freing already free msg buffer\n", __func__);
+
+	msg_buf_used = 0;
+}
+
+int msg_send(HostMessage *msg)
+{
+	struct pfe_ctrl *ctrl = &pfe->ctrl;
+	int rc = -1;
+
+	if (!ctrl->event_cb)
+		goto out;
+
+	if (ctrl->event_cb(msg->code, msg->length, msg->data) < 0)
+		goto out;
+
+	rc = 0;
+
+out:
+	msg_free(msg);
+
+	return rc;
+}
+
+
+void timer_init(TIMER_ENTRY *timer, TIMER_HANDLER handler)
+{
+	timer->handler = handler;
+	timer->running = 0;
+}
+
+
+void timer_add(TIMER_ENTRY *timer, u16 granularity)
+{
+	struct pfe_ctrl *ctrl = &pfe->ctrl;
+
+
+	timer->period = granularity;
+	timer->timeout = jiffies + timer->period;
+
+	if (!timer->running)
+	{
+		list_add(&timer->list, &ctrl->timer_list);
+		timer->running = 1;
+	}
+}
+
+
+void timer_del(TIMER_ENTRY *timer)
+{
+
+	if (timer->running)
+	{
+		list_del(&timer->list);
+		timer->running = 0;
+	}
+}
+
+
+void *Heap_Alloc(int size)
+{
+	/* FIXME we may want to use dma API's and use non cacheable memory */
+	return pfe_kmalloc(size, GFP_KERNEL);
+}
+
+
+void Heap_Free(void *p)
+{
+	pfe_kfree(p);
+}
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/pfe_ctrl_hal.h
@@ -0,0 +1,129 @@
+/*
+ *
+ *  Copyright (C) 2007 Freescale Semiconductor, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+
+#ifndef _PFE_CTRL_HAL_H_
+#define _PFE_CTRL_HAL_H_
+
+#include <linux/timer.h>
+#include <linux/jiffies.h>
+#include <linux/string.h>
+#include <linux/elf.h>
+#include <linux/slab.h>
+#include <asm/byteorder.h>
+#include <asm/io.h>
+
+#include "pfe_mod.h"
+
+#define CLASS_DMEM_SH(var) __attribute__((section(".class_dmem_sh_" #var))) var
+#define CLASS_PE_LMEM_SH(var) __attribute__((section(".class_pe_lmem_sh_" #var))) var
+#define TMU_DMEM_SH(var) __attribute__((section(".tmu_dmem_sh_" #var))) var
+#define UTIL_DMEM_SH(var) __attribute__((section(".util_dmem_sh_" #var))) var
+#define UTIL_DDR_SH(var) __attribute__((section(".util_ddr_sh_" #var))) var
+
+#define CLASS_DMEM_SH2(var) __attribute__((section(".class_dmem_sh_" #var))) class_##var
+#define CLASS_PE_LMEM_SH2(var) __attribute__((section(".class_pe_lmem_sh_" #var))) class_##var
+#define TMU_DMEM_SH2(var) __attribute__((section(".tmu_dmem_sh_" #var))) tmu_##var
+#define UTIL_DMEM_SH2(var) __attribute__((section(".util_dmem_sh_" #var))) util_##var
+
+/** Translate the name of a shared variable to its PFE counterpart.
+ * Those macros may be used to determine the address of a shared variable,
+ * and will work even if the variable is accessed through a macro, as is the case
+ * with most fields of gFppGlobals.
+ */
+#define CONCAT(str, var) str##var
+#define CLASS_VARNAME2(var) CONCAT(class_, var)
+#define UTIL_VARNAME2(var) CONCAT(util_, var)
+#define TMU_VARNAME2(var) CONCAT(tmu_, var)
+
+typedef struct tHostMessage {
+	u16	length;
+	u16	code;
+	u16	data[128];
+} HostMessage;
+
+HostMessage *msg_alloc(void);
+void msg_free(HostMessage *msg);
+int msg_send(HostMessage *msg);
+
+
+unsigned long virt_to_class(void *p);
+unsigned long virt_to_class_dmem(void *p);
+unsigned long virt_to_class_pe_lmem(void *p);
+unsigned long virt_to_tmu_dmem(void *p);
+unsigned long virt_to_util_dmem(void *p);
+unsigned long virt_to_util_ddr(void *p);
+void * virt_to_util_virt(void *p);
+unsigned long virt_to_phys_iram(void *p);
+unsigned long virt_to_phys_ipsec_lmem(void *p);
+unsigned long virt_to_phys_ipsec_axi(void *p);
+
+
+#define TIMER_TICKS_PER_SEC	100
+
+#if TIMER_TICKS_PER_SEC > HZ
+#error TIMER_TICKS_PER_SEC is too high
+#endif
+
+
+typedef void (* TIMER_HANDLER)(void);
+
+typedef struct {
+	struct list_head list;
+	unsigned long timeout;
+	unsigned long period;
+	TIMER_HANDLER handler;
+	char running;
+} TIMER_ENTRY;
+
+
+/** Initializes a timer structure.
+* Must be called once for each TIMER_ENTRY structure.
+* The caller must be holding the ctrl->mutex.
+*
+* @param timer		pointer to the timer to be initialized
+* @param handler	timer handler function pointer
+*
+*/
+void timer_init(TIMER_ENTRY *timer, TIMER_HANDLER handler);
+
+/** Adds a timer to the running timer list.
+* It's safe to call even if the timer was already running. In this case we just update the granularity.
+* The caller must be holding the ctrl->mutex.
+*
+* @param timer		pointer to the timer to be added
+* @param granularity	granularity of the timer (in timer tick units)
+*
+*/
+void timer_add(TIMER_ENTRY *timer, u16 granularity);
+
+/** Deletes a timer from the running timer list.
+* It's safe to call even if the timer is no longer running.
+* The caller must be holding the ctrl->mutex.
+*
+* @param timer	pointer to the timer to be removed
+*/
+void timer_del(TIMER_ENTRY *timer);
+
+void *Heap_Alloc(int size);
+
+#define Heap_Alloc_ARAM(s)	Heap_Alloc(s)
+#define __Heap_Alloc(h, s)		Heap_Alloc(s)
+void Heap_Free(void *p);
+
+#endif /* _PFE_CTRL_HAL_H_ */
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/pfe_debugfs.c
@@ -0,0 +1,109 @@
+/*
+ *  (C) Copyright 2013
+ *  Author : Freescale Technologes
+ *
+ *  See file CREDITS for list of people who contributed to this
+ *  project.
+ *
+ *  This program is free software; you can redistribute it and/or
+ *  modify it under the terms of the GNU General Public License as
+ *  published by the Free Software Foundation; either version 2 of
+ *  the License, or (at your option) any later version.
+ *
+ *  This program is distributed in the hope that it will be useful,
+ *  but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *  GNU General Public License for more details.
+ *
+ *  You should have received a copy of the GNU General Public License
+ *  along with this program; if not, write to the Free Software
+ *  Foundation, Inc., 59 Temple Place, Suite 330, Boston,
+ *  MA 02111-1307 USA
+ * */
+
+#include <linux/module.h>
+#include <linux/debugfs.h>
+#include <linux/platform_device.h>
+
+#include "pfe_mod.h"
+
+static int dmem_show(struct seq_file *s, void *unused)
+{
+	u32 dmem_addr, val;
+	int id = (long int)s->private;
+	int i;
+
+	for (dmem_addr = 0; dmem_addr < CLASS_DMEM_SIZE; dmem_addr += 8 * 4) {
+		seq_printf(s, "%04x:", dmem_addr);
+
+		for (i = 0; i < 8; i++) {
+			val = pe_dmem_read(id, dmem_addr + i * 4, 4);
+			seq_printf(s, " %02x %02x %02x %02x", val & 0xff, (val >> 8) & 0xff, (val >> 16) & 0xff, (val >> 24) & 0xff);
+		}
+
+		seq_printf(s, "\n");
+	}
+
+	return 0;
+}
+
+static int dmem_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, dmem_show, inode->i_private);
+}
+
+static const struct file_operations dmem_fops = {
+	.open		= dmem_open,
+	.read		= seq_read,
+	.llseek		= seq_lseek,
+	.release	= single_release,
+};
+
+int pfe_debugfs_init(struct pfe *pfe)
+{
+	struct dentry *d;
+
+	printk(KERN_INFO "%s\n", __func__);
+
+	pfe->dentry = debugfs_create_dir("pfe", NULL);
+	if (IS_ERR_OR_NULL(pfe->dentry))
+		goto err_dir;
+
+	d = debugfs_create_file("pe0_dmem", S_IRUGO, pfe->dentry, (void *)0, &dmem_fops);
+	if (IS_ERR_OR_NULL(d))
+		goto err_pe;
+
+	d = debugfs_create_file("pe1_dmem", S_IRUGO, pfe->dentry, (void *)1, &dmem_fops);
+	if (IS_ERR_OR_NULL(d))
+		goto err_pe;
+
+	d = debugfs_create_file("pe2_dmem", S_IRUGO, pfe->dentry, (void *)2, &dmem_fops);
+	if (IS_ERR_OR_NULL(d))
+		goto err_pe;
+
+	d = debugfs_create_file("pe3_dmem", S_IRUGO, pfe->dentry, (void *)3, &dmem_fops);
+	if (IS_ERR_OR_NULL(d))
+		goto err_pe;
+
+	d = debugfs_create_file("pe4_dmem", S_IRUGO, pfe->dentry, (void *)4, &dmem_fops);
+	if (IS_ERR_OR_NULL(d))
+		goto err_pe;
+
+	d = debugfs_create_file("pe5_dmem", S_IRUGO, pfe->dentry, (void *)5, &dmem_fops);
+	if (IS_ERR_OR_NULL(d))
+		goto err_pe;
+
+	return 0;
+
+err_pe:
+	debugfs_remove_recursive(pfe->dentry);
+
+err_dir:
+	return -1;
+}
+
+void pfe_debugfs_exit(struct pfe *pfe)
+{
+	debugfs_remove_recursive(pfe->dentry);
+}
+
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/pfe_debugfs.h
@@ -0,0 +1,8 @@
+#ifndef _PFE_DEBUGFS_H_
+#define _PFE_DEBUGFS_H_
+
+int pfe_debugfs_init(struct pfe *pfe);
+void pfe_debugfs_exit(struct pfe *pfe);
+#endif /* _PFE_DEBUGFS_H_ */
+
+
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/pfe_eth.c
@@ -0,0 +1,2956 @@
+/*
+ *
+ *  Copyright (C) 2007 Freescale Semiconductor, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+
+/** @pfe_eth.c.
+ *  Ethernet driver for to handle exception path for PFE.
+ *  - uses HIF functions to send/receive packets.
+ *  - uses ctrl function to start/stop interfaces.
+ *  - uses direct register accesses to control phy operation.
+ */
+#include <linux/version.h>
+#include <linux/kernel.h>
+#include <linux/interrupt.h>
+#include <linux/dma-mapping.h>
+#include <linux/dmapool.h>
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/ethtool.h>
+#include <linux/mii.h>
+#include <linux/phy.h>
+#include <linux/timer.h>
+#include <linux/hrtimer.h>
+#include <linux/platform_device.h>
+
+#include <net/ip.h>
+#include <net/sock.h>
+
+#include <asm/io.h>
+#include <asm/irq.h>
+#include <asm/delay.h>
+#include <linux/regmap.h>
+#include <linux/i2c.h>
+
+#if defined(CONFIG_NF_CONNTRACK_MARK)
+#include <net/netfilter/nf_conntrack.h>
+#endif
+
+#include "pfe_mod.h"
+#include "pfe_eth.h"
+
+const char comcerto_eth_driver_version[]="1.0";
+static void *cbus_emac_base[3];
+static void *cbus_gpi_base[3];
+
+/* Forward Declaration */
+static void pfe_eth_exit_one(struct pfe_eth_priv_s *priv);
+static void pfe_eth_flush_tx(struct pfe_eth_priv_s *priv, int force);
+static void pfe_eth_flush_txQ(struct pfe_eth_priv_s *priv, int txQ_num, int from_tx, int n_desc);
+
+#if defined(CONFIG_PLATFORM_C2000)
+static void pfe_eth_set_device_wakeup(struct pfe *pfe);
+
+
+
+unsigned int gemac_regs[] = {
+	0x0000,	/* Network control */
+	0x0004,	/* Network configuration */
+	0x0008, /* Network status */
+	0x0010, /* DMA configuration */
+	0x0014, /* Transmit status */
+	0x0020, /* Receive status */
+	0x0024, /* Interrupt status */
+	0x0030, /* Interrupt mask */
+	0x0038, /* Received pause quantum */
+	0x003c, /* Transmit pause quantum */
+	0x0080, /* Hash register bottom [31:0] */
+	0x0084, /* Hash register bottom [63:32] */
+	0x0088, /* Specific address 1 bottom [31:0] */
+	0x008c, /* Specific address 1 top [47:32] */
+	0x0090, /* Specific address 2 bottom [31:0] */
+	0x0094, /* Specific address 2 top [47:32] */
+	0x0098, /* Specific address 3 bottom [31:0] */
+	0x009c, /* Specific address 3 top [47:32] */
+	0x00a0, /* Specific address 4 bottom [31:0] */
+	0x00a4, /* Specific address 4 top [47:32] */
+	0x00a8, /* Type ID Match 1 */
+	0x00ac, /* Type ID Match 2 */
+	0x00b0, /* Type ID Match 3 */
+	0x00b4, /* Type ID Match 4 */
+	0x00b8, /* Wake Up ON LAN  */
+	0x00bc, /* IPG stretch register */
+	0x00c0, /* Stacked VLAN Register */
+	0x00fc, /* Module ID */
+	0x07a0  /* EMAC Control register */
+};
+#else
+unsigned int gemac_regs[] = {
+	0x0004, /*Interrupt event */
+	0x0008, /*Interrupt mask */
+	0x0024, /*Ethernet control */
+	0x0064, /*MIB Control/Status */
+	0x0084, /*Receive control/status */
+	0x00C4, /*Transmit control */
+	0x00E4, /*Physical address low */
+	0x00E8, /*Physical address high */
+	0x0144, /*Transmit FIFO Watermark and Store and Forward Control*/
+	0x0190, /* Receive FIFO Section Full Threshold */
+	0x01A0, /* Transmit FIFO Section Empty Threshold */
+	0x01B0, /* Frame Truncation Length */
+};
+#endif
+/********************************************************************/
+/*                   SYSFS INTERFACE				    */
+/********************************************************************/
+
+
+
+#ifdef PFE_ETH_NAPI_STATS
+/*
+ * pfe_eth_show_napi_stats
+ */
+static ssize_t pfe_eth_show_napi_stats(struct device *dev,
+		struct device_attribute *attr, char *buf)
+{
+	struct pfe_eth_priv_s *priv = netdev_priv(to_net_dev(dev));
+	ssize_t len = 0;
+
+	len += sprintf(buf + len, "sched:  %u\n", priv->napi_counters[NAPI_SCHED_COUNT]);
+	len += sprintf(buf + len, "poll:   %u\n", priv->napi_counters[NAPI_POLL_COUNT]);
+	len += sprintf(buf + len, "packet: %u\n", priv->napi_counters[NAPI_PACKET_COUNT]);
+	len += sprintf(buf + len, "budget: %u\n", priv->napi_counters[NAPI_FULL_BUDGET_COUNT]);
+	len += sprintf(buf + len, "desc:   %u\n", priv->napi_counters[NAPI_DESC_COUNT]);
+
+	return len;
+}
+
+/*
+ * pfe_eth_set_napi_stats
+ */
+static ssize_t pfe_eth_set_napi_stats(struct device *dev,
+		struct device_attribute *attr, const char *buf, size_t count)
+{
+	struct pfe_eth_priv_s *priv = netdev_priv(to_net_dev(dev));
+
+	memset(priv->napi_counters, 0, sizeof(priv->napi_counters));
+
+	return count;
+}
+#endif
+#ifdef PFE_ETH_TX_STATS
+/** pfe_eth_show_tx_stats
+ *
+ */
+static ssize_t pfe_eth_show_tx_stats(struct device *dev,
+		struct device_attribute *attr, char *buf)
+{
+	struct pfe_eth_priv_s *priv = netdev_priv(to_net_dev(dev));
+	ssize_t len = 0;
+	int i;
+
+	len += sprintf(buf + len, "TX queues stats:\n");
+
+	for (i = 0; i < emac_txq_cnt; i++) {
+		struct netdev_queue *tx_queue = netdev_get_tx_queue(priv->dev, i); 
+
+		len += sprintf(buf + len, "\n");
+		__netif_tx_lock_bh(tx_queue);
+
+		hif_tx_lock(&pfe->hif);
+		len += sprintf(buf + len, "Queue %2d :  credits               = %10d\n", i, hif_lib_tx_credit_avail(pfe, priv->id, i));
+		len += sprintf(buf + len, "            tx packets            = %10d\n",  pfe->tmu_credit.tx_packets[priv->id][i]);
+		hif_tx_unlock(&pfe->hif);
+
+		/* Don't output additionnal stats if queue never used */
+		if (!pfe->tmu_credit.tx_packets[priv->id][i])
+			goto skip;
+
+		len += sprintf(buf + len, "            clean_fail            = %10d\n", priv->clean_fail[i]);
+		len += sprintf(buf + len, "            stop_queue            = %10d\n", priv->stop_queue_total[i]);
+		len += sprintf(buf + len, "            stop_queue_hif        = %10d\n", priv->stop_queue_hif[i]);
+		len += sprintf(buf + len, "            stop_queue_hif_client = %10d\n", priv->stop_queue_hif_client[i]);
+		len += sprintf(buf + len, "            stop_queue_credit     = %10d\n", priv->stop_queue_credit[i]);
+skip:
+		__netif_tx_unlock_bh(tx_queue);
+	}
+	return len;
+}
+
+/** pfe_eth_set_tx_stats
+ *
+ */
+static ssize_t pfe_eth_set_tx_stats(struct device *dev,
+		struct device_attribute *attr, const char *buf, size_t count)
+{
+	struct pfe_eth_priv_s *priv = netdev_priv(to_net_dev(dev));
+	int i;
+
+	for (i = 0; i < emac_txq_cnt; i++) {
+		struct netdev_queue *tx_queue = netdev_get_tx_queue(priv->dev, i); 
+
+		__netif_tx_lock_bh(tx_queue);
+		priv->clean_fail[i] = 0;
+		priv->stop_queue_total[i] = 0;
+		priv->stop_queue_hif[i] = 0;
+		priv->stop_queue_hif_client[i]= 0;
+		priv->stop_queue_credit[i] = 0;
+		__netif_tx_unlock_bh(tx_queue);
+	}
+
+	return count;
+}
+#endif
+/** pfe_eth_show_txavail
+ *
+ */
+static ssize_t pfe_eth_show_txavail(struct device *dev,
+		struct device_attribute *attr, char *buf)
+{
+	struct pfe_eth_priv_s *priv = netdev_priv(to_net_dev(dev));
+	ssize_t len = 0;
+	int i;
+
+	for (i = 0; i < emac_txq_cnt; i++) {
+		struct netdev_queue *tx_queue = netdev_get_tx_queue(priv->dev, i); 
+
+		__netif_tx_lock_bh(tx_queue);
+
+		len += sprintf(buf + len, "%d", hif_lib_tx_avail(&priv->client, i));
+
+		__netif_tx_unlock_bh(tx_queue);
+
+		if (i == (emac_txq_cnt - 1))
+			len += sprintf(buf + len, "\n");
+		else
+			len += sprintf(buf + len, " ");
+	}
+
+	return len;
+}
+
+
+/** pfe_eth_show_default_priority
+ *
+ */ 
+static ssize_t pfe_eth_show_default_priority(struct device *dev,
+		struct device_attribute *attr,
+		char *buf)
+{
+	struct pfe_eth_priv_s *priv = netdev_priv(to_net_dev(dev));
+	unsigned long flags;
+	int rc;
+
+	spin_lock_irqsave(&priv->lock, flags);
+	rc = sprintf(buf, "%d\n", priv->default_priority);
+	spin_unlock_irqrestore(&priv->lock, flags);
+
+	return rc;
+}
+
+/** pfe_eth_set_default_priority
+ *
+ */
+
+static ssize_t pfe_eth_set_default_priority(struct device *dev,
+		struct device_attribute *attr,
+		const char *buf, size_t count)
+{
+	struct pfe_eth_priv_s *priv = netdev_priv(to_net_dev(dev));
+	unsigned long flags;
+
+	spin_lock_irqsave(&priv->lock, flags);
+	priv->default_priority = simple_strtoul(buf, NULL, 0);
+	spin_unlock_irqrestore(&priv->lock, flags);
+
+	return count;
+}
+
+static DEVICE_ATTR(txavail, 0444, pfe_eth_show_txavail, NULL);
+static DEVICE_ATTR(default_priority, 0644, pfe_eth_show_default_priority, pfe_eth_set_default_priority);
+
+#ifdef PFE_ETH_NAPI_STATS
+static DEVICE_ATTR(napi_stats, 0644, pfe_eth_show_napi_stats, pfe_eth_set_napi_stats);
+#endif
+
+#ifdef PFE_ETH_TX_STATS
+static DEVICE_ATTR(tx_stats, 0644, pfe_eth_show_tx_stats, pfe_eth_set_tx_stats);
+#endif
+
+
+/** pfe_eth_sysfs_init
+ *
+ */
+static int pfe_eth_sysfs_init(struct net_device *dev)
+{
+	struct pfe_eth_priv_s *priv = netdev_priv(dev);
+	int err;
+
+	/* Initialize the default values */
+	/* By default, packets without conntrack will use this default high priority queue */
+	priv->default_priority = 15;
+
+	/* Create our sysfs files */
+	err = device_create_file(&dev->dev, &dev_attr_default_priority);
+	if (err) {
+		netdev_err(dev, "failed to create default_priority sysfs files\n");
+		goto err_priority;
+	}
+
+	err = device_create_file(&dev->dev, &dev_attr_txavail);
+	if (err) {
+		netdev_err(dev, "failed to create default_priority sysfs files\n");
+		goto err_txavail;
+	}
+
+#ifdef PFE_ETH_NAPI_STATS
+	err = device_create_file(&dev->dev, &dev_attr_napi_stats);
+	if (err) {
+		netdev_err(dev, "failed to create napi stats sysfs files\n");
+		goto err_napi;
+	}
+#endif
+
+#ifdef PFE_ETH_TX_STATS
+	err = device_create_file(&dev->dev, &dev_attr_tx_stats);
+	if (err) {
+		netdev_err(dev, "failed to create tx stats sysfs files\n");
+		goto err_tx;
+	}
+#endif
+
+	return 0;
+
+#ifdef PFE_ETH_TX_STATS
+err_tx:
+#endif
+#ifdef PFE_ETH_NAPI_STATS
+	device_remove_file(&dev->dev, &dev_attr_napi_stats);
+
+err_napi:
+#endif
+	device_remove_file(&dev->dev, &dev_attr_txavail);
+
+err_txavail:
+	device_remove_file(&dev->dev, &dev_attr_default_priority);
+
+err_priority:
+	return -1;
+}
+
+/** pfe_eth_sysfs_exit
+ *
+ */
+void pfe_eth_sysfs_exit(struct net_device *dev)
+{
+#ifdef PFE_ETH_TX_STATS
+	device_remove_file(&dev->dev, &dev_attr_tx_stats);
+#endif
+
+#ifdef PFE_ETH_NAPI_STATS
+	device_remove_file(&dev->dev, &dev_attr_napi_stats);
+#endif
+	device_remove_file(&dev->dev, &dev_attr_txavail);
+	device_remove_file(&dev->dev, &dev_attr_default_priority);
+}
+
+/*************************************************************************/
+/*		ETHTOOL INTERCAE					 */
+/*************************************************************************/
+
+#if defined(CONFIG_PLATFORM_C2000)
+static char stat_gstrings[][ETH_GSTRING_LEN] = {
+	"tx- octets",
+	"tx- packets",
+	"tx- broadcast",
+	"tx- multicast",
+	"tx- pause",
+	"tx- 64 bytes packets",
+	"tx- 64 - 127 bytes packets",
+	"tx- 128 - 255 bytes packets",
+	"tx- 256 - 511 bytes packets",
+	"tx- 512 - 1023 bytes packets",
+	"tx- 1024 - 1518 bytes packets",
+	"tx- > 1518 bytes packets",
+	"tx- underruns  - errors",
+	"tx- single collision",
+	"tx- multi collision",
+	"tx- exces. collision  - errors",
+	"tx- late collision  - errors",
+	"tx- deferred",
+	"tx- carrier sense - errors",
+	"rx- octets",
+	"rx- packets",
+	"rx- broadcast",
+	"rx- multicast",
+	"rx- pause",
+	"rx- 64 bytes packets",
+	"rx- 64 - 127 bytes packets",
+	"rx- 128 - 255 bytes packets",
+	"rx- 256 - 511 bytes packets",
+	"rx- 512 - 1023 bytes packets",
+	"rx- 1024 - 1518 bytes packets",
+	"rx- > 1518 bytes packets",
+	"rx- undersize -errors",
+	"rx- oversize  - errors ",
+	"rx- jabbers - errors",
+	"rx- fcs - errors",
+	"rx- length - errors",
+	"rx- symbol - errors",
+	"rx- align - errors",
+	"rx- ressource - errors",
+	"rx- overrun - errors",
+	"rx- IP cksum - errors",
+	"rx- TCP cksum - errors",
+	"rx- UDP cksum - errors"
+};
+
+
+/**
+ * pfe_eth_gstrings - Fill in a buffer with the strings which correspond to
+ *                    the stats.
+ *
+ */
+static void pfe_eth_gstrings(struct net_device *dev, u32 stringset, u8 * buf)
+{
+	switch (stringset) {
+		case ETH_SS_STATS:
+			memcpy(buf, stat_gstrings, (EMAC_RMON_LEN - 2) * ETH_GSTRING_LEN);
+			break;
+
+		default:
+			WARN_ON(1);
+			break;
+	}
+}
+
+/** 
+ * pfe_eth_fill_stats - Fill in an array of 64-bit statistics from 
+ *			various sources. This array will be appended 
+ *			to the end of the ethtool_stats* structure, and 
+ *			returned to user space
+ */
+static void pfe_eth_fill_stats(struct net_device *dev, struct ethtool_stats *dummy, u64 * buf)
+{
+	struct pfe_eth_priv_s *priv = netdev_priv(dev);
+	int i;
+	for (i=0;i<EMAC_RMON_LEN;i++, buf++) {
+		*buf = readl(priv->EMAC_baseaddr + EMAC_RMON_BASE_OFST + (i << 2));	
+		if ( ( i == EMAC_RMON_TXBYTES_POS ) || ( i == EMAC_RMON_RXBYTES_POS ) ){
+			i++;
+			*buf |= (u64)readl(priv->EMAC_baseaddr + EMAC_RMON_BASE_OFST + (i << 2)) << 32;
+		}
+	}
+
+}
+
+/**
+ * pfe_eth_stats_count - Returns the number of stats (and their corresponding strings) 
+ *
+ */
+static int pfe_eth_stats_count(struct net_device *dev, int sset)
+{
+	switch (sset) {
+		case ETH_SS_STATS:
+			return EMAC_RMON_LEN - 2;
+		default:
+			return -EOPNOTSUPP;
+	}
+}
+
+#if defined(CONFIG_PLATFORM_C2000)
+/**
+ * pfe_eth_set_wol - Set the magic packet option, in WoL register.
+ *
+ */
+static int pfe_eth_set_wol(struct net_device *dev, struct ethtool_wolinfo *wol)
+{
+	struct pfe_eth_priv_s *priv = netdev_priv(dev);
+
+	if (wol->wolopts & ~(WAKE_MAGIC | WAKE_ARP | WAKE_MCAST | WAKE_UCAST))
+		return -EOPNOTSUPP;
+
+	priv->wol = 0;
+
+	if (wol->wolopts & WAKE_MAGIC)
+		 priv->wol |= EMAC_WOL_MAGIC;
+	if (wol->wolopts & WAKE_ARP)
+		 priv->wol |= EMAC_WOL_ARP;
+	if (wol->wolopts & WAKE_MCAST)
+		 priv->wol |= EMAC_WOL_MULTI;
+	if (wol->wolopts & WAKE_UCAST)
+		 priv->wol |= EMAC_WOL_SPEC_ADDR;
+
+	pfe_eth_set_device_wakeup(priv->pfe);
+
+	return 0;
+}
+
+/**
+ *
+ * pfe_eth_get_wol - Get the WoL options.
+ *
+ */
+static void pfe_eth_get_wol(struct net_device *dev, struct ethtool_wolinfo *wol)
+{
+	struct pfe_eth_priv_s *priv = netdev_priv(dev);
+
+	wol->supported = (WAKE_MAGIC | WAKE_ARP | WAKE_MCAST | WAKE_UCAST);
+	wol->wolopts = 0;
+
+	if(priv->wol & EMAC_WOL_MAGIC)
+		wol->wolopts |= WAKE_MAGIC;
+	if(priv->wol & EMAC_WOL_ARP)
+		wol->wolopts |= WAKE_ARP;
+	if(priv->wol & EMAC_WOL_MULTI)
+		wol->wolopts |= WAKE_UCAST;
+	if(priv->wol & EMAC_WOL_SPEC_ADDR)
+		wol->wolopts |= WAKE_UCAST;
+
+	memset(&wol->sopass, 0, sizeof(wol->sopass));
+}
+#endif
+/**
+ * pfe_eth_gemac_reglen - Return the length of the register structure.
+ *
+ */
+static int pfe_eth_gemac_reglen(struct net_device *dev)
+{
+	return (sizeof (gemac_regs)/ sizeof(u32)) + (( MAX_UC_SPEC_ADDR_REG - 3 ) * 2);
+}
+
+/**
+ * pfe_eth_gemac_get_regs - Return the gemac register structure.
+ *
+ */
+static void  pfe_eth_gemac_get_regs(struct net_device *dev, struct ethtool_regs *regs, void *regbuf)
+{
+	int i,j;
+	struct pfe_eth_priv_s *priv = netdev_priv(dev);
+	u32 *buf = (u32 *) regbuf;
+
+	for (i = 0; i < sizeof (gemac_regs) / sizeof (u32); i++)
+		buf[i] = readl( priv->EMAC_baseaddr + gemac_regs[i] );
+
+	for (j = 0; j < (( MAX_UC_SPEC_ADDR_REG - 3 ) * 2); j++,i++)
+		buf[i] = readl( priv->EMAC_baseaddr + EMAC_SPEC5_ADD_BOT + (j<<2) );
+
+}
+
+
+#else //if defined(CONFIG_PLATFORM_C2000)
+/*MTIP GEMAC */
+static const struct fec_stat {
+	char name[ETH_GSTRING_LEN];
+	u16 offset;
+} fec_stats[] = {
+	/* RMON TX */
+	{ "tx_dropped", RMON_T_DROP },
+	{ "tx_packets", RMON_T_PACKETS },
+	{ "tx_broadcast", RMON_T_BC_PKT },
+	{ "tx_multicast", RMON_T_MC_PKT },
+	{ "tx_crc_errors", RMON_T_CRC_ALIGN },
+	{ "tx_undersize", RMON_T_UNDERSIZE },
+	{ "tx_oversize", RMON_T_OVERSIZE },
+	{ "tx_fragment", RMON_T_FRAG },
+	{ "tx_jabber", RMON_T_JAB },
+	{ "tx_collision", RMON_T_COL },
+	{ "tx_64byte", RMON_T_P64 },
+	{ "tx_65to127byte", RMON_T_P65TO127 },
+	{ "tx_128to255byte", RMON_T_P128TO255 },
+	{ "tx_256to511byte", RMON_T_P256TO511 },
+	{ "tx_512to1023byte", RMON_T_P512TO1023 },
+	{ "tx_1024to2047byte", RMON_T_P1024TO2047 },
+	{ "tx_GTE2048byte", RMON_T_P_GTE2048 },
+	{ "tx_octets", RMON_T_OCTETS },
+
+	/* IEEE TX */
+	{ "IEEE_tx_drop", IEEE_T_DROP },
+	{ "IEEE_tx_frame_ok", IEEE_T_FRAME_OK },
+	{ "IEEE_tx_1col", IEEE_T_1COL },
+	{ "IEEE_tx_mcol", IEEE_T_MCOL },
+	{ "IEEE_tx_def", IEEE_T_DEF },
+	{ "IEEE_tx_lcol", IEEE_T_LCOL },
+	{ "IEEE_tx_excol", IEEE_T_EXCOL },
+	{ "IEEE_tx_macerr", IEEE_T_MACERR },
+	{ "IEEE_tx_cserr", IEEE_T_CSERR },
+	{ "IEEE_tx_sqe", IEEE_T_SQE },
+	{ "IEEE_tx_fdxfc", IEEE_T_FDXFC },
+	{ "IEEE_tx_octets_ok", IEEE_T_OCTETS_OK },
+
+	/* RMON RX */
+	{ "rx_packets", RMON_R_PACKETS },
+	{ "rx_broadcast", RMON_R_BC_PKT },
+	{ "rx_multicast", RMON_R_MC_PKT },
+	{ "rx_crc_errors", RMON_R_CRC_ALIGN },
+	{ "rx_undersize", RMON_R_UNDERSIZE },
+	{ "rx_oversize", RMON_R_OVERSIZE },
+	{ "rx_fragment", RMON_R_FRAG },
+	{ "rx_jabber", RMON_R_JAB },
+	{ "rx_64byte", RMON_R_P64 },
+	{ "rx_65to127byte", RMON_R_P65TO127 },
+	{ "rx_128to255byte", RMON_R_P128TO255 },
+	{ "rx_256to511byte", RMON_R_P256TO511 },
+	{ "rx_512to1023byte", RMON_R_P512TO1023 },
+	{ "rx_1024to2047byte", RMON_R_P1024TO2047 },
+	{ "rx_GTE2048byte", RMON_R_P_GTE2048 },
+	{ "rx_octets", RMON_R_OCTETS },
+
+	/* IEEE RX */
+	{ "IEEE_rx_drop", IEEE_R_DROP },
+	{ "IEEE_rx_frame_ok", IEEE_R_FRAME_OK },
+	{ "IEEE_rx_crc", IEEE_R_CRC },
+	{ "IEEE_rx_align", IEEE_R_ALIGN },
+	{ "IEEE_rx_macerr", IEEE_R_MACERR },
+	{ "IEEE_rx_fdxfc", IEEE_R_FDXFC },
+	{ "IEEE_rx_octets_ok", IEEE_R_OCTETS_OK },
+};
+
+static void pfe_eth_fill_stats(struct net_device *dev, struct ethtool_stats *stats, u64 *data)
+{
+	struct pfe_eth_priv_s *priv = netdev_priv(dev);
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(fec_stats); i++)
+		data[i] = readl(priv->EMAC_baseaddr + fec_stats[i].offset);
+}
+
+static void pfe_eth_gstrings(struct net_device *netdev,
+	u32 stringset, u8 *data)
+{
+	int i;
+	switch (stringset) {
+	case ETH_SS_STATS:
+		for (i = 0; i < ARRAY_SIZE(fec_stats); i++)
+			memcpy(data + i * ETH_GSTRING_LEN,
+				fec_stats[i].name, ETH_GSTRING_LEN);
+		break;
+	}
+}
+
+static int pfe_eth_stats_count(struct net_device *dev, int sset)
+{
+	switch (sset) {
+	case ETH_SS_STATS:
+		return ARRAY_SIZE(fec_stats);
+	default:
+		return -EOPNOTSUPP;
+	}
+}
+
+/**
+ * pfe_eth_gemac_reglen - Return the length of the register structure.
+ *
+ */
+static int pfe_eth_gemac_reglen(struct net_device *dev)
+{
+	printk("%s() \n", __func__);
+	return (sizeof (gemac_regs)/ sizeof(u32)) ;
+}
+
+/**
+ * pfe_eth_gemac_get_regs - Return the gemac register structure.
+ *
+ */
+static void  pfe_eth_gemac_get_regs(struct net_device *dev, struct ethtool_regs *regs, void *regbuf)
+{
+	int i;
+	struct pfe_eth_priv_s *priv = netdev_priv(dev);
+	u32 *buf = (u32 *) regbuf;
+
+	printk("%s() \n", __func__);
+	for (i = 0; i < sizeof (gemac_regs) / sizeof (u32); i++)
+		buf[i] = readl( priv->EMAC_baseaddr + gemac_regs[i] );
+
+}
+
+
+#endif
+
+/**
+ * pfe_eth_get_drvinfo -  Fills in the drvinfo structure with some basic info 
+ *
+ */
+static void pfe_eth_get_drvinfo(struct net_device *dev, struct ethtool_drvinfo *drvinfo)
+{
+	strncpy(drvinfo->driver, DRV_NAME, COMCERTO_INFOSTR_LEN);
+	strncpy(drvinfo->version, comcerto_eth_driver_version, COMCERTO_INFOSTR_LEN);
+	strncpy(drvinfo->fw_version, "N/A", COMCERTO_INFOSTR_LEN);
+	strncpy(drvinfo->bus_info, "N/A", COMCERTO_INFOSTR_LEN);
+	drvinfo->testinfo_len = 0;
+	drvinfo->regdump_len = 0;
+	drvinfo->eedump_len = 0;
+}
+
+/**
+ * pfe_eth_set_settings - Used to send commands to PHY. 
+ *
+ */
+
+static int pfe_eth_set_settings(struct net_device *dev, struct ethtool_cmd *cmd)
+{
+	struct pfe_eth_priv_s *priv = netdev_priv(dev);
+	struct phy_device *phydev = priv->phydev;
+
+	if (NULL == phydev)
+		return -ENODEV;
+
+	return phy_ethtool_sset(phydev, cmd);
+}
+
+
+/**
+ * pfe_eth_getsettings - Return the current settings in the ethtool_cmd structure.
+ *
+ */
+static int pfe_eth_get_settings(struct net_device *dev, struct ethtool_cmd *cmd)
+{
+	struct pfe_eth_priv_s *priv = netdev_priv(dev);
+	struct phy_device *phydev = priv->phydev;
+
+	if (NULL == phydev)
+		return -ENODEV;
+
+	return phy_ethtool_gset(phydev, cmd);
+}
+
+
+/**
+ * pfe_eth_get_msglevel - Gets the debug message mask.
+ *
+ */
+static uint32_t pfe_eth_get_msglevel(struct net_device *dev)
+{
+	struct pfe_eth_priv_s *priv = netdev_priv(dev);
+
+	return priv->msg_enable;
+}
+
+/**
+ * pfe_eth_set_msglevel - Sets the debug message mask.
+ *
+ */
+static void pfe_eth_set_msglevel(struct net_device *dev, uint32_t data)
+{
+	struct pfe_eth_priv_s *priv = netdev_priv(dev);
+
+	priv->msg_enable = data;
+}
+
+#define HIF_RX_COAL_MAX_CLKS		(~(1<<31))
+#define HIF_RX_COAL_CLKS_PER_USEC	(pfe->ctrl.sys_clk/1000)
+#define HIF_RX_COAL_MAX_USECS		(HIF_RX_COAL_MAX_CLKS/HIF_RX_COAL_CLKS_PER_USEC)
+
+/**
+ * pfe_eth_set_coalesce - Sets rx interrupt coalescing timer.
+ *
+ */
+static int pfe_eth_set_coalesce(struct net_device *dev,
+                              struct ethtool_coalesce *ec)
+{
+	if (ec->rx_coalesce_usecs > HIF_RX_COAL_MAX_USECS)
+		  return -EINVAL;
+
+	if (!ec->rx_coalesce_usecs) {
+		writel(0, HIF_INT_COAL);
+		return 0;
+	}
+
+	writel((ec->rx_coalesce_usecs * HIF_RX_COAL_CLKS_PER_USEC) | HIF_INT_COAL_ENABLE, HIF_INT_COAL);
+
+	return 0;
+}
+
+/**
+ * pfe_eth_get_coalesce - Gets rx interrupt coalescing timer value.
+ *
+ */
+static int pfe_eth_get_coalesce(struct net_device *dev,
+                              struct ethtool_coalesce *ec)
+{
+	int reg_val = readl(HIF_INT_COAL);
+
+	if (reg_val & HIF_INT_COAL_ENABLE)
+		ec->rx_coalesce_usecs = (reg_val & HIF_RX_COAL_MAX_CLKS) / HIF_RX_COAL_CLKS_PER_USEC;
+	else
+		ec->rx_coalesce_usecs = 0;
+
+        return 0;
+}
+
+#if defined(CONFIG_PLATFORM_C2000)
+/**
+ * pfe_eth_pause_rx_enabled - Tests if pause rx is enabled on GEM
+ *
+ */
+static int pfe_eth_pause_rx_enabled(struct pfe_eth_priv_s *priv)
+{
+	return (readl(priv->EMAC_baseaddr + EMAC_NETWORK_CONFIG) & EMAC_ENABLE_PAUSE_RX) != 0;
+}
+
+/**
+ * pfe_eth_set_pauseparam - Sets pause parameters
+ *
+ */
+static int pfe_eth_set_pauseparam(struct net_device *dev, struct ethtool_pauseparam *epause)
+{
+	struct pfe_eth_priv_s *priv = netdev_priv(dev);
+
+	if (epause->rx_pause)
+	{
+		gemac_enable_pause_rx(priv->EMAC_baseaddr);
+		if (priv->phydev)
+			priv->phydev->advertising |= ADVERTISED_Pause | ADVERTISED_Asym_Pause;
+	}
+	else
+	{
+		gemac_disable_pause_rx(priv->EMAC_baseaddr);
+		if (priv->phydev)
+			priv->phydev->advertising &= ~(ADVERTISED_Pause | ADVERTISED_Asym_Pause);
+	}
+
+	return 0;
+}
+
+/**
+ * pfe_eth_get_pauseparam - Gets pause parameters
+ *
+ */
+static void pfe_eth_get_pauseparam(struct net_device *dev, struct ethtool_pauseparam *epause)
+{
+	struct pfe_eth_priv_s *priv = netdev_priv(dev);
+
+	epause->autoneg = 0;
+	epause->tx_pause = 0;
+	epause->rx_pause = pfe_eth_pause_rx_enabled(priv);
+}
+
+/** pfe_eth_get_hash
+ */
+static int pfe_eth_get_hash(u8 * addr)
+{
+	u8 temp1,temp2,temp3,temp4,temp5,temp6,temp7,temp8;
+	temp1 = addr[0] & 0x3F ;
+	temp2 = ((addr[0] & 0xC0)  >> 6)| ((addr[1] & 0x0F) << 2);
+	temp3 = ((addr[1] & 0xF0) >> 4) | ((addr[2] & 0x03) << 4);
+	temp4 = (addr[2] & 0xFC) >> 2;
+	temp5 = addr[3] & 0x3F;
+	temp6 = ((addr[3] & 0xC0) >> 6) | ((addr[4] & 0x0F) << 2);
+	temp7 = ((addr[4] & 0xF0) >>4 ) | ((addr[5] & 0x03) << 4);
+	temp8 = ((addr[5] &0xFC) >> 2);
+	return (temp1 ^ temp2 ^ temp3 ^ temp4 ^ temp5 ^ temp6 ^ temp7 ^ temp8);
+}
+
+#else
+	/*TODO Add pause frame support for LS1012A */
+
+/** pfe_eth_get_hash
+ */
+#define HASH_BITS	6		/* #bits in hash */
+#define CRC32_POLY	0xEDB88320
+
+static int pfe_eth_get_hash(u8 * addr)
+{
+	unsigned int i, bit, data, crc, hash;
+
+	/* calculate crc32 value of mac address */
+	crc = 0xffffffff;
+
+	for (i = 0; i < 6; i++) {
+		data = addr[i];
+		for (bit = 0; bit < 8; bit++, data >>= 1) {
+			crc = (crc >> 1) ^
+				(((crc ^ data) & 1) ? CRC32_POLY : 0);
+		}
+	}
+
+	/* only upper 6 bits (HASH_BITS) are used
+	 * which point to specific bit in he hash registers
+	 */
+	hash = (crc >> (32 - HASH_BITS)) & 0x3f;
+
+	return hash;
+}
+
+#endif
+
+struct ethtool_ops pfe_ethtool_ops = {
+	.get_settings = pfe_eth_get_settings,
+	.set_settings = pfe_eth_set_settings,
+	.get_drvinfo = pfe_eth_get_drvinfo,
+	.get_regs_len = pfe_eth_gemac_reglen,
+	.get_regs = pfe_eth_gemac_get_regs,
+	.get_link = ethtool_op_get_link,
+#if defined(CONFIG_PLATFORM_C2000)
+	.get_wol  = pfe_eth_get_wol,
+	.set_wol  = pfe_eth_set_wol,
+	.set_pauseparam = pfe_eth_set_pauseparam,
+	.get_pauseparam = pfe_eth_get_pauseparam,
+#endif
+	.get_strings = pfe_eth_gstrings,
+	.get_sset_count = pfe_eth_stats_count,
+	.get_ethtool_stats = pfe_eth_fill_stats,
+	.get_msglevel = pfe_eth_get_msglevel,
+	.set_msglevel = pfe_eth_set_msglevel,
+	.set_coalesce = pfe_eth_set_coalesce,
+	.get_coalesce = pfe_eth_get_coalesce,
+};
+
+
+
+#if defined(CONFIG_PLATFORM_C2000)
+/** pfe_eth_mdio_reset
+ */
+int pfe_eth_mdio_reset(struct mii_bus *bus)
+{
+	struct pfe_eth_priv_s *priv = (struct pfe_eth_priv_s *)bus->priv;
+
+	netif_info(priv, hw, priv->dev, "%s\n", __func__);
+
+#if !defined(CONFIG_PLATFORM_EMULATION)
+	mutex_lock(&bus->mdio_lock);
+
+	/* Setup the MII Mgmt clock speed */
+	if (priv->mii_bus)
+		gemac_set_mdc_div(priv->EMAC_baseaddr, priv->mdc_div);
+
+	/* Reset the management interface */
+	__raw_writel(__raw_readl(priv->EMAC_baseaddr + EMAC_NETWORK_CONTROL) | EMAC_MDIO_EN, 
+			priv->EMAC_baseaddr + EMAC_NETWORK_CONTROL);
+
+	/* Wait until the bus is free */
+	while(!(__raw_readl(priv->EMAC_baseaddr + EMAC_NETWORK_STATUS) & EMAC_PHY_IDLE));
+
+	mutex_unlock(&bus->mdio_lock);
+#endif
+
+	return 0;
+}
+
+
+/** pfe_eth_gemac_phy_timeout
+ *
+ */
+static int pfe_eth_gemac_phy_timeout(struct pfe_eth_priv_s *priv, int timeout)
+{
+	while(!(__raw_readl(priv->EMAC_baseaddr + EMAC_NETWORK_STATUS) & EMAC_PHY_IDLE)) {
+
+		if (timeout-- <= 0) {
+			return -1;
+		}
+
+		udelay(10);
+	}
+
+	return 0;
+}
+
+
+/** pfe_eth_mdio_write
+ */
+static int pfe_eth_mdio_write(struct mii_bus *bus, int mii_id, int regnum, u16 value)
+{
+	struct pfe_eth_priv_s *priv = (struct pfe_eth_priv_s *)bus->priv;
+	u32 write_data;
+
+#if !defined(CONFIG_PLATFORM_EMULATION)
+
+	netif_info(priv, hw, priv->dev, "%s: phy %d\n", __func__, mii_id);
+
+//	netif_info(priv, hw, priv->dev, "%s %d %d %x\n", bus->id, mii_id, regnum, value);
+
+	write_data = 0x50020000;
+	write_data |= ((mii_id << 23) | (regnum << 18) | value);
+	__raw_writel(write_data, priv->EMAC_baseaddr + EMAC_PHY_MANAGEMENT);
+
+	if (pfe_eth_gemac_phy_timeout(priv, EMAC_MDIO_TIMEOUT)){
+		netdev_err(priv->dev, "%s: phy MDIO write timeout\n", __func__);
+		return -1;
+	}
+
+#endif
+
+	return 0;
+}
+
+
+/** pfe_eth_mdio_read
+ */
+static int pfe_eth_mdio_read(struct mii_bus *bus, int mii_id, int regnum)
+{
+	struct pfe_eth_priv_s *priv = (struct pfe_eth_priv_s *)bus->priv;
+	u16 value = 0;
+	u32 write_data;
+
+#if !defined(CONFIG_PLATFORM_EMULATION)
+	netif_info(priv, hw, priv->dev, "%s: phy %d\n", __func__, mii_id);
+
+	write_data = 0x60020000;
+	write_data |= ((mii_id << 23) | (regnum << 18));
+
+	__raw_writel(write_data, priv->EMAC_baseaddr + EMAC_PHY_MANAGEMENT);
+
+	if (pfe_eth_gemac_phy_timeout( priv, EMAC_MDIO_TIMEOUT))	{
+		netdev_err(priv->dev, "%s: phy MDIO read timeout\n", __func__);
+		return -1;	
+	}
+
+	value = __raw_readl(priv->EMAC_baseaddr + EMAC_PHY_MANAGEMENT) & 0xFFFF;
+#endif
+
+//	netif_info(priv, hw, priv->dev, "%s %d %d %x\n", bus->id, mii_id, regnum, value);
+
+	return value;
+}
+
+#else
+/** pfe_eth_mdio_reset
+ */
+int pfe_eth_mdio_reset(struct mii_bus *bus)
+{
+	struct pfe_eth_priv_s *priv = (struct pfe_eth_priv_s *)bus->priv;
+	u32 phy_speed, pclk = 250000000; /*TODO this needs to be checked read from the correct source*/
+
+	netif_info(priv, hw, priv->dev, "%s\n", __func__);
+
+	mutex_lock(&bus->mdio_lock);
+
+	/*
+	 * Set MII speed to 2.5 MHz (= clk_get_rate() / 2 * phy_speed)
+	 *
+	 * The formula for FEC MDC is 'ref_freq / (MII_SPEED x 2)' while
+	 * for ENET-MAC is 'ref_freq / ((MII_SPEED + 1) x 2)'.
+	 */
+	phy_speed = (DIV_ROUND_UP(pclk, 4000000) << EMAC_MII_SPEED_SHIFT);
+	phy_speed |= EMAC_HOLDTIME(0x5);
+	__raw_writel(phy_speed, priv->PHY_baseaddr + EMAC_MII_CTRL_REG);
+
+	mutex_unlock(&bus->mdio_lock);
+
+	return 0;
+}
+
+/** pfe_eth_gemac_phy_timeout
+ *
+ */
+static int pfe_eth_gemac_phy_timeout(struct pfe_eth_priv_s *priv, int timeout)
+{
+	while(!(__raw_readl(priv->PHY_baseaddr + EMAC_IEVENT_REG) & EMAC_IEVENT_MII)) {
+
+		if (timeout-- <= 0) {
+			return -1;
+		}
+
+		udelay(10);
+	}
+	__raw_writel(EMAC_IEVENT_MII, priv->PHY_baseaddr + EMAC_IEVENT_REG);
+
+	return 0;
+}
+
+static int pfe_eth_mdio_mux(u8 muxval)
+{
+	struct i2c_adapter *a;
+	struct i2c_msg msg;
+	unsigned char buf[2];
+	int ret;
+
+	a = i2c_get_adapter(0);
+        if (!a)
+                return -ENODEV;
+
+        /* set bit 1 (the second bit) of chip at 0x09, register 0x13 */
+        buf[0] = 0x54; //reg number
+        buf[1] = (muxval << 6)| 0x3; //data
+        msg.addr = 0x66;
+        msg.buf = buf;
+        msg.len = 2;
+        msg.flags = 0;
+        ret = i2c_transfer(a, &msg, 1);
+	i2c_put_adapter(a);
+        if (ret != 1)
+                return -ENODEV;
+	return 0;
+
+
+}
+
+static int pfe_eth_mdio_write(struct mii_bus *bus, int mii_id, int regnum, u16 value)
+{
+	struct pfe_eth_priv_s *priv = (struct pfe_eth_priv_s *)bus->priv;
+
+	/*FIXME Dirty hack to configure mux */
+	if(priv->mdio_muxval) {
+		if(mii_id == 0x1)
+			pfe_eth_mdio_mux(0x1);
+		else
+			pfe_eth_mdio_mux(0x2);
+	}
+
+	/* start a write op */
+	__raw_writel(EMAC_MII_DATA_ST | EMAC_MII_DATA_OP_WR |
+			EMAC_MII_DATA_PA(mii_id) | EMAC_MII_DATA_RA(regnum) |
+			EMAC_MII_DATA_TA | EMAC_MII_DATA(value),
+			priv->PHY_baseaddr + EMAC_MII_DATA_REG);
+
+	if (pfe_eth_gemac_phy_timeout(priv, EMAC_MDIO_TIMEOUT)){
+		netdev_err(priv->dev, "%s: phy MDIO write timeout\n", __func__);
+		return -1;
+	}
+	netif_info(priv, hw, priv->dev, "%s: phy %x reg %x val %x\n", __func__, mii_id, regnum, value);
+
+	return 0;
+
+
+}
+static int pfe_eth_mdio_read(struct mii_bus *bus, int mii_id, int regnum)
+{
+	struct pfe_eth_priv_s *priv = (struct pfe_eth_priv_s *)bus->priv;
+	u16 value = 0;
+
+	/*FIXME Dirty hack to configure mux */
+	if(priv->mdio_muxval){
+		if(mii_id == 0x1)
+			pfe_eth_mdio_mux(0x1);
+		else
+			pfe_eth_mdio_mux(0x2);
+	}
+
+	/* start a read op */
+	__raw_writel(EMAC_MII_DATA_ST | EMAC_MII_DATA_OP_RD |
+			EMAC_MII_DATA_PA(mii_id) | EMAC_MII_DATA_RA(regnum) |
+			EMAC_MII_DATA_TA, priv->PHY_baseaddr + EMAC_MII_DATA_REG);
+
+	if (pfe_eth_gemac_phy_timeout( priv, EMAC_MDIO_TIMEOUT))	{
+		netdev_err(priv->dev, "%s: phy MDIO read timeout\n", __func__);
+		return -1;
+	}
+
+	value = EMAC_MII_DATA(__raw_readl(priv->PHY_baseaddr + EMAC_MII_DATA_REG));
+	netif_info(priv, hw, priv->dev, "%s: phy %x reg %x val %x\n", __func__, mii_id, regnum, value);
+	return value;
+}
+#endif
+static int pfe_eth_mdio_init(struct pfe_eth_priv_s *priv, struct comcerto_mdio_platform_data *minfo)
+{
+	struct mii_bus *bus;
+	int rc;
+
+	netif_info(priv, drv, priv->dev, "%s\n", __func__);
+	printk( "%s\n", __func__);
+
+#if !defined(CONFIG_PLATFORM_EMULATION) 
+	bus = mdiobus_alloc();
+	if (!bus) {
+		netdev_err(priv->dev, "mdiobus_alloc() failed\n");
+		rc = -ENOMEM;
+		goto err0;
+	}
+
+	bus->name = "Comcerto MDIO Bus";
+	bus->read = &pfe_eth_mdio_read;
+	bus->write = &pfe_eth_mdio_write;
+	bus->reset = &pfe_eth_mdio_reset;
+	snprintf(bus->id, MII_BUS_ID_SIZE, "comcerto-%x", priv->id);
+	bus->priv = priv;
+
+	bus->phy_mask = minfo->phy_mask;
+	priv->mdc_div = minfo->mdc_div;
+
+	if (!priv->mdc_div)
+		priv->mdc_div = 64;
+
+	bus->irq = minfo->irq;
+
+	bus->parent = priv->pfe->dev;
+
+	netif_info(priv, drv, priv->dev, "%s: mdc_div: %d, phy_mask: %x \n", __func__, priv->mdc_div, bus->phy_mask);
+	rc = mdiobus_register(bus);
+	if (rc) {
+		netdev_err(priv->dev, "mdiobus_register(%s) failed\n", bus->name);
+		goto err1;
+	}
+
+	priv->mii_bus = bus;
+	pfe_eth_mdio_reset(bus);
+
+	return 0;
+
+err1:
+	mdiobus_free(bus);
+err0:
+	return rc;
+#else
+	return 0;
+#endif
+
+}
+
+/** pfe_eth_mdio_exit
+ */
+static void pfe_eth_mdio_exit(struct mii_bus *bus)
+{
+	if (!bus)
+		return;
+
+	netif_info((struct pfe_eth_priv_s *)bus->priv, drv, ((struct pfe_eth_priv_s *)(bus->priv))->dev, "%s\n", __func__);
+
+	mdiobus_unregister(bus);
+	mdiobus_free(bus);
+}
+
+#if defined(CONFIG_PLATFORM_C2000)
+/** pfe_get_interface
+ */
+static phy_interface_t pfe_get_interface(struct net_device *dev)
+{
+	struct pfe_eth_priv_s *priv = netdev_priv(dev);
+	u32 mii_mode = priv->einfo->mii_config;
+
+	netif_info(priv, drv, dev, "%s\n", __func__);
+
+	if (priv->einfo->gemac_mode & (GEMAC_SW_CONF)) {
+		switch (mii_mode) {
+			case CONFIG_COMCERTO_USE_GMII:
+				return PHY_INTERFACE_MODE_GMII;
+				break;
+			case CONFIG_COMCERTO_USE_RGMII:
+				return PHY_INTERFACE_MODE_RGMII;
+				break;
+			case CONFIG_COMCERTO_USE_RMII:
+				return PHY_INTERFACE_MODE_RMII;
+				break;
+			case CONFIG_COMCERTO_USE_SGMII:
+				return PHY_INTERFACE_MODE_SGMII;
+				break;
+
+			default :
+			case CONFIG_COMCERTO_USE_MII:
+				return PHY_INTERFACE_MODE_MII;
+				break;
+
+		}
+	} else {
+		// Bootstrap config read from controller
+		BUG();
+		return 0;
+	}
+}
+#endif
+
+/** pfe_get_phydev_speed
+ */
+static int pfe_get_phydev_speed(struct phy_device *phydev)
+{
+	switch (phydev->speed) {
+		case 10:
+			return SPEED_10M;
+		case 100:
+			return SPEED_100M;
+		case 1000:
+		default:
+			return SPEED_1000M;
+	}
+
+}
+
+/** pfe_set_rgmii_speed
+ */
+#define RGMIIPCR	0x434
+/* RGMIIPCR bit definitions*/
+#define SCFG_RGMIIPCR_EN_AUTO           (0x00000008)
+#define SCFG_RGMIIPCR_SETSP_1000M       (0x00000004)
+#define SCFG_RGMIIPCR_SETSP_100M        (0x00000000)
+#define SCFG_RGMIIPCR_SETSP_10M         (0x00000002)
+#define SCFG_RGMIIPCR_SETFD             (0x00000001)
+
+static void pfe_set_rgmii_speed(struct phy_device *phydev)
+{
+	u32 rgmii_pcr;
+
+	regmap_read(pfe->scfg, RGMIIPCR, &rgmii_pcr);
+	rgmii_pcr  &= ~(SCFG_RGMIIPCR_SETSP_1000M|SCFG_RGMIIPCR_SETSP_10M);
+
+	switch (phydev->speed) {
+		case 10:
+			rgmii_pcr |= SCFG_RGMIIPCR_SETSP_10M;
+			break;
+		case 1000:
+			rgmii_pcr |= SCFG_RGMIIPCR_SETSP_1000M;
+			break;
+		case 100:
+		default:
+			/* Default is 100M */
+			break;
+	}
+	regmap_write(pfe->scfg, RGMIIPCR, rgmii_pcr);
+
+
+}
+/** pfe_get_phydev_duplex
+ */
+static int pfe_get_phydev_duplex(struct phy_device *phydev)
+{
+	//return ( phydev->duplex == DUPLEX_HALF ) ? DUP_HALF:DUP_FULL ;
+	return DUPLEX_FULL;
+}
+
+/** pfe_eth_adjust_link
+ */
+static void pfe_eth_adjust_link(struct net_device *dev)
+{
+	struct pfe_eth_priv_s *priv = netdev_priv(dev);
+	unsigned long flags;
+	struct phy_device *phydev = priv->phydev;
+	int new_state = 0;
+
+	netif_info(priv, drv, dev, "%s\n", __func__);
+
+	spin_lock_irqsave(&priv->lock, flags);
+	if (phydev->link) {
+		/* Now we make sure that we can be in full duplex mode.
+		 * If not, we operate in half-duplex mode. */
+		if (phydev->duplex != priv->oldduplex) {
+			new_state = 1;
+			gemac_set_duplex(priv->EMAC_baseaddr, pfe_get_phydev_duplex(phydev));
+			priv->oldduplex = phydev->duplex;
+		}
+
+		if (phydev->speed != priv->oldspeed) {
+			new_state = 1;
+			gemac_set_speed(priv->EMAC_baseaddr, pfe_get_phydev_speed(phydev));
+			if(priv->einfo->mii_config == PHY_INTERFACE_MODE_RGMII)
+				pfe_set_rgmii_speed(phydev);
+			priv->oldspeed = phydev->speed;
+		}
+
+		if (!priv->oldlink) {
+			new_state = 1;
+			priv->oldlink = 1;
+		}
+
+	} else if (priv->oldlink) {
+		new_state = 1;
+		priv->oldlink = 0;
+		priv->oldspeed = 0;
+		priv->oldduplex = -1;
+	}
+
+	if (new_state && netif_msg_link(priv))
+		phy_print_status(phydev);
+
+	spin_unlock_irqrestore(&priv->lock, flags);
+}
+
+
+/** pfe_phy_exit
+ */
+static void pfe_phy_exit(struct net_device *dev)
+{
+	struct pfe_eth_priv_s *priv = netdev_priv(dev);
+
+	netif_info(priv, drv, dev, "%s\n", __func__);
+
+	phy_disconnect(priv->phydev);
+	priv->phydev = NULL;
+}
+
+/** pfe_eth_stop
+ */
+static void pfe_eth_stop( struct net_device *dev , int wake)
+{
+	struct pfe_eth_priv_s *priv = netdev_priv(dev);
+
+	netif_info(priv, drv, dev, "%s\n", __func__);
+
+	if (wake)
+		gemac_tx_disable(priv->EMAC_baseaddr);
+	else {
+		gemac_disable(priv->EMAC_baseaddr);
+		gpi_disable(priv->GPI_baseaddr);
+
+		if (priv->phydev)
+			phy_stop(priv->phydev);
+	}
+}
+
+/** pfe_eth_start
+ */
+static int pfe_eth_start( struct pfe_eth_priv_s *priv )
+{
+	netif_info(priv, drv, priv->dev, "%s\n", __func__);
+
+	if (priv->phydev)
+		phy_start(priv->phydev);
+
+	gpi_enable(priv->GPI_baseaddr);
+	gemac_enable(priv->EMAC_baseaddr);
+
+	return 0;
+}
+
+/*Configure on chip serdes through mdio
+ * Is there any better way to do this? */
+static void ls1012a_configure_serdes(struct net_device *dev)
+{
+	struct pfe_eth_priv_s *priv = pfe->eth.eth_priv[0];  // FIXME This will not work for EMAC2 as SGMII
+        /*int value,sgmii_2500=0; */
+	struct mii_bus *bus = priv->mii_bus;
+
+	netif_info(priv, drv, dev, "%s\n", __func__);
+        /* PCS configuration done with corresponding GEMAC */
+
+	pfe_eth_mdio_read(bus, 0, 0);
+	pfe_eth_mdio_read(bus, 0, 1);
+#if 1
+       /*These settings taken from validtion team */
+        pfe_eth_mdio_write(bus, 0, 0x0, 0x8000);
+        pfe_eth_mdio_write(bus, 0, 0x14, 0xb); 
+        pfe_eth_mdio_write(bus, 0, 0x4, 0x1a1);
+        pfe_eth_mdio_write(bus, 0, 0x12, 0x400);
+        pfe_eth_mdio_write(bus, 0, 0x13, 0x0);
+        pfe_eth_mdio_write(bus, 0, 0x0, 0x1140);
+        return;
+#else
+       /*Reset serdes */
+        pfe_eth_mdio_write(bus, 0, 0x0, 0x8000);
+
+        /* SGMII IF mode + AN enable only for 1G SGMII, not for 2.5G */
+        value = PHY_SGMII_IF_MODE_SGMII;
+        if (!sgmii_2500)
+                value |= PHY_SGMII_IF_MODE_AN;
+
+        pfe_eth_mdio_write(bus, 0, 0x14, value);
+
+        /* Dev ability according to SGMII specification */
+        value = PHY_SGMII_DEV_ABILITY_SGMII;
+        pfe_eth_mdio_write(bus, 0, 0x4, value);
+
+        //These values taken from validation team
+        pfe_eth_mdio_write(bus, 0, 0x13, 0x0);
+        pfe_eth_mdio_write(bus, 0, 0x12, 0x400);
+
+        /* Restart AN */
+        value = PHY_SGMII_CR_DEF_VAL;
+        if (!sgmii_2500)
+                value |= PHY_SGMII_CR_RESET_AN;
+        pfe_eth_mdio_write(bus, 0, 0, value);
+
+#endif
+}
+
+/** pfe_phy_init
+ *
+ */
+static int pfe_phy_init(struct net_device *dev)
+{
+	struct pfe_eth_priv_s *priv = netdev_priv(dev);
+	struct phy_device *phydev;
+	char phy_id[MII_BUS_ID_SIZE + 3];
+	char bus_id[MII_BUS_ID_SIZE];
+	phy_interface_t interface;
+
+	priv->oldlink = 0;
+	priv->oldspeed = 0;
+	priv->oldduplex = -1;
+
+	snprintf(bus_id, MII_BUS_ID_SIZE, "comcerto-%d", 0);
+	snprintf(phy_id, MII_BUS_ID_SIZE + 3, PHY_ID_FMT, bus_id, priv->einfo->phy_id);
+
+	netif_info(priv, drv, dev, "%s: %s\n", __func__, phy_id);
+#if defined(CONFIG_PLATFORM_C2000)
+	interface = pfe_get_interface(dev);
+#else
+	interface = priv->einfo->mii_config;
+	if(interface == PHY_INTERFACE_MODE_SGMII) {
+		/*Configure SGMII PCS */
+		if(pfe->scfg) {
+			/*Config MDIO from serdes */
+			regmap_write(pfe->scfg, 0x484, 0x00000000);
+		}
+		ls1012a_configure_serdes(dev);
+	}
+
+	if(pfe->scfg) {
+		/*Config MDIO from PAD */
+		regmap_write(pfe->scfg, 0x484, 0x80000000);
+	}
+#endif
+
+
+	priv->oldlink = 0;
+	priv->oldspeed = 0;
+	priv->oldduplex = -1;
+
+	printk("%s interface %x \n", __func__, interface);
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,9,0)
+	phydev = phy_connect(dev, phy_id, &pfe_eth_adjust_link, interface);
+#else
+	phydev = phy_connect(dev, phy_id, &pfe_eth_adjust_link, 0, interface);
+#endif
+
+	if (IS_ERR(phydev)) {
+		netdev_err(dev, "phy_connect() failed\n");
+		return PTR_ERR(phydev);
+	}
+
+	priv->phydev = phydev;
+	phydev->irq = PHY_POLL;
+
+#if defined(CONFIG_PLATFORM_C2000)
+	/* Pause frame support */
+	phydev->supported |= SUPPORTED_Pause | SUPPORTED_Asym_Pause;
+	if (pfe_eth_pause_rx_enabled(priv))
+		phydev->advertising |= ADVERTISED_Pause | ADVERTISED_Asym_Pause;
+	else
+		phydev->advertising &= ~(ADVERTISED_Pause | ADVERTISED_Asym_Pause);
+#else
+	/*TODO Add pause frame support for LS1012A */
+#endif
+
+	return 0;
+}
+
+/** pfe_gemac_init
+ */
+static int pfe_gemac_init(struct pfe_eth_priv_s *priv)
+{
+	GEMAC_CFG cfg;
+
+	netif_info(priv, ifup, priv->dev, "%s\n", __func__);
+
+	/* software config */
+	/* MII interface mode selection */ 
+	switch (priv->einfo->mii_config) {
+		case CONFIG_COMCERTO_USE_GMII:
+			cfg.mode = GMII;
+			break;
+
+		case CONFIG_COMCERTO_USE_MII:
+			cfg.mode = MII;
+			break;
+
+		case CONFIG_COMCERTO_USE_RGMII:
+			cfg.mode = RGMII;
+			break;
+
+		case CONFIG_COMCERTO_USE_RMII:
+			cfg.mode = RMII;
+			break;
+
+		case CONFIG_COMCERTO_USE_SGMII:
+			cfg.mode = SGMII;
+			break;
+
+		default:
+			cfg.mode = RGMII;
+	}
+
+	/* Speed selection */
+	switch (priv->einfo->gemac_mode & GEMAC_SW_SPEED_1G ) {
+		case GEMAC_SW_SPEED_1G:
+			cfg.speed = SPEED_1000M;
+			break;
+
+		case GEMAC_SW_SPEED_100M:
+			cfg.speed = SPEED_100M;
+			break;
+
+		case GEMAC_SW_SPEED_10M:
+			cfg.speed = SPEED_10M;
+			break;
+
+		default:
+			cfg.speed = SPEED_1000M;
+	}
+
+	/* Duplex selection */
+	cfg.duplex =  ( priv->einfo->gemac_mode & GEMAC_SW_FULL_DUPLEX ) ? DUPLEX_FULL : DUPLEX_HALF;
+
+	gemac_set_config( priv->EMAC_baseaddr, &cfg);
+	gemac_allow_broadcast( priv->EMAC_baseaddr );
+	gemac_disable_unicast( priv->EMAC_baseaddr );
+	gemac_disable_multicast( priv->EMAC_baseaddr );
+	gemac_disable_fcs_rx( priv->EMAC_baseaddr );
+	gemac_enable_1536_rx( priv->EMAC_baseaddr );
+	gemac_enable_rx_jmb( priv->EMAC_baseaddr );
+	gemac_enable_stacked_vlan( priv->EMAC_baseaddr );
+	gemac_enable_pause_rx( priv->EMAC_baseaddr );
+	gemac_set_bus_width(priv->EMAC_baseaddr, 64);
+	/*TODO just for testing remove it later */
+	gemac_enable_copy_all(priv->EMAC_baseaddr);
+
+	/*GEM will perform checksum verifications*/
+	if (priv->dev->features & NETIF_F_RXCSUM)
+		gemac_enable_rx_checksum_offload(priv->EMAC_baseaddr);
+	else
+		gemac_disable_rx_checksum_offload(priv->EMAC_baseaddr);	
+
+	return 0;
+}
+
+/** pfe_eth_event_handler
+ */
+static int pfe_eth_event_handler(void *data, int event, int qno)
+{
+	struct pfe_eth_priv_s *priv = data;
+
+	switch (event) {
+	case EVENT_RX_PKT_IND:
+
+		if (qno == 0) {
+			if (napi_schedule_prep(&priv->high_napi)) {
+				netif_info(priv, intr, priv->dev, "%s: schedule high prio poll\n", __func__);
+
+#ifdef PFE_ETH_NAPI_STATS
+				priv->napi_counters[NAPI_SCHED_COUNT]++;
+#endif
+
+				__napi_schedule(&priv->high_napi);
+			}
+		}
+		else if (qno == 1) {
+			if (napi_schedule_prep(&priv->low_napi)) {
+				netif_info(priv, intr, priv->dev, "%s: schedule low prio poll\n", __func__);
+
+#ifdef PFE_ETH_NAPI_STATS
+				priv->napi_counters[NAPI_SCHED_COUNT]++;
+#endif
+				__napi_schedule(&priv->low_napi);
+			}
+		}
+		else if (qno == 2) {
+			if (napi_schedule_prep(&priv->lro_napi)) {
+				netif_info(priv, intr, priv->dev, "%s: schedule lro prio poll\n", __func__);
+
+#ifdef PFE_ETH_NAPI_STATS
+				priv->napi_counters[NAPI_SCHED_COUNT]++;
+#endif
+				__napi_schedule(&priv->lro_napi);
+			}
+		}
+
+		break;
+
+	case EVENT_TXDONE_IND:
+	case EVENT_HIGH_RX_WM:
+	default:
+		break;
+	}
+
+	return 0;
+}
+
+/** pfe_eth_open
+ */
+static int pfe_eth_open(struct net_device *dev)
+{
+	struct pfe_eth_priv_s *priv = netdev_priv(dev);
+	struct hif_client_s *client;
+	int rc;
+
+	netif_info(priv, ifup, dev, "%s\n", __func__);
+
+	/* Register client driver with HIF */
+	client = &priv->client;
+	memset(client, 0, sizeof(*client));
+	client->id = PFE_CL_GEM0 + priv->id;
+	client->tx_qn = emac_txq_cnt;
+	client->rx_qn = EMAC_RXQ_CNT;
+	client->priv    = priv;
+	client->pfe     = priv->pfe;
+	client->event_handler   = pfe_eth_event_handler;
+
+	/* FIXME : For now hif lib sets all tx and rx queues to same size */
+	client->tx_qsize = EMAC_TXQ_DEPTH;
+	client->rx_qsize = EMAC_RXQ_DEPTH;
+
+	if ((rc = hif_lib_client_register(client))) {
+		netdev_err(dev, "%s: hif_lib_client_register(%d) failed\n", __func__, client->id);
+		goto err0;
+	}
+
+	netif_info(priv, drv, dev, "%s: registered client: %p\n", __func__,  client);
+
+#if defined(CONFIG_PLATFORM_C2000)
+	/* Enable gemac tx clock */
+	clk_enable(priv->gemtx_clk);
+#endif
+
+	pfe_gemac_init(priv);
+
+	if (!is_valid_ether_addr(dev->dev_addr)) {
+		netdev_err(dev, "%s: invalid MAC address\n", __func__);
+		rc = -EADDRNOTAVAIL;
+		goto err1;
+	}
+
+	gemac_set_laddrN( priv->EMAC_baseaddr, ( MAC_ADDR *)dev->dev_addr, 1 );
+
+	napi_enable(&priv->high_napi);
+	napi_enable(&priv->low_napi);
+	napi_enable(&priv->lro_napi);
+
+	rc = pfe_eth_start(priv);
+
+	netif_tx_wake_all_queues(dev);
+
+	//pfe_ctrl_set_eth_state(priv->id, 1, dev->dev_addr);
+
+	priv->tx_timer.expires = jiffies + ( COMCERTO_TX_RECOVERY_TIMEOUT_MS * HZ )/1000;
+	add_timer(&priv->tx_timer);
+
+	return rc;
+
+err1:
+	hif_lib_client_unregister(&priv->client);
+#if defined(CONFIG_PLATFORM_C2000)
+	clk_disable(priv->gemtx_clk);
+#endif
+
+err0:
+	return rc;
+}
+/*
+ *  pfe_eth_shutdown
+ */
+int pfe_eth_shutdown( struct net_device *dev, int wake)
+{
+	struct pfe_eth_priv_s *priv = netdev_priv(dev);
+	int i, qstatus;
+	unsigned long next_poll = jiffies + 1, end = jiffies + (TX_POLL_TIMEOUT_MS * HZ) / 1000;
+	int tx_pkts, prv_tx_pkts;
+
+	netif_info(priv, ifdown, dev, "%s\n", __func__);
+
+	del_timer_sync(&priv->tx_timer);
+
+	for(i = 0; i < emac_txq_cnt; i++)
+		hrtimer_cancel(&priv->fast_tx_timeout[i].timer);
+
+	netif_tx_stop_all_queues(dev);
+
+	do {
+		tx_pkts = 0;
+		pfe_eth_flush_tx(priv, 1);
+
+		for (i = 0; i < emac_txq_cnt; i++) 
+			tx_pkts += hif_lib_tx_pending(&priv->client, i);
+
+		if (tx_pkts) {
+			/*Don't wait forever, break if we cross max timeout */
+			if (time_after(jiffies, end)) {
+				printk(KERN_ERR "(%s)Tx is not complete after %dmsec\n", dev->name, TX_POLL_TIMEOUT_MS);
+				break;
+			}
+
+			printk("%s : (%s) Waiting for tx packets to free. Pending tx pkts = %d.\n", __func__, dev->name, tx_pkts);
+			if (need_resched())
+				schedule();
+		}
+
+	} while(tx_pkts);
+
+	end = jiffies + (TX_POLL_TIMEOUT_MS * HZ) / 1000;
+	/*Disable transmit in PFE before disabling GEMAC */
+	//pfe_ctrl_set_eth_state(priv->id, 0, NULL);
+
+	prv_tx_pkts = tmu_pkts_processed(priv->id);
+	/*Wait till TMU transmits all pending packets
+	* poll tmu_qstatus and pkts processed by TMU for every 10ms
+	* Consider TMU is busy, If we see TMU qeueu pending or any packets processed by TMU
+	*/
+	while(1) {
+
+		if (time_after(jiffies, next_poll)) {
+
+			tx_pkts = tmu_pkts_processed(priv->id);
+			qstatus = tmu_qstatus(priv->id) & 0x7ffff;
+
+			if(!qstatus && (tx_pkts == prv_tx_pkts)) {
+				break;
+			}
+			/*Don't wait forever, break if we cross max timeout(TX_POLL_TIMEOUT_MS) */
+			if (time_after(jiffies, end)) {
+				printk(KERN_ERR "TMU%d is busy after %dmsec\n", priv->id, TX_POLL_TIMEOUT_MS);
+				break;
+			}
+			prv_tx_pkts = tx_pkts;
+			next_poll++;
+		}
+		if (need_resched())
+			schedule();
+
+
+	}
+	/* Wait for some more time to complete transmitting packet if any */
+	next_poll = jiffies + 1;
+	while(1) {
+		if (time_after(jiffies, next_poll))
+			break;
+		if (need_resched())
+			schedule();
+	}
+
+	pfe_eth_stop(dev, wake);
+
+	napi_disable(&priv->lro_napi);
+	napi_disable(&priv->low_napi);
+	napi_disable(&priv->high_napi);
+
+#if defined(CONFIG_PLATFORM_C2000)
+	/* Disable gemac tx clock */
+	clk_disable(priv->gemtx_clk);
+#endif
+
+	hif_lib_client_unregister(&priv->client);
+
+	return 0;
+}
+
+/* pfe_eth_close
+ *
+ */
+static int pfe_eth_close( struct net_device *dev )
+{
+	pfe_eth_shutdown(dev, 0);
+
+	return 0;
+}
+
+/* pfe_eth_suspend
+ *
+ * return value : 1 if netdevice is configured to wakeup system
+ *                0 otherwise
+ */
+int pfe_eth_suspend(struct net_device *dev)
+{
+	struct pfe_eth_priv_s *priv = netdev_priv(dev);
+	int retval = 0;
+
+	if (priv->wol) {
+		gemac_set_wol(priv->EMAC_baseaddr, priv->wol);
+		retval = 1;
+	}
+	pfe_eth_shutdown(dev, priv->wol);
+
+	return retval;
+}
+
+/** pfe_eth_resume
+ *
+ */
+int pfe_eth_resume(struct net_device *dev)
+{
+	struct pfe_eth_priv_s *priv = netdev_priv(dev);
+
+	if (priv->wol)
+		gemac_set_wol(priv->EMAC_baseaddr, 0);
+
+	return pfe_eth_open(dev);
+}
+
+#if defined(CONFIG_PLATFORM_C2000)
+/** pfe_eth_set_device_wakeup
+ *
+ *  Called when a netdevice changes its wol status.
+ *  Scans state of all interfaces and updae PFE device
+ *  wakeable state
+ */
+static void pfe_eth_set_device_wakeup(struct pfe *pfe)
+{
+	int i;
+	int wake = 0;
+
+	for(i = 0; i < NUM_GEMAC_SUPPORT; i++)
+			wake |= pfe->eth.eth_priv[i]->wol;
+
+	device_set_wakeup_enable(pfe->dev, wake);
+	//TODO Find correct IRQ mapping.
+	//TODO interface with PMU
+	//int irq_set_irq_wake(unsigned int irq, unsigned int on)
+}
+#endif
+/** pfe_eth_get_queuenum
+ *
+ */
+static int pfe_eth_get_queuenum( struct pfe_eth_priv_s *priv, struct sk_buff *skb )
+{
+	int queuenum = 0;
+	unsigned long flags;
+
+	/* Get the Fast Path queue number */
+	/* Use conntrack mark (if conntrack exists), then packet mark (if any), then fallback to default */
+#if defined(CONFIG_IP_NF_CONNTRACK_MARK) || defined(CONFIG_NF_CONNTRACK_MARK)
+	if (skb->nfct) {
+		enum ip_conntrack_info cinfo;
+		struct nf_conn *ct;
+		ct = nf_ct_get(skb, &cinfo);
+
+		if (ct) {
+			u_int32_t connmark;
+			connmark = ct->mark;
+
+			if ((connmark & 0x80000000) && priv->id != 0)
+				connmark >>= 16;
+
+			queuenum = connmark & EMAC_QUEUENUM_MASK;
+		}
+	}
+	else  /* continued after #endif ... */
+#endif
+		if (skb->mark)
+			queuenum = skb->mark & EMAC_QUEUENUM_MASK;
+		else {
+			spin_lock_irqsave(&priv->lock, flags);	
+			queuenum = priv->default_priority & EMAC_QUEUENUM_MASK;
+			spin_unlock_irqrestore(&priv->lock, flags);	
+		}
+
+	return queuenum;
+}
+
+
+
+/** pfe_eth_might_stop_tx
+ *
+ */
+static int pfe_eth_might_stop_tx(struct pfe_eth_priv_s *priv, int queuenum, struct netdev_queue *tx_queue, unsigned int n_desc, unsigned int n_segs)
+{
+	int tried = 0;
+	ktime_t kt;
+
+try_again:
+	if (unlikely((__hif_tx_avail(&pfe->hif) < n_desc)
+	|| (hif_lib_tx_avail(&priv->client, queuenum) < n_desc)
+	|| (hif_lib_tx_credit_avail(pfe, priv->id, queuenum) < n_segs))) {
+
+		if (!tried) {
+			hif_tx_unlock(&pfe->hif);
+			pfe_eth_flush_txQ(priv, queuenum, 1, n_desc);
+			hif_lib_update_credit(&priv->client, queuenum);
+			tried = 1;
+			hif_tx_lock(&pfe->hif);
+			goto try_again;
+		}
+#ifdef PFE_ETH_TX_STATS
+		if (__hif_tx_avail(&pfe->hif) < n_desc)
+			priv->stop_queue_hif[queuenum]++;
+		else if (hif_lib_tx_avail(&priv->client, queuenum) < n_desc) {
+			priv->stop_queue_hif_client[queuenum]++;
+		}
+		else if (hif_lib_tx_credit_avail(pfe, priv->id, queuenum) < n_segs) {
+			priv->stop_queue_credit[queuenum]++;
+		}
+		priv->stop_queue_total[queuenum]++;
+#endif
+		netif_tx_stop_queue(tx_queue);
+
+		kt = ktime_set(0, COMCERTO_TX_FAST_RECOVERY_TIMEOUT_MS * NSEC_PER_MSEC);
+		hrtimer_start(&priv->fast_tx_timeout[queuenum].timer, kt, HRTIMER_MODE_REL);
+		return -1;
+	}
+	else {
+		return 0;
+	}
+}
+
+#define SA_MAX_OP 2
+/** pfe_hif_send_packet
+ *
+ * At this level if TX fails we drop the packet
+ */
+static void pfe_hif_send_packet( struct sk_buff *skb, struct  pfe_eth_priv_s *priv, int queuenum)
+{
+	struct skb_shared_info *sh = skb_shinfo(skb);
+	unsigned int nr_frags;
+	u32 ctrl = 0;
+
+	netif_info(priv, tx_queued, priv->dev, "%s\n", __func__);
+
+	if (skb_is_gso(skb)) {
+		priv->stats.tx_dropped++;
+		return;
+	}
+
+	if (skb->ip_summed == CHECKSUM_PARTIAL) {
+		if (skb->len > 1522) {
+			skb->ip_summed = 0;
+			ctrl = 0;
+
+			if (pfe_compute_csum(skb)){
+				kfree_skb(skb);
+				return;
+			}
+		}
+		else
+			ctrl = HIF_CTRL_TX_CHECKSUM;
+	}
+
+	nr_frags = sh->nr_frags;
+
+	if (nr_frags) {
+		skb_frag_t *f;
+		int i;
+
+		__hif_lib_xmit_pkt(&priv->client, queuenum, skb->data, skb_headlen(skb), ctrl, HIF_FIRST_BUFFER, skb);
+
+		for (i = 0; i < nr_frags - 1; i++) {
+			f = &sh->frags[i];
+			__hif_lib_xmit_pkt(&priv->client, queuenum, skb_frag_address(f), skb_frag_size(f), 0x0, 0x0, skb);
+		}
+
+		f = &sh->frags[i];
+
+		__hif_lib_xmit_pkt(&priv->client, queuenum, skb_frag_address(f), skb_frag_size(f), 0x0, HIF_LAST_BUFFER|HIF_DATA_VALID, skb);
+
+		netif_info(priv, tx_queued, priv->dev, "%s: pkt sent successfully skb:%p nr_frags:%d len:%d\n", __func__, skb, nr_frags, skb->len);
+	}
+	else {
+		__hif_lib_xmit_pkt(&priv->client, queuenum, skb->data, skb->len, ctrl, HIF_FIRST_BUFFER | HIF_LAST_BUFFER | HIF_DATA_VALID, skb);
+		netif_info(priv, tx_queued, priv->dev, "%s: pkt sent successfully skb:%p len:%d\n", __func__, skb, skb->len);
+	}
+	hif_tx_dma_start();
+	priv->stats.tx_packets++;
+	priv->stats.tx_bytes += skb->len;
+	hif_lib_tx_credit_use(pfe, priv->id, queuenum, 1);
+}
+
+/** pfe_eth_flush_txQ
+ */
+static void pfe_eth_flush_txQ(struct pfe_eth_priv_s *priv, int txQ_num, int from_tx, int n_desc)
+{
+	struct sk_buff *skb;
+	struct netdev_queue *tx_queue = netdev_get_tx_queue(priv->dev, txQ_num);
+	int count = max(TX_FREE_MAX_COUNT, n_desc);
+	unsigned int flags;
+
+	netif_info(priv, tx_done, priv->dev, "%s\n", __func__);
+
+	if (!from_tx)
+		__netif_tx_lock_bh(tx_queue);
+
+	/* Clean HIF and client queue */
+	while (count && (skb = hif_lib_tx_get_next_complete(&priv->client, txQ_num, &flags, count))) {
+
+		/* FIXME : Invalid data can be skipped in hif_lib itself */
+		if (flags & HIF_DATA_VALID) {
+			dev_kfree_skb_any(skb);
+
+		}
+		// When called from the timer, flush all descriptors
+		if (from_tx)
+			count--;
+	}
+
+	if (!from_tx)
+		__netif_tx_unlock_bh(tx_queue);
+}
+
+/** pfe_eth_flush_tx
+ */
+static void pfe_eth_flush_tx(struct pfe_eth_priv_s *priv, int force)
+{
+	int ii;
+
+	netif_info(priv, tx_done, priv->dev, "%s\n", __func__);
+
+	for (ii = 0; ii < emac_txq_cnt; ii++) {
+		if (force || (time_after(jiffies, priv->client.tx_q[ii].jiffies_last_packet + (COMCERTO_TX_RECOVERY_TIMEOUT_MS * HZ)/1000))) {
+			pfe_eth_flush_txQ(priv, ii, 0, 0); //We will release everything we can based on from_tx param, so the count param can be set to any value
+			hif_lib_update_credit(&priv->client, ii);
+		}
+	}
+}
+
+void pfe_tx_get_req_desc(struct sk_buff *skb, unsigned int *n_desc, unsigned int *n_segs)
+{
+	struct skb_shared_info *sh = skb_shinfo(skb);
+
+	// Scattered data
+	if (sh->nr_frags) {
+		*n_desc = sh->nr_frags + 1;
+		*n_segs = 1;
+	}
+	// Regular case
+	else {
+		*n_desc = 1;
+		*n_segs = 1;
+	}
+	return;
+}
+
+/** pfe_eth_send_packet
+ */
+static int pfe_eth_send_packet(struct sk_buff *skb, struct net_device *dev)
+{
+	struct pfe_eth_priv_s *priv = netdev_priv(dev);
+	int txQ_num = skb_get_queue_mapping(skb);
+	int n_desc, n_segs, count;
+	struct netdev_queue *tx_queue = netdev_get_tx_queue(priv->dev, txQ_num);
+
+	netif_info(priv, tx_queued, dev, "%s\n", __func__);
+
+	if ((!skb_is_gso(skb)) && (skb_headroom(skb) < (PFE_PKT_HEADER_SZ + sizeof(unsigned long)))) {
+
+		netif_warn(priv, tx_err, priv->dev, "%s: copying skb\n", __func__);
+
+		if (pskb_expand_head(skb, (PFE_PKT_HEADER_SZ + sizeof(unsigned long)), 0, GFP_ATOMIC)) {
+			/* No need to re-transmit, no way to recover*/
+			kfree_skb(skb);
+			priv->stats.tx_dropped++;
+			return NETDEV_TX_OK;
+		}
+	}
+
+	pfe_tx_get_req_desc(skb, &n_desc, &n_segs);
+
+	hif_tx_lock(&pfe->hif);
+	if(unlikely(pfe_eth_might_stop_tx(priv, txQ_num, tx_queue, n_desc, n_segs))) {
+#ifdef PFE_ETH_TX_STATS
+		if(priv->was_stopped[txQ_num]) {
+			priv->clean_fail[txQ_num]++;
+			priv->was_stopped[txQ_num] = 0;
+		}
+#endif
+		hif_tx_unlock(&pfe->hif);
+		return NETDEV_TX_BUSY;
+	}
+
+	pfe_hif_send_packet(skb, priv, txQ_num);
+
+	hif_tx_unlock(&pfe->hif);
+
+	dev->trans_start = jiffies;
+
+	// Recycle buffers if a socket's send buffer becomes half full or if the HIF client queue starts filling up
+	if (((count = (hif_lib_tx_pending(&priv->client, txQ_num) - HIF_CL_TX_FLUSH_MARK)) > 0)
+		|| (skb->sk && ((sk_wmem_alloc_get(skb->sk) << 1) > skb->sk->sk_sndbuf)))
+		pfe_eth_flush_txQ(priv, txQ_num, 1, count);
+
+#ifdef PFE_ETH_TX_STATS
+	priv->was_stopped[txQ_num] = 0;
+#endif
+
+	return NETDEV_TX_OK;
+}
+
+/** pfe_eth_select_queue
+ *
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,14,0)
+static u16 pfe_eth_select_queue( struct net_device *dev, struct sk_buff *skb,
+		void *accel_priv, select_queue_fallback_t fallback)
+#else
+static u16 pfe_eth_select_queue( struct net_device *dev, struct sk_buff *skb )
+#endif
+{
+	struct pfe_eth_priv_s *priv = netdev_priv(dev);
+
+	return pfe_eth_get_queuenum(priv, skb);
+}
+
+
+/** pfe_eth_get_stats
+ */
+static struct net_device_stats *pfe_eth_get_stats(struct net_device *dev)
+{
+	struct pfe_eth_priv_s *priv = netdev_priv(dev);
+
+	netif_info(priv, drv, dev, "%s\n", __func__);
+
+	return &priv->stats;
+}
+
+
+/** pfe_eth_change_mtu
+ */
+static int pfe_eth_change_mtu(struct net_device *dev, int new_mtu)
+{
+	struct pfe_eth_priv_s *priv = netdev_priv(dev);
+	int oldsize = dev->mtu ;
+	int frame_size = new_mtu + ETH_HLEN +4;
+
+	netif_info(priv, drv, dev, "%s\n", __func__);
+
+	if ((frame_size < 64) || (frame_size > JUMBO_FRAME_SIZE)) {
+		netif_err(priv, drv, dev, "Invalid MTU setting\n");
+		return -EINVAL;
+	}
+
+	if ((new_mtu > 1500) && (dev->features & NETIF_F_TSO))
+	{
+		priv->usr_features = dev->features;
+		if (dev->features & NETIF_F_TSO)
+		{
+			netdev_err(dev, "MTU cannot be set to more than 1500 while TSO is enabled. disabling TSO.\n");
+			dev->features &= ~(NETIF_F_TSO);
+		}
+	}
+	else if ((dev->mtu > 1500) && (new_mtu <= 1500))
+	{
+		if (priv->usr_features & NETIF_F_TSO)
+		{
+			priv->usr_features &= ~(NETIF_F_TSO);
+			dev->features |= NETIF_F_TSO;
+			netdev_err(dev, "MTU is <= 1500, Enabling TSO feature.\n");
+		}
+	}
+
+	/* Only stop and start the controller if it isn't already
+	 * stopped, and we changed something */
+	if ((oldsize != new_mtu) && (dev->flags & IFF_UP)){
+		netdev_err(dev, "Can not change MTU - fast_path must be disabled and ifconfig down must be issued first\n");
+
+		return -EINVAL;
+	}
+
+	dev->mtu = new_mtu;
+
+	return 0;
+}
+
+/** pfe_eth_set_mac_address
+ */
+static int pfe_eth_set_mac_address(struct net_device *dev, void *addr)
+{
+	struct pfe_eth_priv_s *priv = netdev_priv(dev);
+	struct sockaddr *sa = addr;
+
+	netif_info(priv, drv, dev, "%s\n", __func__);
+
+	if (!is_valid_ether_addr(sa->sa_data))
+		return -EADDRNOTAVAIL;
+
+	memcpy(dev->dev_addr, sa->sa_data, ETH_ALEN);
+
+	gemac_set_laddrN(priv->EMAC_baseaddr, (MAC_ADDR *)dev->dev_addr, 1);
+
+	return 0;
+
+}
+
+/** pfe_eth_enet_addr_byte_mac
+ */
+int pfe_eth_enet_addr_byte_mac(u8 * enet_byte_addr, MAC_ADDR *enet_addr)
+{
+	if ((enet_byte_addr == NULL) || (enet_addr == NULL))
+	{
+		return -1;
+	}
+	else
+	{
+		enet_addr->bottom = enet_byte_addr[0] |
+			(enet_byte_addr[1] << 8) |
+			(enet_byte_addr[2] << 16) |
+			(enet_byte_addr[3] << 24);
+		enet_addr->top = enet_byte_addr[4] |
+			(enet_byte_addr[5] << 8);
+		return 0;
+	}
+}
+
+
+
+/** pfe_eth_set_multi
+ */
+static void pfe_eth_set_multi(struct net_device *dev)
+{
+	struct pfe_eth_priv_s *priv = netdev_priv(dev);
+	MAC_ADDR    hash_addr;          /* hash register structure */
+	MAC_ADDR    spec_addr;		/* specific mac address register structure */
+	int         result;          /* index into hash register to set.. */
+	int 	    uc_count = 0;
+	struct netdev_hw_addr *ha;
+
+	if (dev->flags & IFF_PROMISC) {
+		netif_info(priv, drv, dev, "entering promiscuous mode\n");
+
+		priv->promisc = 1;
+		gemac_enable_copy_all(priv->EMAC_baseaddr);
+	} else {
+		priv->promisc = 0;
+		gemac_disable_copy_all(priv->EMAC_baseaddr);
+	}
+
+	/* Enable broadcast frame reception if required. */
+	if (dev->flags & IFF_BROADCAST) {
+		gemac_allow_broadcast(priv->EMAC_baseaddr);
+	} else {
+		netif_info(priv, drv, dev, "disabling broadcast frame reception\n");
+
+		gemac_no_broadcast(priv->EMAC_baseaddr);
+	}
+
+	if (dev->flags & IFF_ALLMULTI) {
+		/* Set the hash to rx all multicast frames */
+		hash_addr.bottom = 0xFFFFFFFF;
+		hash_addr.top = 0xFFFFFFFF;
+		gemac_set_hash(priv->EMAC_baseaddr, &hash_addr);
+		gemac_enable_multicast(priv->EMAC_baseaddr);
+		netdev_for_each_uc_addr(ha, dev) {
+			if(uc_count >= MAX_UC_SPEC_ADDR_REG) break;
+			pfe_eth_enet_addr_byte_mac(ha->addr, &spec_addr);
+			gemac_set_laddrN(priv->EMAC_baseaddr, &spec_addr, uc_count + 2);
+			uc_count++;
+		}
+	} else if ((netdev_mc_count(dev) > 0)  || (netdev_uc_count(dev))) {
+		u8 *addr;
+
+		hash_addr.bottom = 0;
+		hash_addr.top = 0;
+
+		netdev_for_each_mc_addr(ha, dev) {
+			addr = ha->addr;
+
+			netif_info(priv, drv, dev, "adding multicast address %X:%X:%X:%X:%X:%X to gem filter\n",
+						addr[0], addr[1], addr[2], addr[3], addr[4], addr[5]);
+
+			result = pfe_eth_get_hash(addr);
+
+			if (result >= EMAC_HASH_REG_BITS) {
+				break;
+			} else {
+				if (result < 32) {
+					hash_addr.bottom |= (1 << result);
+				} else {
+					hash_addr.top |= (1 << (result - 32));
+				}
+			}
+
+		}
+
+		uc_count = -1;
+		netdev_for_each_uc_addr(ha, dev) {
+			addr = ha->addr;
+
+			if(++uc_count < MAX_UC_SPEC_ADDR_REG)  
+			{
+				netdev_info(dev, "adding unicast address %02x:%02x:%02x:%02x:%02x:%02x to gem filter\n",
+						addr[0], addr[1], addr[2],
+						addr[3], addr[4], addr[5]);
+
+				pfe_eth_enet_addr_byte_mac(addr, &spec_addr);
+				gemac_set_laddrN(priv->EMAC_baseaddr, &spec_addr, uc_count + 2);
+			}
+			else
+			{
+				netif_info(priv, drv, dev, "adding unicast address %02x:%02x:%02x:%02x:%02x:%02x to gem hash\n",
+							addr[0], addr[1], addr[2],
+							addr[3], addr[4], addr[5]);
+
+				result = pfe_eth_get_hash(addr);
+				if (result >= EMAC_HASH_REG_BITS) {
+					break;
+				} else {
+					if (result < 32)
+						hash_addr.bottom |= (1 << result);
+					else
+						hash_addr.top |= (1 << (result - 32));
+				}
+
+
+			}
+		}
+
+		gemac_set_hash(priv->EMAC_baseaddr, &hash_addr);
+		if(netdev_mc_count(dev))
+			gemac_enable_multicast(priv->EMAC_baseaddr);
+		else
+			gemac_disable_multicast(priv->EMAC_baseaddr);		
+	}
+
+	if(netdev_uc_count(dev) >= MAX_UC_SPEC_ADDR_REG)
+		gemac_enable_unicast(priv->EMAC_baseaddr);
+	else
+	{
+		/* Check if there are any specific address HW registers that need 
+		 *  to be flushed 
+		 *  */
+		for(uc_count = netdev_uc_count(dev); uc_count < MAX_UC_SPEC_ADDR_REG; uc_count++) 
+			gemac_clear_laddrN(priv->EMAC_baseaddr, uc_count + 2);
+
+		gemac_disable_unicast(priv->EMAC_baseaddr);
+	}
+
+	if (dev->flags & IFF_LOOPBACK) {
+		gemac_set_loop(priv->EMAC_baseaddr, LB_LOCAL);
+	}
+
+	return;
+}
+
+/** pfe_eth_set_features
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,6,0)
+static int pfe_eth_set_features(struct net_device *dev, netdev_features_t features)
+#else
+static int pfe_eth_set_features(struct net_device *dev, u32 features)
+#endif
+{
+	struct pfe_eth_priv_s *priv = netdev_priv(dev);
+	int rc = 0;
+
+	if (features & NETIF_F_RXCSUM)
+		gemac_enable_rx_checksum_offload(priv->EMAC_baseaddr);
+	else
+		gemac_disable_rx_checksum_offload(priv->EMAC_baseaddr);
+	return rc;
+}
+
+/** pfe_eth_fix_features
+ */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,6,0)
+static netdev_features_t pfe_eth_fix_features(struct net_device *dev, netdev_features_t features)
+#else
+static unsigned int pfe_eth_fix_features(struct net_device *dev,u32 features)
+#endif
+{
+	struct pfe_eth_priv_s *priv = netdev_priv(dev);
+
+	if (dev->mtu > 1500)
+	{
+		if (features & (NETIF_F_TSO))
+		{
+			priv->usr_features |= NETIF_F_TSO;
+			features &= ~(NETIF_F_TSO);
+			netdev_err(dev, "TSO cannot be enabled when the MTU is larger than 1500. Please set the MTU to 1500 or lower first.\n");
+		}
+	}
+
+	return features;
+}
+
+/** pfe_eth_tx_timeout
+ */
+void pfe_eth_tx_timeout(unsigned long data )
+{
+	struct pfe_eth_priv_s *priv = (struct pfe_eth_priv_s *)data;
+
+	netif_info(priv, timer, priv->dev, "%s\n", __func__);
+
+	pfe_eth_flush_tx(priv, 0);
+
+	priv->tx_timer.expires = jiffies + ( COMCERTO_TX_RECOVERY_TIMEOUT_MS * HZ )/1000;
+	add_timer(&priv->tx_timer);
+}
+
+/** pfe_eth_fast_tx_timeout
+ */
+static enum hrtimer_restart pfe_eth_fast_tx_timeout(struct hrtimer *timer)
+{
+	struct pfe_eth_fast_timer *fast_tx_timeout = container_of(timer, struct pfe_eth_fast_timer, timer);
+	struct pfe_eth_priv_s *priv =  container_of(fast_tx_timeout->base, struct pfe_eth_priv_s, fast_tx_timeout);
+	struct netdev_queue *tx_queue = netdev_get_tx_queue(priv->dev, fast_tx_timeout->queuenum);
+
+	if(netif_tx_queue_stopped(tx_queue)) {
+#ifdef PFE_ETH_TX_STATS
+		priv->was_stopped[fast_tx_timeout->queuenum] = 1;
+#endif
+		netif_tx_wake_queue(tx_queue);
+	}
+
+	return HRTIMER_NORESTART;
+}
+
+/** pfe_eth_fast_tx_timeout_init
+ */
+static void pfe_eth_fast_tx_timeout_init(struct pfe_eth_priv_s *priv)
+{
+	int i;
+	for (i = 0; i < emac_txq_cnt; i++) {
+		priv->fast_tx_timeout[i].queuenum = i;
+		hrtimer_init(&priv->fast_tx_timeout[i].timer, CLOCK_MONOTONIC, HRTIMER_MODE_REL);
+		priv->fast_tx_timeout[i].timer.function = pfe_eth_fast_tx_timeout;
+		priv->fast_tx_timeout[i].base = priv->fast_tx_timeout;
+	}
+}
+
+static struct sk_buff *pfe_eth_rx_skb(struct net_device *dev, struct pfe_eth_priv_s *priv, unsigned int qno)
+{
+	void *buf_addr;
+	unsigned int rx_ctrl;
+	unsigned int desc_ctrl = 0;
+	struct hif_ipsec_hdr *ipsec_hdr = NULL;
+	struct sk_buff *skb;
+	struct sk_buff *skb_frag, *skb_frag_last = NULL;
+	int length = 0, offset;
+
+	skb = priv->skb_inflight[qno];
+
+	if (skb && (skb_frag_last = skb_shinfo(skb)->frag_list)) {
+		while (skb_frag_last->next)
+			skb_frag_last = skb_frag_last->next;
+	}
+
+	while (!(desc_ctrl & CL_DESC_LAST)) {
+
+		buf_addr = hif_lib_receive_pkt(&priv->client, qno, &length, &offset, &rx_ctrl, &desc_ctrl, (void **)&ipsec_hdr);
+		if (!buf_addr)
+			goto incomplete;
+
+#ifdef PFE_ETH_NAPI_STATS
+		priv->napi_counters[NAPI_DESC_COUNT]++;
+#endif
+
+		/* First frag */
+		if (desc_ctrl & CL_DESC_FIRST) {
+#if defined(CONFIG_PLATFORM_EMULATION) || defined(CONFIG_PLATFORM_PCI)
+			skb = dev_alloc_skb(PFE_BUF_SIZE);
+			if (unlikely(!skb)) {
+				goto pkt_drop;
+			}
+
+			skb_copy_to_linear_data(skb, buf_addr, length + offset);
+			kfree(buf_addr);
+#else
+#if defined(CONFIG_COMCERTO_ZONE_DMA_NCNB)
+			skb = alloc_skb(length + offset + 32, GFP_ATOMIC);
+#else
+			skb = alloc_skb_header(PFE_BUF_SIZE, buf_addr, GFP_ATOMIC);
+#endif
+			if (unlikely(!skb)) {
+				goto pkt_drop;
+			}
+#endif
+			skb_reserve(skb, offset);
+#if defined(CONFIG_COMCERTO_ZONE_DMA_NCNB)
+			__memcpy(skb->data, buf_addr + offset, length);
+			if (ipsec_hdr) {
+				sah_local = *(unsigned int *)&ipsec_hdr->sa_handle[0];
+			}
+			kfree(buf_addr);
+#endif
+			skb_put(skb, length);
+			skb->dev = dev;
+
+			if ((dev->features & NETIF_F_RXCSUM) && (rx_ctrl & HIF_CTRL_RX_CHECKSUMMED))
+				skb->ip_summed = CHECKSUM_UNNECESSARY;
+			else
+				skb_checksum_none_assert(skb);
+
+		} else {
+
+			/* Next frags */
+			if (unlikely(!skb)) {
+				printk(KERN_ERR "%s: NULL skb_inflight\n", __func__);
+				goto pkt_drop;
+			}
+
+#if defined(CONFIG_COMCERTO_ZONE_DMA_NCNB)
+			skb_frag = alloc_skb(length + offset + 32, GFP_ATOMIC);
+#else
+			skb_frag = alloc_skb_header(PFE_BUF_SIZE, buf_addr, GFP_ATOMIC);
+#endif
+			if (unlikely(!skb_frag)) {
+				kfree(buf_addr);
+				goto pkt_drop;
+			}
+
+			skb_reserve(skb_frag, offset);
+#if defined(CONFIG_COMCERTO_ZONE_DMA_NCNB)
+			__memcpy(skb_frag->data, buf_addr + offset, length);
+			kfree(buf_addr);
+#endif
+			skb_put(skb_frag, length);
+
+			skb_frag->dev = dev;
+
+			if (skb_shinfo(skb)->frag_list)
+				skb_frag_last->next = skb_frag;
+			else
+				skb_shinfo(skb)->frag_list = skb_frag;
+
+			skb->truesize += skb_frag->truesize;
+			skb->data_len += length;
+			skb->len += length;
+			skb_frag_last = skb_frag;
+		}
+	}
+
+	priv->skb_inflight[qno] = NULL;
+	return skb;
+
+incomplete:
+	priv->skb_inflight[qno] = skb;
+	return NULL;
+
+pkt_drop:
+	priv->skb_inflight[qno] = NULL;
+
+	if (skb) {
+		kfree_skb(skb);
+	} else {
+		kfree(buf_addr);
+	}
+
+	priv->stats.rx_errors++;
+
+	return NULL;
+}
+
+
+/** pfe_eth_poll
+ */
+static int pfe_eth_poll(struct pfe_eth_priv_s *priv, struct napi_struct *napi, unsigned int qno, int budget)
+{
+	struct net_device *dev = priv->dev;
+	struct sk_buff *skb;
+	int work_done = 0;
+	unsigned int len;
+
+	netif_info(priv, intr, priv->dev, "%s\n", __func__);
+
+#ifdef PFE_ETH_NAPI_STATS
+	priv->napi_counters[NAPI_POLL_COUNT]++;
+#endif
+
+	do {
+		skb = pfe_eth_rx_skb(dev, priv, qno);
+
+		if (!skb)
+			break;
+
+		len = skb->len;
+
+		/* Packet will be processed */
+		skb->protocol = eth_type_trans(skb, dev);
+
+		netif_receive_skb(skb);
+
+		priv->stats.rx_packets++;
+		priv->stats.rx_bytes += len;
+
+		dev->last_rx = jiffies;
+
+		work_done++;
+
+#ifdef PFE_ETH_NAPI_STATS
+		priv->napi_counters[NAPI_PACKET_COUNT]++;
+#endif
+
+	} while (work_done < budget);
+
+	/* If no Rx receive nor cleanup work was done, exit polling mode.
+	 * No more netif_running(dev) check is required here , as this is checked in
+	 * net/core/dev.c ( 2.6.33.5 kernel specific).
+	 */
+	if (work_done < budget) {
+		napi_complete(napi);
+
+		hif_lib_event_handler_start(&priv->client, EVENT_RX_PKT_IND, qno);
+	}
+#ifdef PFE_ETH_NAPI_STATS
+	else
+		priv->napi_counters[NAPI_FULL_BUDGET_COUNT]++;
+#endif
+
+	return work_done;
+}
+
+/** pfe_eth_lro_poll
+ */
+static int pfe_eth_lro_poll(struct napi_struct *napi, int budget)
+{
+	struct pfe_eth_priv_s *priv = container_of(napi, struct pfe_eth_priv_s, lro_napi);
+
+	netif_info(priv, intr, priv->dev, "%s\n", __func__);
+
+	return pfe_eth_poll(priv, napi, 2, budget);
+}
+
+
+/** pfe_eth_low_poll
+ */
+static int pfe_eth_low_poll(struct napi_struct *napi, int budget)
+{
+	struct pfe_eth_priv_s *priv = container_of(napi, struct pfe_eth_priv_s, low_napi);
+
+	netif_info(priv, intr, priv->dev, "%s\n", __func__);
+
+	return pfe_eth_poll(priv, napi, 1, budget);
+}
+
+/** pfe_eth_high_poll
+ */
+static int pfe_eth_high_poll(struct napi_struct *napi, int budget )
+{
+	struct pfe_eth_priv_s *priv = container_of(napi, struct pfe_eth_priv_s, high_napi);
+
+	netif_info(priv, intr, priv->dev, "%s\n", __func__);
+
+	return pfe_eth_poll(priv, napi, 0, budget);
+}
+
+static const struct net_device_ops pfe_netdev_ops = {
+	.ndo_open = pfe_eth_open,
+	.ndo_stop = pfe_eth_close,
+	.ndo_start_xmit = pfe_eth_send_packet,
+	.ndo_select_queue = pfe_eth_select_queue,
+	.ndo_get_stats = pfe_eth_get_stats,
+	.ndo_change_mtu = pfe_eth_change_mtu,
+	.ndo_set_mac_address = pfe_eth_set_mac_address,
+	.ndo_set_rx_mode = pfe_eth_set_multi,
+	.ndo_set_features = pfe_eth_set_features,
+	.ndo_fix_features = pfe_eth_fix_features,
+	.ndo_validate_addr = eth_validate_addr,
+};
+
+
+/** pfe_eth_init_one 
+ */
+
+static int pfe_eth_init_one( struct pfe *pfe, int id )
+{
+	struct net_device *dev = NULL;
+	struct pfe_eth_priv_s *priv = NULL;
+	struct comcerto_eth_platform_data *einfo;
+	struct comcerto_mdio_platform_data *minfo;
+	struct comcerto_pfe_platform_data *pfe_info;
+	int err;
+
+	/* Extract pltform data */
+#if defined(CONFIG_PLATFORM_EMULATION) || defined(CONFIG_PLATFORM_PCI)
+	pfe_info = (struct comcerto_pfe_platform_data *) &comcerto_pfe_pdata;
+#else
+	pfe_info = (struct comcerto_pfe_platform_data *) pfe->dev->platform_data;
+#endif
+	if (!pfe_info) {
+		printk(KERN_ERR "%s: pfe missing additional platform data\n", __func__);
+		err = -ENODEV;
+		goto err0;
+	}
+
+	einfo = (struct comcerto_eth_platform_data *) pfe_info->comcerto_eth_pdata;
+
+	/* einfo never be NULL, but no harm in having this check */ 
+	if (!einfo) {
+		printk(KERN_ERR "%s: pfe missing additional gemacs platform data\n", __func__);
+		err = -ENODEV;
+		goto err0;
+	}
+
+	minfo = (struct comcerto_mdio_platform_data *) pfe_info->comcerto_mdio_pdata;
+
+	/* einfo never be NULL, but no harm in having this check */ 
+	if (!minfo) {
+		printk(KERN_ERR "%s: pfe missing additional mdios platform data\n", __func__);
+		err = -ENODEV;
+		goto err0;
+	}
+
+	/*
+	 * FIXME: Need to check some flag in "einfo" to know whether
+	 *        GEMAC is enabled Or not.
+	 */
+
+	/* Create an ethernet device instance */
+	dev = alloc_etherdev_mq(sizeof (*priv), emac_txq_cnt);
+
+	if (!dev) {
+		printk(KERN_ERR "%s: gemac %d device allocation failed\n", __func__, einfo[id].gem_id);
+		err = -ENOMEM;
+		goto err0;
+	}
+
+	priv = netdev_priv(dev);
+	priv->dev = dev;
+	priv->id = einfo[id].gem_id;
+	priv->pfe = pfe;
+
+#if defined(CONFIG_PLATFORM_C2000)
+	/* get gemac tx clock */
+	priv->gemtx_clk = clk_get(NULL, "gemtx");
+
+	if (IS_ERR(priv->gemtx_clk)) {
+		printk(KERN_ERR "%s: Unable to get the clock for gemac %d\n", __func__, priv->id);
+		err = -ENODEV;
+		goto err1; 
+	}
+#endif
+
+	pfe->eth.eth_priv[id] = priv;
+
+	/* Set the info in the priv to the current info */
+	priv->einfo = &einfo[id];
+	priv->EMAC_baseaddr = cbus_emac_base[id];
+	priv->PHY_baseaddr = cbus_emac_base[0];
+	priv->mdio_muxval = einfo[id].mdio_muxval;
+	priv->GPI_baseaddr = cbus_gpi_base[id];
+
+	/* FIXME : For now TMU queue numbers hardcoded, later should be taken from pfe.h */	
+#define HIF_GEMAC_TMUQ_BASE	6
+	priv->low_tmuQ	=  HIF_GEMAC_TMUQ_BASE + (id * 2);	
+	priv->high_tmuQ	=  priv->low_tmuQ + 1;	
+
+	spin_lock_init(&priv->lock);
+	priv->tx_timer.data = (unsigned long)priv;
+	priv->tx_timer.function = pfe_eth_tx_timeout;
+	priv->tx_timer.expires = jiffies + ( COMCERTO_TX_RECOVERY_TIMEOUT_MS * HZ )/1000;
+	init_timer(&priv->tx_timer);
+
+	pfe_eth_fast_tx_timeout_init(priv);
+
+	/* Copy the station address into the dev structure, */
+	memcpy(dev->dev_addr, einfo[id].mac_addr, ETH_ALEN);
+
+	/* Initialize mdio */
+	if (minfo[id].enabled) {
+		if ((err = pfe_eth_mdio_init(priv, &minfo[id]))) {
+			netdev_err(dev, "%s: pfe_eth_mdio_init() failed\n", __func__);
+			goto err2;
+		}
+	}
+
+	dev->mtu = 1500;
+
+	/* supported features */
+	dev->hw_features = NETIF_F_SG;
+	/* Enable after checksum offload is validated 
+	dev->hw_features = NETIF_F_RXCSUM | NETIF_F_IP_CSUM |  NETIF_F_IPV6_CSUM |
+				NETIF_F_SG; */
+
+	/* enabled by default */
+	dev->features = dev->hw_features;
+
+	priv->usr_features = dev->features;
+
+	dev->netdev_ops = &pfe_netdev_ops;
+
+	dev->ethtool_ops = &pfe_ethtool_ops;
+
+	/* Enable basic messages by default */
+	priv->msg_enable = NETIF_MSG_IFUP | NETIF_MSG_IFDOWN | NETIF_MSG_LINK | NETIF_MSG_PROBE;
+
+	netif_napi_add(dev, &priv->low_napi, pfe_eth_low_poll, HIF_RX_POLL_WEIGHT - 16);
+	netif_napi_add(dev, &priv->high_napi, pfe_eth_high_poll, HIF_RX_POLL_WEIGHT - 16);
+	netif_napi_add(dev, &priv->lro_napi, pfe_eth_lro_poll, HIF_RX_POLL_WEIGHT - 16);
+
+	err = register_netdev(dev);
+
+	if (err) {
+		netdev_err(dev, "register_netdev() failed\n");
+		goto err3;
+	}
+
+	if (!(priv->einfo->phy_flags & GEMAC_NO_PHY)) {
+		err = pfe_phy_init(dev);
+		if (err) {
+			netdev_err(dev, "%s: pfe_phy_init() failed\n", __func__);
+			goto err4;
+		}
+	}
+
+
+	/* Create all the sysfs files */
+	if(pfe_eth_sysfs_init(dev))
+		goto err4;
+
+	netif_info(priv, probe, dev, "%s: created interface, baseaddr: %p\n", __func__, priv->EMAC_baseaddr);
+
+	return 0;
+err4:
+	unregister_netdev(dev);
+err3:
+	pfe_eth_mdio_exit(priv->mii_bus);
+err2:
+#if defined(CONFIG_PLATFORM_C2000)
+	clk_put(priv->gemtx_clk);
+err1:
+#endif
+	free_netdev(priv->dev);
+
+err0:
+	return err;
+}
+
+/** pfe_eth_init
+ */
+int pfe_eth_init(struct pfe *pfe)
+{
+	int ii = 0;
+	int err;
+
+	printk(KERN_INFO "%s\n", __func__);
+
+	cbus_emac_base[0] = EMAC1_BASE_ADDR;
+	cbus_emac_base[1] = EMAC2_BASE_ADDR;
+
+	cbus_gpi_base[0] = EGPI1_BASE_ADDR;
+	cbus_gpi_base[1] = EGPI2_BASE_ADDR;
+
+#if !defined(CONFIG_PLATFORM_LS1012A)
+	cbus_emac_base[2] = EMAC3_BASE_ADDR;
+	cbus_gpi_base[2] = EGPI3_BASE_ADDR;
+#endif
+
+	for (ii = 0; ii < NUM_GEMAC_SUPPORT; ii++) {
+		if ((err = pfe_eth_init_one(pfe, ii)))
+			goto err0;
+	}
+
+	return 0;
+
+err0:
+	while(ii--){
+		pfe_eth_exit_one( pfe->eth.eth_priv[ii] );
+	} 
+
+	/* Register three network devices in the kernel */
+	return err;
+}
+
+/** pfe_eth_exit_one
+ */
+static void pfe_eth_exit_one(struct pfe_eth_priv_s *priv)
+{
+	netif_info(priv, probe, priv->dev, "%s\n", __func__);
+
+	pfe_eth_sysfs_exit(priv->dev);
+
+#if defined(CONFIG_PLATFORM_C2000)
+	clk_put(priv->gemtx_clk);
+#endif
+
+	unregister_netdev(priv->dev);
+
+	pfe_eth_mdio_exit(priv->mii_bus);
+
+	if (!(priv->einfo->phy_flags & GEMAC_NO_PHY))
+		pfe_phy_exit(priv->dev);
+
+	free_netdev(priv->dev);
+}
+
+/** pfe_eth_exit
+ */
+void pfe_eth_exit(struct pfe *pfe)
+{
+	int ii;
+
+	printk(KERN_INFO "%s\n", __func__);
+
+	for(ii = 0; ii < NUM_GEMAC_SUPPORT; ii++ ) {
+		/*
+		 * FIXME: Need to check some flag in "einfo" to know whether
+		 *        GEMAC is enabled Or not.
+		 */
+
+		pfe_eth_exit_one(pfe->eth.eth_priv[ii]);
+	}
+}
+
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/pfe_eth.h
@@ -0,0 +1,384 @@
+/*
+ *
+ *  Copyright (C) 2007 Freescale Semiconductor, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+
+#ifndef _PFE_ETH_H_
+#define _PFE_ETH_H_
+#include <linux/kernel.h>
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/ethtool.h>
+#include <linux/mii.h>
+#include <linux/phy.h>
+#include <linux/clk.h>
+#include <linux/interrupt.h>
+#include <linux/time.h>
+
+#define PFE_ETH_NAPI_STATS
+#define PFE_ETH_TX_STATS
+
+#define PFE_ETH_FRAGS_MAX (65536/HIF_RX_PKT_MIN_SIZE)
+#define LRO_LEN_COUNT_MAX	32
+#define LRO_NB_COUNT_MAX	32
+
+#if defined(CONFIG_PLATFORM_PCI) || defined(CONFIG_PLATFORM_EMULATION) || defined(CONFIG_PLATFORM_LS1012A)
+
+#define CONFIG_COMCERTO_GEMAC           1
+
+#define CONFIG_COMCERTO_USE_MII         1
+#define CONFIG_COMCERTO_USE_RMII                2
+#define CONFIG_COMCERTO_USE_GMII                4
+#define CONFIG_COMCERTO_USE_RGMII       8
+#define CONFIG_COMCERTO_USE_SGMII       16
+
+#define GEMAC_SW_CONF                   (1 << 8) | (1 << 11)    // GEMAC configured by SW
+#define GEMAC_PHY_CONF          0                       // GEMAC configured by phy lines (not for MII/GMII)
+#define GEMAC_SW_FULL_DUPLEX    (1 << 9)
+#define GEMAC_SW_SPEED_10M      (0 << 12)
+#define GEMAC_SW_SPEED_100M     (1 << 12)
+#define GEMAC_SW_SPEED_1G               (2 << 12)
+
+#define GEMAC_NO_PHY                    (1 << 0)                // set if no phy connected to MAC (ex ethernet switch). In this case use MAC fixed configuration
+#define GEMAC_PHY_RGMII_ADD_DELAY       (1 << 1)
+
+/* gemac to interface name assignment */
+#define GEMAC0_ITF_NAME "eth5"
+#define GEMAC1_ITF_NAME "eth6"
+#define GEMAC2_ITF_NAME "eth7"
+
+#define GEMAC0_MAC { 0x00, 0xED, 0xCD, 0xEF, 0xAA, 0xCC }
+#define GEMAC1_MAC { 0x00, 0x2A, 0x2B, 0x2C, 0x2D, 0x2E }
+
+struct comcerto_eth_platform_data {
+	/* device specific information */
+	u32 device_flags;
+	char name[16];
+
+
+	/* board specific information */
+	u32 mii_config;
+	u32 gemac_mode;
+	u32 phy_flags;
+	u32 gem_id;
+	u32 bus_id;
+	u32 phy_id;
+	u32 mdio_muxval;
+	u8 mac_addr[ETH_ALEN];
+};
+
+struct comcerto_mdio_platform_data {
+	int enabled;
+	int irq[32];
+	u32 phy_mask;
+	int mdc_div;
+};
+
+struct comcerto_pfe_platform_data
+{
+	struct comcerto_eth_platform_data comcerto_eth_pdata[3];
+	struct comcerto_mdio_platform_data comcerto_mdio_pdata[3];
+};
+#if !defined(CONFIG_PLATFORM_LS1012A)
+static struct comcerto_pfe_platform_data comcerto_pfe_pdata = {
+	.comcerto_eth_pdata[0] = {
+		.name = GEMAC0_ITF_NAME,
+		.device_flags = CONFIG_COMCERTO_GEMAC,
+		.mii_config = CONFIG_COMCERTO_USE_MII,
+		.gemac_mode = GEMAC_SW_CONF | GEMAC_SW_FULL_DUPLEX | GEMAC_SW_SPEED_100M,
+#if defined(CONFIG_PLATFORM_EMULATION) || defined(CONFIG_PLATFORM_PCI) 
+		.phy_flags = GEMAC_NO_PHY,
+#else
+		.phy_flags = GEMAC_PHY_RGMII_ADD_DELAY,
+#endif
+		.bus_id = 0,
+		.phy_id = 0,
+		.gem_id = 0,
+		.mac_addr = (u8[])GEMAC0_MAC,
+	},
+
+	.comcerto_eth_pdata[1] = {
+		.name = GEMAC1_ITF_NAME,
+		.device_flags = CONFIG_COMCERTO_GEMAC,
+		.mii_config = CONFIG_COMCERTO_USE_RGMII,
+		.gemac_mode = GEMAC_SW_CONF | GEMAC_SW_FULL_DUPLEX | GEMAC_SW_SPEED_1G,
+		.phy_flags = GEMAC_NO_PHY,
+		.gem_id = 1,
+		.mac_addr = (u8[])GEMAC1_MAC,
+	},
+
+	.comcerto_eth_pdata[2] = {
+		.name = GEMAC2_ITF_NAME,
+	},
+
+	.comcerto_mdio_pdata[0] = {
+		.enabled = 1,
+		.phy_mask = 0xFFFFFFFE,
+		.mdc_div = 96,
+		.irq = {
+			[0] = PHY_POLL,
+		},
+	},
+};
+#endif
+#endif
+
+#if defined(CONFIG_PLATFORM_LS1012A)
+#define NUM_GEMAC_SUPPORT		2
+#define DRV_NAME			"ls1012a-geth"
+#else
+#define NUM_GEMAC_SUPPORT		3
+#define DRV_NAME			"c2000-geth"
+#endif
+#define COMCERTO_INFOSTR_LEN		32
+#define COMCERTO_TX_RECOVERY_TIMEOUT_MS	500
+#define COMCERTO_TX_FAST_RECOVERY_TIMEOUT_MS	3
+#define TX_POLL_TIMEOUT_MS		1000
+
+#define EMAC_TXQ_CNT	16
+#define EMAC_TXQ_DEPTH	(HIF_TX_DESC_NT)
+
+#define JUMBO_FRAME_SIZE	10258
+/**
+ * Client Tx queue threshold, for txQ flush condition.
+ * It must be smaller than the queue size (in case we ever change it in the future).
+ */
+#define HIF_CL_TX_FLUSH_MARK	32
+
+/**
+ * Max number of TX resources (HIF descriptors or skbs) that will be released
+ * in a single go during batch recycling.
+ * Should be lower than the flush mark so the SW can provide the HW with a
+ * continuous stream of packets instead of bursts.
+ */
+#define TX_FREE_MAX_COUNT 16
+#define EMAC_RXQ_CNT	3
+#define EMAC_RXQ_DEPTH	HIF_RX_DESC_NT /* make sure clients can receive a full burst of packets */
+#define EMAC_RMON_TXBYTES_POS	0x00
+#define EMAC_RMON_RXBYTES_POS	0x14
+
+#define EMAC_QUEUENUM_MASK      (emac_txq_cnt - 1)
+#define EMAC_MDIO_TIMEOUT	1000
+#define MAX_UC_SPEC_ADDR_REG 31
+
+
+/* The set of statistics registers implemented in the Cadence MAC.
+ * The statistics registers implemented are a subset of all the statistics
+ * available, but contains all the compulsory ones.
+ * For full descriptions on the registers, refer to the Cadence MAC programmers
+ * guide or the IEEE 802.3 specifications.
+ */
+struct gemac_stats{
+	u32 octets_tx_bot;      /* Lower 32-bits for number of octets tx'd */
+	u32 octets_tx_top;      /* Upper 16-bits for number of octets tx'd */
+	u32 frames_tx;          /* Number of frames transmitted OK */
+	u32 broadcast_tx;       /* Number of broadcast frames transmitted */
+	u32 multicast_tx;       /* Number of multicast frames transmitted */
+	u32 pause_tx;           /* Number of pause frames transmitted. */
+	u32 frame64_tx;         /* Number of 64byte frames transmitted */
+	u32 frame65_127_tx;     /* Number of 65-127 byte frames transmitted */
+	u32 frame128_255_tx;    /* Number of 128-255 byte frames transmitted */
+	u32 frame256_511_tx;    /* Number of 256-511 byte frames transmitted */
+	u32 frame512_1023_tx;   /* Number of 512-1023 byte frames transmitted */
+	u32 frame1024_1518_tx;  /* Number of 1024-1518 byte frames transmitted*/
+	u32 frame1519_tx;       /* Number of frames greater than 1518 bytes tx*/
+	u32 tx_urun;            /* Transmit underrun errors due to DMA */
+	u32 single_col;         /* Number of single collision frames */
+	u32 multi_col;          /* Number of multi collision frames */
+	u32 excess_col;         /* Number of excessive collision frames. */
+	u32 late_col;           /* Collisions occuring after slot time */
+	u32 def_tx;             /* Frames deferred due to crs */
+	u32 crs_errors;         /* Errors caused by crs not being asserted. */
+	u32 octets_rx_bot;      /* Lower 32-bits for number of octets rx'd */
+	u32 octets_rx_top;      /* Upper 16-bits for number of octets rx'd */
+	u32 frames_rx;          /* Number of frames received OK */
+	u32 broadcast_rx;       /* Number of broadcast frames received */
+	u32 multicast_rx;       /* Number of multicast frames received */
+	u32 pause_rx;           /* Number of pause frames received. */
+	u32 frame64_rx;         /* Number of 64byte frames received */
+	u32 frame65_127_rx;     /* Number of 65-127 byte frames received */
+	u32 frame128_255_rx;    /* Number of 128-255 byte frames received */
+	u32 frame256_511_rx;    /* Number of 256-511 byte frames received */
+	u32 frame512_1023_rx;   /* Number of 512-1023 byte frames received */
+	u32 frame1024_1518_rx;  /* Number of 1024-1518 byte frames received*/
+	u32 frame1519_rx;       /* Number of frames greater than 1518 bytes rx*/
+	u32 usize_frames;       /* Frames received less than min of 64 bytes */
+	u32 excess_length;      /* Number of excessive length frames rx */
+	u32 jabbers;            /* Excessive length + crc or align errors. */
+	u32 fcs_errors;         /* Number of frames received with crc errors */
+	u32 length_check_errors;/* Number of frames with incorrect length */
+	u32 rx_symbol_errors;   /* Number of times rx_er asserted during rx */
+	u32 align_errors;       /* Frames received without integer no. bytes */
+	u32 rx_res_errors;      /* Number of times buffers ran out during rx */
+	u32 rx_orun;            /* Receive overrun errors due to DMA */
+	u32 ip_cksum;           /* IP header checksum errors */
+	u32 tcp_cksum;           /* TCP checksum errors */
+	u32 udp_cksum;           /* UDP checksum errors */
+};
+
+#define EMAC_REG_SPACE sizeof(struct gemac_reg)
+#define EMAC_RMON_LEN (sizeof(struct gemac_stats)/sizeof(u32))
+
+
+struct pfe_eth_fast_timer {
+	int queuenum;
+	struct hrtimer timer;
+	void * base;
+};
+
+typedef struct  pfe_eth_priv_s
+{
+	struct pfe 		*pfe;
+	struct hif_client_s	client;
+	struct napi_struct	lro_napi;
+	struct napi_struct   	low_napi;
+	struct napi_struct   	high_napi;
+	int			low_tmuQ;
+	int			high_tmuQ;
+	struct net_device_stats stats;
+	struct net_device 	*dev;
+	int 			id;
+	int 			promisc;
+	unsigned int		msg_enable;
+	unsigned int 		usr_features;
+
+	spinlock_t 		lock;
+	unsigned int 		event_status;
+	int 			irq;
+	void*   		EMAC_baseaddr;
+	void*			PHY_baseaddr; /* This points to the EMAC base from where we access PHY */
+	void*   		GPI_baseaddr;
+	int			mdio_muxval;
+	/* PHY stuff */
+	struct phy_device 	*phydev;
+	int 			oldspeed;
+	int 			oldduplex;
+	int 			oldlink;
+	/* mdio info */
+	int 			mdc_div;
+	struct mii_bus 		*mii_bus;
+	struct clk		*gemtx_clk;
+	int				wol;
+
+	int 			default_priority;
+	struct timer_list	tx_timer;
+	struct pfe_eth_fast_timer fast_tx_timeout[EMAC_TXQ_CNT];
+
+	struct comcerto_eth_platform_data *einfo;
+	struct sk_buff *skb_inflight[EMAC_RXQ_CNT + 6];
+
+#ifdef PFE_ETH_LRO_STATS
+	unsigned int lro_len_counters[LRO_LEN_COUNT_MAX];
+	unsigned int lro_nb_counters[LRO_NB_COUNT_MAX]; //TODO change to exact max number when RX scatter done
+#endif
+
+
+#ifdef PFE_ETH_TX_STATS
+	unsigned int stop_queue_total[EMAC_TXQ_CNT];
+	unsigned int stop_queue_hif[EMAC_TXQ_CNT];
+	unsigned int stop_queue_hif_client[EMAC_TXQ_CNT];
+	unsigned int stop_queue_credit[EMAC_TXQ_CNT];
+	unsigned int clean_fail[EMAC_TXQ_CNT];
+	unsigned int was_stopped[EMAC_TXQ_CNT];
+#endif
+
+#ifdef PFE_ETH_NAPI_STATS
+	unsigned int napi_counters[NAPI_MAX_COUNT];
+#endif
+	unsigned int frags_inflight[EMAC_RXQ_CNT + 6];
+
+}pfe_eth_priv_t;
+
+struct pfe_eth {
+	struct pfe_eth_priv_s *eth_priv[3];
+};
+
+int pfe_eth_init(struct pfe *pfe);
+void pfe_eth_exit(struct pfe *pfe);
+int pfe_eth_suspend(struct net_device *dev);
+int pfe_eth_resume(struct net_device *dev);
+int pfe_eth_mdio_reset(struct mii_bus *bus);
+
+/** pfe_compute_csum
+ *
+ */
+static int inline pfe_compute_csum(struct sk_buff *skb)
+{
+	struct skb_shared_info *sh;
+	unsigned int nr_frags;
+	skb_frag_t *f;
+	u32 csum = 0;
+	int i;
+	int len;
+
+	/* Make sure that no intermediate buffers/fragments are odd byte aligned */
+	if (skb_is_nonlinear(skb)) {
+		int linearize = 0;
+
+		sh = skb_shinfo(skb);
+		nr_frags = sh->nr_frags;
+		len = skb_headlen(skb) -  skb_transport_offset(skb);
+
+		if (len & 0x1) {
+			linearize = 1;
+			//printk("#1 Odd length %d\n", len);
+		}
+		else {
+			for (i = 0; i < nr_frags - 1; i++) {
+				f = &sh->frags[i];
+				len = skb_frag_size(f);
+
+				if (len & 0x1) {
+					linearize = 1;
+					//printk("#2 %d Odd length %d\n", i, len);
+					break;
+				}
+			}
+		}
+
+		if (linearize)
+			if (skb_linearize(skb))
+				return -1;
+	}
+
+	/* Compute checksum */
+	if (!skb_is_nonlinear(skb)) {
+		*(u16*)(skb_transport_header(skb) + skb->csum_offset) = csum_fold(csum_partial(skb_transport_header(skb), skb->len - skb_transport_offset(skb), 0));
+	}
+	else {
+		sh = skb_shinfo(skb);
+		nr_frags = sh->nr_frags;
+
+		if (nr_frags) {
+			csum = csum_partial(skb_transport_header(skb), skb_headlen(skb) -  skb_transport_offset(skb), 0);
+
+			for (i = 0; i < nr_frags - 1; i++) {
+				f = &sh->frags[i];
+				csum = csum_partial(skb_frag_address(f),  skb_frag_size(f), csum);
+			}
+
+			f = &sh->frags[i];
+			*(u16*)(skb_transport_header(skb) + skb->csum_offset) = csum_fold(csum_partial(skb_frag_address(f), skb_frag_size(f), csum));
+		}
+	}
+
+	return 0;
+}
+
+
+
+#endif /* _PFE_ETH_H_ */
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/pfe_firmware.c
@@ -0,0 +1,322 @@
+/*
+ *
+ *  Copyright (C) 2007 Freescale Semiconductor, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+
+/** @file
+ *  Contains all the functions to handle parsing and loading of PE firmware files.
+ */
+#include <linux/firmware.h>
+
+#include "pfe_mod.h"
+#include "pfe_firmware.h"
+#include "pfe/pfe.h"
+
+static Elf32_Shdr * get_elf_section_header(const struct firmware *fw, const char *section)
+{
+	Elf32_Ehdr *elf_hdr = (Elf32_Ehdr *)fw->data;
+	Elf32_Shdr *shdr, *shdr_shstr;
+	Elf32_Off e_shoff = be32_to_cpu(elf_hdr->e_shoff);
+	Elf32_Half e_shentsize = be16_to_cpu(elf_hdr->e_shentsize);
+	Elf32_Half e_shnum = be16_to_cpu(elf_hdr->e_shnum);
+	Elf32_Half e_shstrndx = be16_to_cpu(elf_hdr->e_shstrndx);
+	Elf32_Off shstr_offset;
+	Elf32_Word sh_name;
+	const char *name;
+	int i;
+
+	/* Section header strings */
+	shdr_shstr = (Elf32_Shdr *)(fw->data + e_shoff + e_shstrndx * e_shentsize);
+	shstr_offset = be32_to_cpu(shdr_shstr->sh_offset);
+
+	for (i = 0; i < e_shnum; i++) {
+		shdr = (Elf32_Shdr *)(fw->data + e_shoff + i * e_shentsize);
+
+		sh_name = be32_to_cpu(shdr->sh_name);
+
+		name = (const char *)(fw->data + shstr_offset + sh_name);
+
+		if (!strcmp(name, section))
+			return shdr;
+	}
+
+	printk(KERN_ERR "%s: didn't find section %s\n", __func__, section);
+
+	return NULL;
+}
+
+static unsigned long get_elf_section(const struct firmware *fw, const char *section)
+{
+	Elf32_Shdr *shdr = get_elf_section_header(fw, section);
+
+	if (shdr)
+		return be32_to_cpu(shdr->sh_addr);
+	else
+		return -1;
+}
+
+#if defined(CFG_DIAGS)
+static int pfe_get_diags_info(const struct firmware *fw, struct pfe_diags_info *diags_info)
+{
+	Elf32_Shdr *shdr;
+	unsigned long offset, size;
+
+	shdr = get_elf_section_header(fw, ".pfe_diags_str");
+	if (shdr)
+	{
+		offset = be32_to_cpu(shdr->sh_offset);
+		size = be32_to_cpu(shdr->sh_size);
+		diags_info->diags_str_base = be32_to_cpu(shdr->sh_addr);
+		diags_info->diags_str_size = size;
+		diags_info->diags_str_array = pfe_kmalloc(size, GFP_KERNEL);
+		memcpy(diags_info->diags_str_array, fw->data+offset, size);
+
+		return 0;
+	} else
+	{
+		return -1;
+	}
+}
+#endif
+
+static void pfe_check_version_info(const struct firmware *fw)
+{
+	static char *version = NULL;
+
+	Elf32_Shdr *shdr = get_elf_section_header(fw, ".version");
+
+	if (shdr)
+	{
+		if(!version)
+		{
+			/* this is the first fw we load, use its version string as reference (whatever it is) */
+			version = (char *)(fw->data + be32_to_cpu(shdr->sh_offset));
+
+			printk(KERN_INFO "PFE binary version: %s\n", version);
+		}
+		else
+		{
+			/* already have loaded at least one firmware, check sequence can start now */
+			if(strcmp(version, (char *)(fw->data + be32_to_cpu(shdr->sh_offset))))
+			{
+				printk(KERN_INFO "WARNING: PFE firmware binaries from incompatible version\n");
+			}
+		}
+	}
+	else
+	{
+		/* version cannot be verified, a potential issue that should be reported */
+		printk(KERN_INFO "WARNING: PFE firmware binaries from incompatible version\n");
+	}
+}
+
+/** PFE elf firmware loader.
+* Loads an elf firmware image into a list of PE's (specified using a bitmask)
+*
+* @param pe_mask	Mask of PE id's to load firmware to
+* @param fw		Pointer to the firmware image
+*
+* @return		0 on sucess, a negative value on error
+*
+*/
+int pfe_load_elf(int pe_mask, const struct firmware *fw, struct pfe *pfe)
+{
+	Elf32_Ehdr *elf_hdr = (Elf32_Ehdr *)fw->data;
+	Elf32_Half sections = be16_to_cpu(elf_hdr->e_shnum);
+	Elf32_Shdr *shdr = (Elf32_Shdr *) (fw->data + be32_to_cpu(elf_hdr->e_shoff));
+	int id, section;
+	int rc;
+
+	printk(KERN_INFO "%s\n", __func__);
+
+	/* Some sanity checks */
+	if (strncmp(&elf_hdr->e_ident[EI_MAG0], ELFMAG, SELFMAG))
+	{
+		printk(KERN_ERR "%s: incorrect elf magic number\n", __func__);
+		return -EINVAL;
+	}
+
+	if (elf_hdr->e_ident[EI_CLASS] != ELFCLASS32)
+	{
+		printk(KERN_ERR "%s: incorrect elf class(%x)\n", __func__, elf_hdr->e_ident[EI_CLASS]);
+		return -EINVAL;
+	}
+
+	if (elf_hdr->e_ident[EI_DATA] != ELFDATA2MSB)
+	{
+		printk(KERN_ERR "%s: incorrect elf data(%x)\n", __func__, elf_hdr->e_ident[EI_DATA]);
+		return -EINVAL;
+	}
+
+	if (be16_to_cpu(elf_hdr->e_type) != ET_EXEC)
+	{
+		printk(KERN_ERR "%s: incorrect elf file type(%x)\n", __func__, be16_to_cpu(elf_hdr->e_type));
+		return -EINVAL;
+	}	
+
+	for (section = 0; section < sections; section++, shdr++)
+	{
+		if (!(be32_to_cpu(shdr->sh_flags) & (SHF_WRITE | SHF_ALLOC | SHF_EXECINSTR)))
+                        continue;
+		
+		for (id = 0; id < MAX_PE; id++)
+			if (pe_mask & (1 << id))
+			{
+				rc = pe_load_elf_section(id, fw->data, shdr, pfe->dev);
+				if (rc < 0)
+					goto err;
+			}
+	}
+
+	pfe_check_version_info(fw);
+
+	return 0;
+
+err:
+	return rc;
+}
+
+
+/** PFE firmware initialization.
+* Loads different firmware files from filesystem.
+* Initializes PE IMEM/DMEM and UTIL-PE DDR
+* Initializes control path symbol addresses (by looking them up in the elf firmware files
+* Takes PE's out of reset
+*
+* @return	0 on sucess, a negative value on error
+*
+*/
+int pfe_firmware_init(struct pfe *pfe)
+{
+	const struct firmware *class_fw, *tmu_fw;
+	int rc = 0;
+#if !defined(CONFIG_UTIL_DISABLED)
+	const char* util_fw_name;
+	const struct firmware *util_fw;
+#endif
+
+	printk(KERN_INFO "%s\n", __func__);
+
+	if (request_firmware(&class_fw, CLASS_FIRMWARE_FILENAME, pfe->dev)) {
+		printk(KERN_ERR "%s: request firmware %s failed\n", __func__, CLASS_FIRMWARE_FILENAME);
+		rc = -ETIMEDOUT;
+		goto err0;
+	}
+
+	if (request_firmware(&tmu_fw, TMU_FIRMWARE_FILENAME, pfe->dev)) {
+		printk(KERN_ERR "%s: request firmware %s failed\n", __func__,  TMU_FIRMWARE_FILENAME);
+		rc = -ETIMEDOUT;
+		goto err1;
+        }
+#if !defined(CONFIG_UTIL_DISABLED)
+#if defined(CONFIG_PLATFORM_C2000)
+	util_fw_name = (system_rev == 0) ? UTIL_REVA0_FIRMWARE_FILENAME : UTIL_FIRMWARE_FILENAME;
+#else
+	util_fw_name = UTIL_FIRMWARE_FILENAME;
+#endif
+
+	if (request_firmware(&util_fw, util_fw_name, pfe->dev)) {
+		printk(KERN_ERR "%s: request firmware %s failed\n", __func__,  util_fw_name);
+		rc = -ETIMEDOUT;
+		goto err2;
+	}
+#endif
+	rc = pfe_load_elf(CLASS_MASK, class_fw, pfe);
+	if (rc < 0) {
+		printk(KERN_ERR "%s: class firmware load failed\n", __func__);
+		goto err3;
+	}
+
+	pfe->ctrl.class_dmem_sh = get_elf_section(class_fw, ".dmem_sh");
+	pfe->ctrl.class_pe_lmem_sh = get_elf_section(class_fw, ".pe_lmem_sh");
+
+#if defined(CFG_DIAGS)
+	rc = pfe_get_diags_info(class_fw, &pfe->diags.class_diags_info);
+	if (rc < 0) {
+		printk (KERN_WARNING "PFE diags won't be available for class PEs\n");
+		rc = 0;
+	}
+#endif
+
+	printk(KERN_INFO "%s: class firmware loaded %#lx %#lx\n", __func__, pfe->ctrl.class_dmem_sh, pfe->ctrl.class_pe_lmem_sh);
+
+	rc = pfe_load_elf(TMU_MASK, tmu_fw, pfe);
+	if (rc < 0) {
+		printk(KERN_ERR "%s: tmu firmware load failed\n", __func__);
+		goto err3;
+	}
+
+	pfe->ctrl.tmu_dmem_sh = get_elf_section(tmu_fw, ".dmem_sh");
+
+	printk(KERN_INFO "%s: tmu firmware loaded %#lx\n", __func__, pfe->ctrl.tmu_dmem_sh);
+
+#if !defined(CONFIG_UTIL_DISABLED)
+	rc = pfe_load_elf(UTIL_MASK, util_fw, pfe);
+	if (rc < 0) {
+		printk(KERN_ERR "%s: util firmware load failed\n", __func__);
+		goto err3;
+	}
+
+	pfe->ctrl.util_dmem_sh = get_elf_section(util_fw, ".dmem_sh");
+	pfe->ctrl.util_ddr_sh = get_elf_section(util_fw, ".ddr_sh");
+
+#if defined(CFG_DIAGS)
+	rc = pfe_get_diags_info(util_fw, &pfe->diags.util_diags_info);
+	if (rc < 0) {
+		printk(KERN_WARNING "PFE diags won't be available for util PE\n");
+		rc = 0;
+	}
+#endif
+
+	printk(KERN_INFO "%s: util firmware loaded %#lx\n", __func__, pfe->ctrl.util_dmem_sh);
+
+	util_enable();
+#endif
+
+	tmu_enable(0xf);
+	class_enable();
+
+err3:
+#if !defined(CONFIG_UTIL_DISABLED)
+	release_firmware(util_fw);
+
+err2:
+#endif
+	release_firmware(tmu_fw);
+
+err1:
+	release_firmware(class_fw);
+
+err0:
+	return rc;
+}
+
+/** PFE firmware cleanup
+* Puts PE's in reset
+*
+*
+*/
+void pfe_firmware_exit(struct pfe *pfe)
+{
+	printk(KERN_INFO "%s\n", __func__);
+
+	class_disable();
+	tmu_disable(0xf);
+#if !defined(CONFIG_UTIL_DISABLED)
+	util_disable();
+#endif
+}
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/pfe_firmware.h
@@ -0,0 +1,41 @@
+/*
+ *
+ *  Copyright (C) 2007 Freescale Semiconductor, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+
+#ifndef _PFE_FIRMWARE_H_
+#define _PFE_FIRMWARE_H_
+
+#if defined(CONFIG_PLATFORM_C2000)
+#define CLASS_FIRMWARE_FILENAME		"class_c2000.elf"
+#define TMU_FIRMWARE_FILENAME		"tmu_c2000.elf"
+#define UTIL_FIRMWARE_FILENAME		"util_c2000.elf"
+#define UTIL_REVA0_FIRMWARE_FILENAME	"util_c2000_revA0.elf"
+#else
+#define CLASS_FIRMWARE_FILENAME		"ppfe_class_ls1012a.elf"
+#define TMU_FIRMWARE_FILENAME		"ppfe_tmu_ls1012a.elf"
+#endif
+
+#define PFE_FW_CHECK_PASS		0
+#define PFE_FW_CHECK_FAIL		1
+#define NUM_PFE_FW				3
+
+int pfe_firmware_init(struct pfe *pfe);
+void pfe_firmware_exit(struct pfe *pfe);
+
+#endif /* _PFE_FIRMWARE_H_ */
+
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/pfe_hal.c
@@ -0,0 +1,2217 @@
+/*
+ *
+ *  Copyright (C) 2007 Freescale Semiconductor, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+
+
+#include "pfe_ctrl_hal.h" 
+#include "pfe/pfe.h"
+
+void *cbus_base_addr;
+void *ddr_base_addr;
+unsigned long ddr_phys_base_addr;
+unsigned int ddr_size;
+
+static struct pe_info pe[MAX_PE];
+
+/** Initializes the PFE library.
+* Must be called before using any of the library functions.
+*
+* @param[in] cbus_base		CBUS virtual base address (as mapped in the host CPU address space)
+* @param[in] ddr_base		PFE DDR range virtual base address (as mapped in the host CPU address space)
+* @param[in] ddr_phys_base	PFE DDR range physical base address (as mapped in platform)
+* @param[in] size		PFE DDR range size (as defined by the host software)
+*/
+void pfe_lib_init(void *cbus_base, void *ddr_base, unsigned long ddr_phys_base, unsigned int size)
+{
+	cbus_base_addr = cbus_base;
+	ddr_base_addr = ddr_base;
+	ddr_phys_base_addr = ddr_phys_base;
+	ddr_size = size;
+
+	pe[CLASS0_ID].dmem_base_addr = CLASS_DMEM_BASE_ADDR(0);
+	pe[CLASS0_ID].pmem_base_addr = CLASS_IMEM_BASE_ADDR(0);
+	pe[CLASS0_ID].pmem_size = CLASS_IMEM_SIZE;
+	pe[CLASS0_ID].mem_access_wdata = CLASS_MEM_ACCESS_WDATA;
+	pe[CLASS0_ID].mem_access_addr = CLASS_MEM_ACCESS_ADDR;
+	pe[CLASS0_ID].mem_access_rdata = CLASS_MEM_ACCESS_RDATA;
+
+	pe[CLASS1_ID].dmem_base_addr = CLASS_DMEM_BASE_ADDR(1);
+	pe[CLASS1_ID].pmem_base_addr = CLASS_IMEM_BASE_ADDR(1);
+	pe[CLASS1_ID].pmem_size = CLASS_IMEM_SIZE;
+	pe[CLASS1_ID].mem_access_wdata = CLASS_MEM_ACCESS_WDATA;
+	pe[CLASS1_ID].mem_access_addr = CLASS_MEM_ACCESS_ADDR;
+	pe[CLASS1_ID].mem_access_rdata = CLASS_MEM_ACCESS_RDATA;
+
+	pe[CLASS2_ID].dmem_base_addr = CLASS_DMEM_BASE_ADDR(2);
+	pe[CLASS2_ID].pmem_base_addr = CLASS_IMEM_BASE_ADDR(2);
+	pe[CLASS2_ID].pmem_size = CLASS_IMEM_SIZE;
+	pe[CLASS2_ID].mem_access_wdata = CLASS_MEM_ACCESS_WDATA;
+	pe[CLASS2_ID].mem_access_addr = CLASS_MEM_ACCESS_ADDR;
+	pe[CLASS2_ID].mem_access_rdata = CLASS_MEM_ACCESS_RDATA;
+
+	pe[CLASS3_ID].dmem_base_addr = CLASS_DMEM_BASE_ADDR(3);
+	pe[CLASS3_ID].pmem_base_addr = CLASS_IMEM_BASE_ADDR(3);
+	pe[CLASS3_ID].pmem_size = CLASS_IMEM_SIZE;
+	pe[CLASS3_ID].mem_access_wdata = CLASS_MEM_ACCESS_WDATA;
+	pe[CLASS3_ID].mem_access_addr = CLASS_MEM_ACCESS_ADDR;
+	pe[CLASS3_ID].mem_access_rdata = CLASS_MEM_ACCESS_RDATA;
+
+#if !defined(CONFIG_PLATFORM_PCI)
+	pe[CLASS4_ID].dmem_base_addr = CLASS_DMEM_BASE_ADDR(4);
+	pe[CLASS4_ID].pmem_base_addr = CLASS_IMEM_BASE_ADDR(4);
+	pe[CLASS4_ID].pmem_size = CLASS_IMEM_SIZE;
+	pe[CLASS4_ID].mem_access_wdata = CLASS_MEM_ACCESS_WDATA;
+	pe[CLASS4_ID].mem_access_addr = CLASS_MEM_ACCESS_ADDR;
+	pe[CLASS4_ID].mem_access_rdata = CLASS_MEM_ACCESS_RDATA;
+
+	pe[CLASS5_ID].dmem_base_addr = CLASS_DMEM_BASE_ADDR(5);
+	pe[CLASS5_ID].pmem_base_addr = CLASS_IMEM_BASE_ADDR(5);
+	pe[CLASS5_ID].pmem_size = CLASS_IMEM_SIZE;
+	pe[CLASS5_ID].mem_access_wdata = CLASS_MEM_ACCESS_WDATA;
+	pe[CLASS5_ID].mem_access_addr = CLASS_MEM_ACCESS_ADDR;
+	pe[CLASS5_ID].mem_access_rdata = CLASS_MEM_ACCESS_RDATA;
+#endif
+	pe[TMU0_ID].dmem_base_addr = TMU_DMEM_BASE_ADDR(0);
+	pe[TMU0_ID].pmem_base_addr = TMU_IMEM_BASE_ADDR(0);
+	pe[TMU0_ID].pmem_size = TMU_IMEM_SIZE;
+	pe[TMU0_ID].mem_access_wdata = TMU_MEM_ACCESS_WDATA;
+	pe[TMU0_ID].mem_access_addr = TMU_MEM_ACCESS_ADDR;
+	pe[TMU0_ID].mem_access_rdata = TMU_MEM_ACCESS_RDATA;
+
+#if !defined(CONFIG_TMU_DUMMY)
+	pe[TMU1_ID].dmem_base_addr = TMU_DMEM_BASE_ADDR(1);
+	pe[TMU1_ID].pmem_base_addr = TMU_IMEM_BASE_ADDR(1);
+	pe[TMU1_ID].pmem_size = TMU_IMEM_SIZE;
+	pe[TMU1_ID].mem_access_wdata = TMU_MEM_ACCESS_WDATA;
+	pe[TMU1_ID].mem_access_addr = TMU_MEM_ACCESS_ADDR;
+	pe[TMU1_ID].mem_access_rdata = TMU_MEM_ACCESS_RDATA;
+
+#if !defined(CONFIG_PLATFORM_LS1012A)
+	pe[TMU2_ID].dmem_base_addr = TMU_DMEM_BASE_ADDR(2);
+	pe[TMU2_ID].pmem_base_addr = TMU_IMEM_BASE_ADDR(2);
+	pe[TMU2_ID].pmem_size = TMU_IMEM_SIZE;
+	pe[TMU2_ID].mem_access_wdata = TMU_MEM_ACCESS_WDATA;
+	pe[TMU2_ID].mem_access_addr = TMU_MEM_ACCESS_ADDR;
+	pe[TMU2_ID].mem_access_rdata = TMU_MEM_ACCESS_RDATA;
+#endif
+
+	pe[TMU3_ID].dmem_base_addr = TMU_DMEM_BASE_ADDR(3);
+	pe[TMU3_ID].pmem_base_addr = TMU_IMEM_BASE_ADDR(3);
+	pe[TMU3_ID].pmem_size = TMU_IMEM_SIZE;
+	pe[TMU3_ID].mem_access_wdata = TMU_MEM_ACCESS_WDATA;
+	pe[TMU3_ID].mem_access_addr = TMU_MEM_ACCESS_ADDR;
+	pe[TMU3_ID].mem_access_rdata = TMU_MEM_ACCESS_RDATA;
+#endif
+
+#if !defined(CONFIG_UTIL_DISABLED)
+	pe[UTIL_ID].dmem_base_addr = UTIL_DMEM_BASE_ADDR;
+	pe[UTIL_ID].mem_access_wdata = UTIL_MEM_ACCESS_WDATA;
+	pe[UTIL_ID].mem_access_addr = UTIL_MEM_ACCESS_ADDR;
+	pe[UTIL_ID].mem_access_rdata = UTIL_MEM_ACCESS_RDATA;
+#endif
+}
+
+
+/** Writes a buffer to PE internal memory from the host
+ * through indirect access registers.
+ *
+ * @param[in] id		PE identification (CLASS0_ID, ..., TMU0_ID, ..., UTIL_ID)
+ * @param[in] src		Buffer source address
+ * @param[in] mem_access_addr	DMEM destination address (must be 32bit aligned)
+ * @param[in] len		Number of bytes to copy
+ */
+void pe_mem_memcpy_to32(int id, u32 mem_access_addr, const void *src, unsigned int len)
+{
+	u32 offset = 0, val, addr;
+	unsigned int len32 = len >> 2;
+	int i;
+
+	addr = mem_access_addr | PE_MEM_ACCESS_WRITE | PE_MEM_ACCESS_BYTE_ENABLE(0, 4);
+
+	for (i = 0; i < len32; i++, offset += 4, src += 4) {
+		val = *(u32 *)src;
+		writel(cpu_to_be32(val), pe[id].mem_access_wdata);
+		writel(addr + offset, pe[id].mem_access_addr);
+	}
+
+	if ((len = (len & 0x3))) {
+		val = 0;
+
+		addr = (mem_access_addr | PE_MEM_ACCESS_WRITE | PE_MEM_ACCESS_BYTE_ENABLE(0, len)) + offset;
+
+		for (i = 0; i < len; i++, src++)
+			val |= (*(u8 *)src) << (8 * i);
+
+		writel(cpu_to_be32(val), pe[id].mem_access_wdata);
+		writel(addr, pe[id].mem_access_addr);
+	}
+}
+
+/** Writes a buffer to PE internal data memory (DMEM) from the host
+ * through indirect access registers.
+ * @param[in] id		PE identification (CLASS0_ID, ..., TMU0_ID, ..., UTIL_ID)
+ * @param[in] src		Buffer source address
+ * @param[in] dst		DMEM destination address (must be 32bit aligned)
+ * @param[in] len		Number of bytes to copy
+ */
+void pe_dmem_memcpy_to32(int id, u32 dst, const void *src, unsigned int len)
+{
+	pe_mem_memcpy_to32(id, pe[id].dmem_base_addr | dst | PE_MEM_ACCESS_DMEM, src, len);
+}
+
+
+/** Writes a buffer to PE internal program memory (PMEM) from the host
+ * through indirect access registers.
+ * @param[in] id		PE identification (CLASS0_ID, ..., TMU0_ID, ..., TMU3_ID)
+ * @param[in] src		Buffer source address
+ * @param[in] dst		PMEM destination address (must be 32bit aligned)
+ * @param[in] len		Number of bytes to copy
+ */
+void pe_pmem_memcpy_to32(int id, u32 dst, const void *src, unsigned int len)
+{
+	pe_mem_memcpy_to32(id, pe[id].pmem_base_addr | (dst & (pe[id].pmem_size - 1)) | PE_MEM_ACCESS_IMEM, src, len);
+}
+
+
+/** Reads PE internal program memory (IMEM) from the host
+ * through indirect access registers.
+ * @param[in] id		PE identification (CLASS0_ID, ..., TMU0_ID, ..., TMU3_ID)
+ * @param[in] addr		PMEM read address (must be aligned on size)
+ * @param[in] size		Number of bytes to read (maximum 4, must not cross 32bit boundaries)
+ * @return			the data read (in PE endianess, i.e BE).
+ */
+u32 pe_pmem_read(int id, u32 addr, u8 size)
+{
+	u32 offset = addr & 0x3;
+	u32 mask = 0xffffffff >> ((4 - size) << 3);
+	u32 val;
+
+	addr = pe[id].pmem_base_addr | ((addr & ~0x3) & (pe[id].pmem_size - 1)) | PE_MEM_ACCESS_IMEM | PE_MEM_ACCESS_BYTE_ENABLE(offset, size);
+
+	writel(addr, pe[id].mem_access_addr);
+	val = be32_to_cpu(readl(pe[id].mem_access_rdata));
+
+	return (val >> (offset << 3)) & mask;
+}
+
+
+/** Writes PE internal data memory (DMEM) from the host
+ * through indirect access registers.
+ * @param[in] id		PE identification (CLASS0_ID, ..., TMU0_ID, ..., UTIL_ID)
+ * @param[in] addr		DMEM write address (must be aligned on size)
+ * @param[in] val		Value to write (in PE endianess, i.e BE)
+ * @param[in] size		Number of bytes to write (maximum 4, must not cross 32bit boundaries)
+ */
+void pe_dmem_write(int id, u32 val, u32 addr, u8 size)
+{
+	u32 offset = addr & 0x3;
+
+	addr = pe[id].dmem_base_addr | (addr & ~0x3) | PE_MEM_ACCESS_WRITE | PE_MEM_ACCESS_DMEM | PE_MEM_ACCESS_BYTE_ENABLE(offset, size);
+
+	/* Indirect access interface is byte swapping data being written */
+	writel(cpu_to_be32(val << (offset << 3)), pe[id].mem_access_wdata);
+	writel(addr, pe[id].mem_access_addr);
+}
+
+
+/** Reads PE internal data memory (DMEM) from the host
+ * through indirect access registers.
+ * @param[in] id		PE identification (CLASS0_ID, ..., TMU0_ID, ..., UTIL_ID)
+ * @param[in] addr		DMEM read address (must be aligned on size)
+ * @param[in] size		Number of bytes to read (maximum 4, must not cross 32bit boundaries)
+ * @return			the data read (in PE endianess, i.e BE).
+ */
+u32 pe_dmem_read(int id, u32 addr, u8 size)
+{
+	u32 offset = addr & 0x3;
+	u32 mask = 0xffffffff >> ((4 - size) << 3);
+	u32 val;
+
+	addr = pe[id].dmem_base_addr | (addr & ~0x3) | PE_MEM_ACCESS_DMEM | PE_MEM_ACCESS_BYTE_ENABLE(offset, size);
+
+	writel(addr, pe[id].mem_access_addr);
+
+	/* Indirect access interface is byte swapping data being read */
+	val = be32_to_cpu(readl(pe[id].mem_access_rdata));
+
+	return (val >> (offset << 3)) & mask;
+}
+
+
+/** This function is used to write to CLASS internal bus peripherals (ccu, pe-lem) from the host
+* through indirect access registers.
+* @param[in]	val	value to write
+* @param[in]	addr	Address to write to (must be aligned on size)
+* @param[in]	size	Number of bytes to write (1, 2 or 4)
+*
+*/
+void class_bus_write(u32 val, u32 addr, u8 size)
+{
+	u32 offset = addr & 0x3;
+
+	writel((addr & CLASS_BUS_ACCESS_BASE_MASK), CLASS_BUS_ACCESS_BASE);
+
+	addr = (addr & ~CLASS_BUS_ACCESS_BASE_MASK) | PE_MEM_ACCESS_WRITE | (size << 24);
+
+	writel(cpu_to_be32(val << (offset << 3)), CLASS_BUS_ACCESS_WDATA);
+	writel(addr, CLASS_BUS_ACCESS_ADDR);
+}
+
+
+/** Reads from CLASS internal bus peripherals (ccu, pe-lem) from the host
+* through indirect access registers.
+* @param[in] addr	Address to read from (must be aligned on size)
+* @param[in] size	Number of bytes to read (1, 2 or 4)
+* @return		the read data
+*
+*/
+u32 class_bus_read(u32 addr, u8 size)
+{
+	u32 offset = addr & 0x3;
+	u32 mask = 0xffffffff >> ((4 - size) << 3);
+	u32 val;
+
+	writel((addr & CLASS_BUS_ACCESS_BASE_MASK), CLASS_BUS_ACCESS_BASE);
+
+	addr = (addr & ~CLASS_BUS_ACCESS_BASE_MASK) | (size << 24);
+
+	writel(addr, CLASS_BUS_ACCESS_ADDR);
+	val = be32_to_cpu(readl(CLASS_BUS_ACCESS_RDATA));
+
+	return (val >> (offset << 3)) & mask;
+}
+
+
+/** Writes data to the cluster memory (PE_LMEM)
+* @param[in] dst	PE LMEM destination address (must be 32bit aligned)
+* @param[in] src	Buffer source address
+* @param[in] len	Number of bytes to copy
+*/
+void class_pe_lmem_memcpy_to32(u32 dst, const void *src, unsigned int len)
+{
+	u32 len32 = len >> 2;
+	int i;
+
+	for (i = 0; i < len32; i++, src += 4, dst += 4)
+		class_bus_write(*(u32 *)src, dst, 4);
+
+	if (len & 0x2)
+	{
+		class_bus_write(*(u16 *)src, dst, 2);
+		src += 2;
+		dst += 2;
+	}
+
+	if (len & 0x1)
+	{
+		class_bus_write(*(u8 *)src, dst, 1);
+		src++;
+		dst++;
+	}
+}
+
+/** Writes value to the cluster memory (PE_LMEM)
+* @param[in] dst	PE LMEM destination address (must be 32bit aligned)
+* @param[in] val	Value to write
+* @param[in] len	Number of bytes to write
+*/
+void class_pe_lmem_memset(u32 dst, int val, unsigned int len)
+{
+	u32 len32 = len >> 2;
+	int i;
+
+	val = val | (val << 8) | (val << 16) | (val << 24);
+	
+	for (i = 0; i < len32; i++, dst += 4)
+		class_bus_write(val, dst, 4);
+
+	if (len & 0x2)
+	{
+		class_bus_write(val, dst, 2);
+		dst += 2;
+	}
+
+	if (len & 0x1)
+	{
+		class_bus_write(val, dst, 1);
+		dst++;
+	}
+}
+
+#if !defined(CONFIG_UTIL_DISABLED)
+
+/** Writes UTIL program memory (DDR) from the host.
+ *
+ * @param[in] addr	Address to write (virtual, must be aligned on size)
+ * @param[in] val		Value to write (in PE endianess, i.e BE)
+ * @param[in] size		Number of bytes to write (2 or 4)
+ */
+static void util_pmem_write(u32 val, void *addr, u8 size)
+{
+	void *addr64 = (void *)((unsigned long)addr & ~0x7);
+	unsigned long off = 8 - ((unsigned long)addr & 0x7) - size;
+	
+	//IMEM should  be loaded as a 64bit swapped value in a 64bit aligned location
+	if (size == 4)
+		writel(be32_to_cpu(val), addr64 + off);
+	else
+		writew(be16_to_cpu((u16)val), addr64 + off);
+}
+
+
+/** Writes a buffer to UTIL program memory (DDR) from the host.
+ *
+ * @param[in] dst	Address to write (virtual, must be at least 16bit aligned)
+ * @param[in] src	Buffer to write (in PE endianess, i.e BE, must have same alignment as dst)
+ * @param[in] len	Number of bytes to write (must be at least 16bit aligned)
+ */
+static void util_pmem_memcpy(void *dst, const void *src, unsigned int len)
+{
+	unsigned int len32;
+	int i;
+
+	if ((unsigned long)src & 0x2) {
+		util_pmem_write(*(u16 *)src, dst, 2);
+		src += 2;
+		dst += 2;
+		len -= 2;
+	}
+
+	len32 = len >> 2;
+
+	for (i = 0; i < len32; i++, dst += 4, src += 4)
+		util_pmem_write(*(u32 *)src, dst, 4);
+
+	if (len & 0x2)
+		util_pmem_write(*(u16 *)src, dst, len & 0x2);
+}
+#endif
+
+/** Loads an elf section into pmem
+ * Code needs to be at least 16bit aligned and only PROGBITS sections are supported
+ *
+ * @param[in] id	PE identification (CLASS0_ID, ..., TMU0_ID, ..., TMU3_ID)
+ * @param[in] data	pointer to the elf firmware
+ * @param[in] shdr	pointer to the elf section header
+ *
+ */
+static int pe_load_pmem_section(int id, const void *data, Elf32_Shdr *shdr)
+{
+	u32 offset = be32_to_cpu(shdr->sh_offset);
+	u32 addr = be32_to_cpu(shdr->sh_addr);
+	u32 size = be32_to_cpu(shdr->sh_size);
+	u32 type = be32_to_cpu(shdr->sh_type);
+
+#if !defined(CONFIG_UTIL_DISABLED)
+	if (id == UTIL_ID)
+	{
+		printk(KERN_ERR "%s: unsuported pmem section for UTIL\n", __func__);
+		return -EINVAL;
+	}
+#endif
+
+	if (((unsigned long)(data + offset) & 0x3) != (addr & 0x3))
+	{
+		printk(KERN_ERR "%s: load address(%x) and elf file address(%lx) don't have the same alignment\n",
+			__func__, addr, (unsigned long) data + offset);
+
+		return -EINVAL;
+	}
+
+	if (addr & 0x1)
+	{
+		printk(KERN_ERR "%s: load address(%x) is not 16bit aligned\n", __func__, addr);
+		return -EINVAL;
+	}
+
+	if (size & 0x1)
+	{
+		printk(KERN_ERR "%s: load size(%x) is not 16bit aligned\n", __func__, size);
+		return -EINVAL;
+	}
+
+	switch (type)
+        {
+        case SHT_PROGBITS:
+		pe_pmem_memcpy_to32(id, addr, data + offset, size);
+
+		break;
+
+	default:
+		printk(KERN_ERR "%s: unsuported section type(%x)\n", __func__, type);
+		return -EINVAL;
+		break;
+	}
+
+	return 0;
+}
+
+
+/** Loads an elf section into dmem
+ * Data needs to be at least 32bit aligned, NOBITS sections are correctly initialized to 0
+ *
+ * @param[in] id		PE identification (CLASS0_ID, ..., TMU0_ID, ..., UTIL_ID)
+ * @param[in] data		pointer to the elf firmware
+ * @param[in] shdr		pointer to the elf section header
+ *
+ */
+static int pe_load_dmem_section(int id, const void *data, Elf32_Shdr *shdr)
+{
+	u32 offset = be32_to_cpu(shdr->sh_offset);
+	u32 addr = be32_to_cpu(shdr->sh_addr);
+	u32 size = be32_to_cpu(shdr->sh_size);
+	u32 type = be32_to_cpu(shdr->sh_type);
+	u32 size32 = size >> 2;
+	int i;
+
+	if (((unsigned long)(data + offset) & 0x3) != (addr & 0x3))
+	{
+		printk(KERN_ERR "%s: load address(%x) and elf file address(%lx) don't have the same alignment\n",
+			__func__, addr, (unsigned long)data + offset);
+
+		return -EINVAL;
+	}
+
+	if (addr & 0x3)
+	{
+		printk(KERN_ERR "%s: load address(%x) is not 32bit aligned\n", __func__, addr);
+		return -EINVAL;
+	}
+
+	switch (type)
+        {
+        case SHT_PROGBITS:
+		pe_dmem_memcpy_to32(id, addr, data + offset, size);
+		break;
+
+	case SHT_NOBITS:
+		for (i = 0; i < size32; i++, addr += 4)
+			pe_dmem_write(id, 0, addr, 4);
+
+		if (size & 0x3)
+			pe_dmem_write(id, 0, addr, size & 0x3);
+
+		break;
+
+	default:
+		printk(KERN_ERR "%s: unsuported section type(%x)\n", __func__, type);
+		return -EINVAL;
+		break;
+	}
+
+	return 0;
+}
+
+
+/** Loads an elf section into DDR
+ * Data needs to be at least 32bit aligned, NOBITS sections are correctly initialized to 0
+ *
+ * @param[in] id		PE identification (CLASS0_ID, ..., TMU0_ID, ..., UTIL_ID)
+ * @param[in] data		pointer to the elf firmware
+ * @param[in] shdr		pointer to the elf section header
+ *
+ */
+static int pe_load_ddr_section(int id, const void *data, Elf32_Shdr *shdr, struct device *dev)
+{
+	u32 offset = be32_to_cpu(shdr->sh_offset);
+	u32 addr = be32_to_cpu(shdr->sh_addr);
+	u32 size = be32_to_cpu(shdr->sh_size);
+	u32 type = be32_to_cpu(shdr->sh_type);
+	u32 flags = be32_to_cpu(shdr->sh_flags);
+
+	switch (type)
+	{
+	case SHT_PROGBITS:
+		if (flags & SHF_EXECINSTR)
+		{
+			if (id <= CLASS_MAX_ID)
+			{
+				/* DO the loading only once in DDR */
+				if (id == CLASS0_ID)
+				{
+					printk(KERN_ERR "%s: load address(%x) and elf file address(%lx) rcvd\n", __func__, addr, (unsigned long)data + offset);
+					if (((unsigned long)(data + offset) & 0x3) != (addr & 0x3))
+					{
+						printk(KERN_ERR "%s: load address(%x) and elf file address(%lx) don't have the same alignment\n",
+								__func__, addr, (unsigned long)data + offset);
+
+						return -EINVAL;
+					}
+
+					if (addr & 0x1)
+					{
+						printk(KERN_ERR "%s: load address(%x) is not 16bit aligned\n", __func__, addr);
+						return -EINVAL;
+					}
+
+					if (size & 0x1)
+					{
+						printk(KERN_ERR "%s: load length(%x) is not 16bit aligned\n", __func__, size);
+						return -EINVAL;
+					}
+					memcpy(DDR_PHYS_TO_VIRT(DDR_PFE_TO_PHYS(addr)), data + offset, size);
+				}
+			}
+#if !defined(CONFIG_UTIL_DISABLED)
+			else if (id == UTIL_ID)
+			{
+				if (((unsigned long)(data + offset) & 0x3) != (addr & 0x3))
+				{
+					printk(KERN_ERR "%s: load address(%x) and elf file address(%lx) don't have the same alignment\n",
+							__func__, addr, (unsigned long)data + offset);
+
+					return -EINVAL;
+				}
+
+				if (addr & 0x1)
+				{
+					printk(KERN_ERR "%s: load address(%x) is not 16bit aligned\n", __func__, addr);
+					return -EINVAL;
+				}
+
+				if (size & 0x1)
+				{
+					printk(KERN_ERR "%s: load length(%x) is not 16bit aligned\n", __func__, size);
+					return -EINVAL;
+				}
+
+				util_pmem_memcpy(DDR_PHYS_TO_VIRT(DDR_PFE_TO_PHYS(addr)), data + offset, size);
+			}
+#endif
+			else
+			{
+				printk(KERN_ERR "%s: unsuported ddr section type(%x) for PE(%d)\n", __func__, type, id);
+				return -EINVAL;
+			}
+
+		}
+		else
+		{
+			memcpy(DDR_PHYS_TO_VIRT(DDR_PFE_TO_PHYS(addr)), data + offset, size);
+		}
+
+		break;
+
+	case SHT_NOBITS:
+		memset(DDR_PHYS_TO_VIRT(DDR_PFE_TO_PHYS(addr)), 0, size);
+
+		break;
+
+	default:
+		printk(KERN_ERR "%s: unsuported section type(%x)\n", __func__, type);
+		return -EINVAL;
+		break;
+	}
+
+	return 0;
+}
+
+
+/** Loads an elf section into pe lmem
+ * Data needs to be at least 32bit aligned, NOBITS sections are correctly initialized to 0
+ *
+ * @param[in] id		PE identification (CLASS0_ID,..., CLASS5_ID)
+ * @param[in] data		pointer to the elf firmware
+ * @param[in] shdr		pointer to the elf section header
+ *
+ */
+static int pe_load_pe_lmem_section(int id, const void *data, Elf32_Shdr *shdr)
+{
+	u32 offset = be32_to_cpu(shdr->sh_offset);
+	u32 addr = be32_to_cpu(shdr->sh_addr);
+	u32 size = be32_to_cpu(shdr->sh_size);
+	u32 type = be32_to_cpu(shdr->sh_type);
+
+	if (id > CLASS_MAX_ID)
+	{
+		printk(KERN_ERR "%s: unsuported pe-lmem section type(%x) for PE(%d)\n", __func__, type, id);
+		return -EINVAL;
+	}
+	
+	if (((unsigned long)(data + offset) & 0x3) != (addr & 0x3))
+	{
+		printk(KERN_ERR "%s: load address(%x) and elf file address(%lx) don't have the same alignment\n",
+			__func__, addr, (unsigned long)data + offset);
+
+		return -EINVAL;
+	}
+
+	if (addr & 0x3)
+	{
+		printk(KERN_ERR "%s: load address(%x) is not 32bit aligned\n", __func__, addr);
+		return -EINVAL;
+	}
+
+	switch (type)
+	{
+	case SHT_PROGBITS:
+		class_pe_lmem_memcpy_to32(addr, data + offset, size);
+		break;
+
+	case SHT_NOBITS:
+		class_pe_lmem_memset(addr, 0, size);
+		break;
+
+	default:
+		printk(KERN_ERR "%s: unsuported section type(%x)\n", __func__, type);
+		return -EINVAL;
+		break;
+	}
+
+	return 0;
+}
+
+
+/** Loads an elf section into a PE
+ * For now only supports loading a section to dmem (all PE's), pmem (class and tmu PE's),
+ * DDDR (util PE code)
+ *
+ * @param[in] id		PE identification (CLASS0_ID, ..., TMU0_ID, ..., UTIL_ID)
+ * @param[in] data		pointer to the elf firmware
+ * @param[in] shdr		pointer to the elf section header
+ *
+ */
+int pe_load_elf_section(int id, const void *data, Elf32_Shdr *shdr, struct device *dev)
+{
+	u32 addr = be32_to_cpu(shdr->sh_addr);
+	u32 size = be32_to_cpu(shdr->sh_size);
+
+	if (IS_DMEM(addr, size))
+		return pe_load_dmem_section(id, data, shdr);
+	else if (IS_PMEM(addr, size))
+		return pe_load_pmem_section(id, data, shdr);
+	else if (IS_PFE_LMEM(addr, size))
+		return 0; /* FIXME */
+	else if (IS_PHYS_DDR(addr, size))
+		return pe_load_ddr_section(id, data, shdr, dev);
+	else if (IS_PE_LMEM(addr, size))
+		return pe_load_pe_lmem_section(id, data, shdr); 
+	else {
+		printk(KERN_ERR "%s: unsuported memory range(%x)\n", __func__, addr);
+//		return -EINVAL;
+	}
+
+	return 0;
+}
+
+
+/**************************** BMU ***************************/
+
+/** Initializes a BMU block.
+* @param[in] base	BMU block base address
+* @param[in] cfg	BMU configuration
+*/
+void bmu_init(void *base, BMU_CFG *cfg)
+{
+	bmu_disable(base);
+
+	bmu_set_config(base, cfg);
+
+	bmu_reset(base);
+}
+
+/** Resets a BMU block.
+* @param[in] base	BMU block base address
+*/
+void bmu_reset(void *base)
+{
+	writel(CORE_SW_RESET, base + BMU_CTRL);
+
+	/* Wait for self clear */
+	while (readl(base + BMU_CTRL) & CORE_SW_RESET) ;
+}
+
+/** Enabled a BMU block.
+* @param[in] base	BMU block base address
+*/
+void bmu_enable(void *base)
+{
+	writel (CORE_ENABLE, base + BMU_CTRL);
+}
+
+/** Disables a BMU block.
+* @param[in] base	BMU block base address
+*/
+void bmu_disable(void *base)
+{
+	writel (CORE_DISABLE, base + BMU_CTRL);
+}
+
+/** Sets the configuration of a BMU block.
+* @param[in] base	BMU block base address
+* @param[in] cfg	BMU configuration
+*/
+void bmu_set_config(void *base, BMU_CFG *cfg)
+{	
+	writel (cfg->baseaddr, base + BMU_UCAST_BASE_ADDR);
+	writel (cfg->count & 0xffff, base + BMU_UCAST_CONFIG);
+	writel (cfg->size & 0xffff, base + BMU_BUF_SIZE);
+//	writel (BMU1_THRES_CNT, base + BMU_THRES);
+
+	/* Interrupts are never used */
+//	writel (0x0, base + BMU_INT_SRC);
+	writel (0x0, base + BMU_INT_ENABLE);
+}
+#if defined(CONFIG_PLATFORM_C2000)
+/**************************** GEMAC ***************************/
+
+/** Enable Rx Checksum Engine. With this enabled, Frame with bad IP, 
+ *   TCP or UDP checksums are discarded
+ *
+ * @param[in] base	GEMAC base address. 
+ */
+void gemac_enable_rx_checksum_offload(void *base)
+{
+	writel(readl(base + EMAC_NETWORK_CONFIG) | EMAC_ENABLE_CHKSUM_RX, base + EMAC_NETWORK_CONFIG);
+	writel(readl(CLASS_L4_CHKSUM_ADDR) | IPV4_CHKSUM_DROP, CLASS_L4_CHKSUM_ADDR);
+}
+
+/** Disable Rx Checksum Engine.
+ *
+ * @param[in] base	GEMAC base address. 
+ */
+void gemac_disable_rx_checksum_offload(void *base)
+{
+	writel(readl(base + EMAC_NETWORK_CONFIG) & ~EMAC_ENABLE_CHKSUM_RX, base + EMAC_NETWORK_CONFIG);
+	writel(readl(CLASS_L4_CHKSUM_ADDR) & ~IPV4_CHKSUM_DROP, CLASS_L4_CHKSUM_ADDR);
+}
+
+/** Setup the MII Mgmt clock speed.
+ * @param[in] base	GEMAC base address (GEMAC0, GEMAC1, GEMAC2)
+ * @param[in] mdc_div	MII clock dividor
+ */
+void gemac_set_mdc_div(void *base, int mdc_div)
+{
+	u32 val = readl(base + EMAC_NETWORK_CONFIG) & ~EMAC_MDC_DIV_MASK;
+	u32 div;
+
+        switch (mdc_div) {
+        case 8:
+                div = 0;
+                break;
+
+        case 16:
+                div = 1;
+                break;
+
+        case 32:
+                div = 2;
+                break;
+
+        case 48:
+                div = 3;
+                break;
+
+        default:
+        case 64:
+                div = 4;
+                break;
+
+        case 96:
+                div = 5;
+                break;
+
+        case 128:
+                div = 6;
+                break;
+
+        case 224:
+                div = 7;
+                break;
+        }
+
+        val |= div << 18;
+
+        writel(val, base + EMAC_NETWORK_CONFIG);
+}
+
+/** GEMAC set speed.
+* @param[in] base	GEMAC base address
+* @param[in] speed	GEMAC speed (10, 100 or 1000 Mbps)
+*/
+void gemac_set_speed(void *base, MAC_SPEED gem_speed)
+{
+	u32 val = readl(base + EMAC_NETWORK_CONFIG);
+
+	val = val & ~EMAC_SPEED_MASK;
+
+	switch (gem_speed)
+	{
+		case SPEED_10M:
+			val &= (~EMAC_PCS_ENABLE);
+			break;
+
+		case SPEED_100M:
+			val = val | EMAC_SPEED_100;
+			val &= (~EMAC_PCS_ENABLE);
+			break;
+
+		case SPEED_1000M:
+			val = val | EMAC_SPEED_1000;
+			val &= (~EMAC_PCS_ENABLE);
+			break;
+
+		case SPEED_1000M_PCS:
+			val = val | EMAC_SPEED_1000;
+			val |= EMAC_PCS_ENABLE;
+			break;
+
+		default:
+			val = val | EMAC_SPEED_100;
+			val &= (~EMAC_PCS_ENABLE);
+		break;
+	}
+	
+	writel (val, base + EMAC_NETWORK_CONFIG);
+}
+
+/** GEMAC set duplex.
+* @param[in] base	GEMAC base address
+* @param[in] duplex	GEMAC duplex mode (Full, Half)
+*/
+void gemac_set_duplex(void *base, int duplex)
+{
+	u32 val = readl(base + EMAC_NETWORK_CONFIG);
+
+	if (duplex == DUPLEX_HALF)
+		val = (val & ~EMAC_DUPLEX_MASK) | EMAC_HALF_DUP;
+	else
+		val = (val & ~EMAC_DUPLEX_MASK) | EMAC_FULL_DUP;
+  
+	writel (val, base + EMAC_NETWORK_CONFIG);
+}
+
+/** GEMAC set mode.
+* @param[in] base	GEMAC base address
+* @param[in] mode	GEMAC operation mode (MII, RMII, RGMII, SGMII)
+*/
+
+#if defined(CONFIG_IP_ALIGNED)
+#define IP_ALIGNED_BITVAL	EMAC_TWO_BYTES_IP_ALIGN
+#else
+#define	IP_ALIGNED_BITVAL	0
+#endif
+
+void gemac_set_mode(void *base, int mode)
+{
+	switch (mode)
+	{
+	case GMII:
+		writel ((readl(base + EMAC_CONTROL) & ~EMAC_MODE_MASK) | EMAC_GMII_MODE_ENABLE | IP_ALIGNED_BITVAL, base + EMAC_CONTROL);
+		writel (readl(base + EMAC_NETWORK_CONFIG) & (~EMAC_SGMII_MODE_ENABLE), base + EMAC_NETWORK_CONFIG);
+		break;
+
+	case RGMII:
+		writel ((readl(base + EMAC_CONTROL) & ~EMAC_MODE_MASK) | EMAC_RGMII_MODE_ENABLE | IP_ALIGNED_BITVAL, base + EMAC_CONTROL);
+		writel (readl(base + EMAC_NETWORK_CONFIG) & (~EMAC_SGMII_MODE_ENABLE), base + EMAC_NETWORK_CONFIG);
+		break;
+
+	case RMII:
+		writel ((readl(base + EMAC_CONTROL) & ~EMAC_MODE_MASK) | EMAC_RMII_MODE_ENABLE | IP_ALIGNED_BITVAL, base + EMAC_CONTROL);
+		writel (readl(base + EMAC_NETWORK_CONFIG) & (~EMAC_SGMII_MODE_ENABLE), base + EMAC_NETWORK_CONFIG);
+		break;
+
+	case MII:
+		writel ((readl(base + EMAC_CONTROL) & ~EMAC_MODE_MASK) | EMAC_MII_MODE_ENABLE | IP_ALIGNED_BITVAL, base + EMAC_CONTROL);
+		writel (readl(base + EMAC_NETWORK_CONFIG) & (~EMAC_SGMII_MODE_ENABLE), base + EMAC_NETWORK_CONFIG);
+		break;
+
+	case SGMII:
+		writel ((readl(base + EMAC_CONTROL) & ~EMAC_MODE_MASK) | (EMAC_RMII_MODE_DISABLE | EMAC_RGMII_MODE_DISABLE) | IP_ALIGNED_BITVAL, base + EMAC_CONTROL);
+		writel (readl(base + EMAC_NETWORK_CONFIG) | EMAC_SGMII_MODE_ENABLE, base + EMAC_NETWORK_CONFIG);
+		break;
+
+	default:
+		writel ((readl(base + EMAC_CONTROL) & ~EMAC_MODE_MASK) | EMAC_MII_MODE_ENABLE | IP_ALIGNED_BITVAL, base + EMAC_CONTROL);
+		writel (readl(base + EMAC_NETWORK_CONFIG) & (~EMAC_SGMII_MODE_ENABLE), base + EMAC_NETWORK_CONFIG);
+		break;
+	}
+}
+/** GEMAC Enable MDIO: Activate the Management interface.  This is required to program the PHY
+ * @param[in] base       GEMAC base address
+ */
+void gemac_enable_mdio(void *base)
+{
+        u32 data;
+
+        data = readl(base + EMAC_NETWORK_CONTROL);
+        data |= EMAC_MDIO_EN;
+        writel(data, base + EMAC_NETWORK_CONTROL);
+}
+
+/** GEMAC Disable MDIO: Disable the Management interface.
+ * @param[in] base       GEMAC base address
+ */
+void gemac_disable_mdio(void *base)
+{
+        u32 data;
+
+        data = readl(base + EMAC_NETWORK_CONTROL);
+        data &= ~EMAC_MDIO_EN;
+        writel(data, base + EMAC_NETWORK_CONTROL);
+}
+
+
+/** GEMAC reset function.
+* @param[in] base	GEMAC base address
+*/
+void gemac_reset(void *base)
+{  
+}
+
+/** GEMAC enable function.
+* @param[in] base	GEMAC base address
+*/
+void gemac_enable(void *base)
+{  
+	writel (readl(base + EMAC_NETWORK_CONTROL) | EMAC_TX_ENABLE | EMAC_RX_ENABLE, base + EMAC_NETWORK_CONTROL);
+}
+
+/** GEMAC disable function.
+* @param[in] base	GEMAC base address
+*/
+void gemac_disable(void *base)
+{
+	writel (readl(base + EMAC_NETWORK_CONTROL) & ~(EMAC_TX_ENABLE | EMAC_RX_ENABLE), base + EMAC_NETWORK_CONTROL);
+}
+
+/** GEMAC TX disable function.
+* @param[in] base	GEMAC base address
+*/
+void gemac_tx_disable(void *base)
+{
+	writel (readl(base + EMAC_NETWORK_CONTROL) & ~(EMAC_TX_ENABLE), base + EMAC_NETWORK_CONTROL);
+}
+
+/** GEMAC set mac address configuration.
+* @param[in] base	GEMAC base address
+* @param[in] addr	MAC address to be configured
+*/
+void gemac_set_address(void *base, SPEC_ADDR *addr)
+{ 
+	writel(addr->one.bottom,	base + EMAC_SPEC1_ADD_BOT);
+	writel(addr->one.top,		base + EMAC_SPEC1_ADD_TOP); 
+	writel(addr->two.bottom,	base + EMAC_SPEC2_ADD_BOT);
+	writel(addr->two.top,		base + EMAC_SPEC2_ADD_TOP);
+	writel(addr->three.bottom,	base + EMAC_SPEC3_ADD_BOT);
+	writel(addr->three.top,		base + EMAC_SPEC3_ADD_TOP);
+	writel(addr->four.bottom,	base + EMAC_SPEC4_ADD_BOT);
+	writel(addr->four.top,		base + EMAC_SPEC4_ADD_TOP);
+} 
+
+/** GEMAC get mac address configuration.
+* @param[in] base	GEMAC base address
+*
+* @return		MAC addresses configured
+*/
+SPEC_ADDR gemac_get_address(void *base)
+{
+	SPEC_ADDR addr;
+	
+	addr.one.bottom = 	readl(base + EMAC_SPEC1_ADD_BOT);
+	addr.one.top = 		readl(base + EMAC_SPEC1_ADD_TOP); 
+	addr.two.bottom =	readl(base + EMAC_SPEC2_ADD_BOT);
+	addr.two.top =		readl(base + EMAC_SPEC2_ADD_TOP);
+	addr.three.bottom =	readl(base + EMAC_SPEC3_ADD_BOT);
+	addr.three.top =	readl(base + EMAC_SPEC3_ADD_TOP);
+	addr.four.bottom =	readl(base + EMAC_SPEC4_ADD_BOT);
+	addr.four.top =		readl(base + EMAC_SPEC4_ADD_TOP);
+	
+	return addr;
+}
+
+/** Sets the hash register of the MAC. 
+ * This register is used for matching unicast and multicast frames.
+ *
+ * @param[in] base	GEMAC base address.
+ * @param[in] hash	64-bit hash to be configured.	
+ */
+void gemac_set_hash( void *base, MAC_ADDR *hash )
+{
+	writel(hash->bottom,		base + EMAC_HASH_BOT);
+	writel(hash->top,		base + EMAC_HASH_TOP); 
+}
+
+/** Get the current value hash register of the MAC. 
+ * This register is used for matching unicast and multicast frames.
+ *
+ * @param[in] base	GEMAC base address
+
+ * @returns		64-bit hash.	
+ */
+MAC_ADDR gemac_get_hash( void *base )
+{
+	MAC_ADDR hash;
+
+	hash.bottom	= readl(base + EMAC_HASH_BOT);
+	hash.top	= readl(base + EMAC_HASH_TOP);
+
+	return hash;
+}
+
+/** GEMAC set specific local addresses of the MAC.
+* Rather than setting up all four specific addresses, this function sets them up individually.
+*
+* @param[in] base	GEMAC base address
+* @param[in] addr	MAC address to be configured
+*/
+void gemac_set_laddr1(void *base, MAC_ADDR *address)
+{
+	writel(address->bottom,		base + EMAC_SPEC1_ADD_BOT);
+	writel(address->top,		base + EMAC_SPEC1_ADD_TOP); 
+}
+
+
+void gemac_set_laddr2(void *base, MAC_ADDR *address)
+{
+	writel(address->bottom,		base + EMAC_SPEC2_ADD_BOT);
+	writel(address->top,		base + EMAC_SPEC2_ADD_TOP); 
+}
+
+
+void gemac_set_laddr3(void *base, MAC_ADDR *address)
+{
+	writel(address->bottom,		base + EMAC_SPEC3_ADD_BOT);
+	writel(address->top,		base + EMAC_SPEC3_ADD_TOP); 
+}
+
+
+void gemac_set_laddr4(void *base, MAC_ADDR *address)
+{
+	writel(address->bottom,		base + EMAC_SPEC4_ADD_BOT);
+	writel(address->top,		base + EMAC_SPEC4_ADD_TOP); 
+}
+
+void gemac_set_laddrN(void *base, MAC_ADDR *address, unsigned int entry_index)
+{
+	if( (entry_index < 1) || (entry_index > EMAC_SPEC_ADDR_MAX) )
+		return;
+
+	entry_index = entry_index - 1;
+
+	if (entry_index < 4)
+	{	
+		writel(address->bottom,		base + (entry_index * 8) + EMAC_SPEC1_ADD_BOT);
+		writel(address->top,		base + (entry_index * 8) + EMAC_SPEC1_ADD_TOP);
+	} 
+	else 
+	{
+		writel(address->bottom,		base + ((entry_index - 4) * 8) + EMAC_SPEC5_ADD_BOT);
+		writel(address->top,		base + ((entry_index - 4) * 8) + EMAC_SPEC5_ADD_TOP);
+	}
+}
+
+/** Get specific local addresses of the MAC.
+* This allows returning of a single specific address stored in the MAC.
+* @param[in] base	GEMAC base address
+*
+* @return		Specific MAC address 1
+* 
+*/
+MAC_ADDR gem_get_laddr1(void *base)
+{
+	MAC_ADDR addr;
+	addr.bottom = readl(base + EMAC_SPEC1_ADD_BOT);
+	addr.top = readl(base + EMAC_SPEC1_ADD_TOP);
+	return addr;
+}
+
+
+MAC_ADDR gem_get_laddr2(void *base)
+{
+	MAC_ADDR addr;
+	addr.bottom = readl(base + EMAC_SPEC2_ADD_BOT);
+	addr.top = readl(base + EMAC_SPEC2_ADD_TOP);
+	return addr;
+}
+
+
+MAC_ADDR gem_get_laddr3(void *base)
+{
+	MAC_ADDR addr;
+	addr.bottom = readl(base + EMAC_SPEC3_ADD_BOT);
+	addr.top = readl(base + EMAC_SPEC3_ADD_TOP);
+	return addr;
+}
+
+
+MAC_ADDR gem_get_laddr4(void *base)
+{
+	MAC_ADDR addr;
+	addr.bottom = readl(base + EMAC_SPEC4_ADD_BOT);
+	addr.top = readl(base + EMAC_SPEC4_ADD_TOP);
+	return addr;
+}
+
+MAC_ADDR gem_get_laddrN(void *base, unsigned int entry_index)
+{
+	MAC_ADDR addr = {0xffffffff, 0xffffffff};
+
+	if( (entry_index < 1) || (entry_index > EMAC_SPEC_ADDR_MAX) )
+		return addr;
+
+	entry_index = entry_index - 1;
+
+	if (entry_index < 4)
+	{
+		addr.bottom = readl(base + (entry_index * 8) + EMAC_SPEC1_ADD_BOT);
+		addr.top = readl(base + (entry_index * 8) + EMAC_SPEC1_ADD_TOP);
+	}
+	else
+	{
+		addr.bottom = readl(base + ((entry_index - 4) * 8) + EMAC_SPEC5_ADD_BOT);
+		addr.top = readl(base + ((entry_index - 4) * 8) + EMAC_SPEC5_ADD_TOP);
+	}
+
+	return addr;
+}
+
+/** Clear specific local addresses of the MAC.
+ * @param[in] base       GEMAC base address
+ */
+
+void gemac_clear_laddr1(void *base)
+{
+	writel(0, base + EMAC_SPEC1_ADD_BOT);
+}
+
+void gemac_clear_laddr2(void *base)
+{
+	writel(0, base + EMAC_SPEC2_ADD_BOT);
+}
+
+void gemac_clear_laddr3(void *base)
+{
+	writel(0, base + EMAC_SPEC3_ADD_BOT);
+}
+
+void gemac_clear_laddr4(void *base)
+{
+	writel(0, base + EMAC_SPEC4_ADD_BOT);
+}
+
+void gemac_clear_laddrN(void *base, unsigned int entry_index)
+{
+	if( (entry_index < 1) || (entry_index > EMAC_SPEC_ADDR_MAX) )
+		return;
+
+	entry_index = entry_index - 1;
+
+	if ( entry_index < 4 )
+		writel(0, base + (entry_index * 8) + EMAC_SPEC1_ADD_BOT);
+	else
+		writel(0, base + ((entry_index - 4) * 8) + EMAC_SPEC5_ADD_BOT);
+}
+
+/** Set the loopback mode of the MAC.  This can be either no loopback for normal
+ *   operation, local loopback through MAC internal loopback module or PHY
+ *   loopback for external loopback through a PHY.  This asserts the external loop
+ *   pin.
+ * 
+ * @param[in] base	GEMAC base address.
+ * @param[in] gem_loop	Loopback mode to be enabled. LB_LOCAL - MAC Loopback, 
+ *			LB_EXT - PHY Loopback.  
+ */
+void gemac_set_loop( void *base, MAC_LOOP gem_loop )
+{
+	switch (gem_loop) {
+		case LB_LOCAL:
+			writel(readl(base + EMAC_NETWORK_CONTROL) & (~EMAC_LB_PHY),
+							base + EMAC_NETWORK_CONTROL);
+			writel(readl(base + EMAC_NETWORK_CONTROL) | (EMAC_LB_MAC),
+							base + EMAC_NETWORK_CONTROL);
+			break;
+		case LB_EXT:
+			writel(readl(base + EMAC_NETWORK_CONTROL) & (~EMAC_LB_MAC),
+							base + EMAC_NETWORK_CONTROL);
+			writel(readl(base + EMAC_NETWORK_CONTROL) | (EMAC_LB_PHY),
+							base + EMAC_NETWORK_CONTROL);
+			break;
+		default:
+			writel(readl(base + EMAC_NETWORK_CONTROL) & (~(EMAC_LB_MAC | EMAC_LB_PHY)),
+									base + EMAC_NETWORK_CONTROL);
+	}
+}
+
+/** GEMAC allow frames
+ * @param[in] base	GEMAC base address
+ */
+void gemac_enable_copy_all(void *base)
+{
+	writel (readl(base + EMAC_NETWORK_CONFIG) | EMAC_ENABLE_COPY_ALL, base + EMAC_NETWORK_CONFIG);
+}
+
+/** GEMAC do not allow frames
+ * @param[in] base	GEMAC base address
+*/
+void gemac_disable_copy_all(void *base)
+{
+	writel (readl(base + EMAC_NETWORK_CONFIG) & ~EMAC_ENABLE_COPY_ALL, base + EMAC_NETWORK_CONFIG);
+}
+
+/** GEMAC allow broadcast function.
+* @param[in] base	GEMAC base address
+*/
+void gemac_allow_broadcast(void *base)
+{
+	writel (readl(base + EMAC_NETWORK_CONFIG) & ~EMAC_NO_BROADCAST, base + EMAC_NETWORK_CONFIG);
+}
+
+/** GEMAC no broadcast function.
+* @param[in] base	GEMAC base address
+*/
+void gemac_no_broadcast(void *base)
+{
+	writel (readl(base + EMAC_NETWORK_CONFIG) | EMAC_NO_BROADCAST, base + EMAC_NETWORK_CONFIG);
+}
+
+/** GEMAC enable unicast function.
+* @param[in] base	GEMAC base address
+*/
+void gemac_enable_unicast(void *base)
+{
+	writel (readl(base + EMAC_NETWORK_CONFIG) | EMAC_ENABLE_UNICAST, base + EMAC_NETWORK_CONFIG);
+}
+
+/** GEMAC disable unicast function.
+* @param[in] base	GEMAC base address
+*/
+void gemac_disable_unicast(void *base)
+{
+	writel (readl(base + EMAC_NETWORK_CONFIG) & ~EMAC_ENABLE_UNICAST, base + EMAC_NETWORK_CONFIG);
+}
+
+/** GEMAC enable multicast function.
+* @param[in] base	GEMAC base address
+*/
+void gemac_enable_multicast(void *base)
+{
+	writel (readl(base + EMAC_NETWORK_CONFIG) | EMAC_ENABLE_MULTICAST, base + EMAC_NETWORK_CONFIG);
+}
+
+/** GEMAC disable multicast function.
+* @param[in]	base	GEMAC base address
+*/
+void gemac_disable_multicast(void *base)
+{
+	writel (readl(base + EMAC_NETWORK_CONFIG) & ~EMAC_ENABLE_MULTICAST, base + EMAC_NETWORK_CONFIG);
+}
+
+/** GEMAC enable fcs rx function.
+* @param[in]	base	GEMAC base address
+*/
+void gemac_enable_fcs_rx(void *base)
+{
+	writel (readl(base + EMAC_NETWORK_CONFIG) | EMAC_ENABLE_FCS_RX, base + EMAC_NETWORK_CONFIG);
+}
+
+/** GEMAC disable fcs rx function.
+* @param[in]	base	GEMAC base address
+*/
+void gemac_disable_fcs_rx(void *base)
+{
+	writel (readl(base + EMAC_NETWORK_CONFIG) & ~EMAC_ENABLE_FCS_RX, base + EMAC_NETWORK_CONFIG);
+}
+
+/** GEMAC enable 1536 rx function.
+* @param[in]	base	GEMAC base address
+*/
+void gemac_enable_1536_rx(void *base)
+{
+	writel (readl(base + EMAC_NETWORK_CONFIG) | EMAC_ENABLE_1536_RX, base + EMAC_NETWORK_CONFIG);
+}
+
+/** GEMAC disable 1536 rx function.
+* @param[in]	base	GEMAC base address
+*/
+void gemac_disable_1536_rx(void *base)
+{
+	writel (readl(base + EMAC_NETWORK_CONFIG) & ~EMAC_ENABLE_1536_RX, base + EMAC_NETWORK_CONFIG);
+}
+
+/** GEMAC enable jumbo function.
+* @param[in]	base	GEMAC base address
+*/
+void gemac_enable_rx_jmb(void *base)
+{
+	writel (readl(base + EMAC_NETWORK_CONFIG) | EMAC_ENABLE_JUMBO_FRAME, base + EMAC_NETWORK_CONFIG);
+}
+
+/** GEMAC disable jumbo function.
+* @param[in]	base	GEMAC base address
+*/
+void gemac_disable_rx_jmb(void *base)
+{
+	writel (readl(base + EMAC_NETWORK_CONFIG) & ~EMAC_ENABLE_JUMBO_FRAME, base + EMAC_NETWORK_CONFIG);
+}
+
+/** GEMAC enable stacked vlan function.
+* @param[in]	base	GEMAC base address
+*/
+void gemac_enable_stacked_vlan(void *base)
+{
+	writel (readl(base + EMAC_STACKED_VLAN_REG) | EMAC_ENABLE_STACKED_VLAN, base + EMAC_STACKED_VLAN_REG);
+}
+
+/** GEMAC enable stacked vlan function.
+* @param[in]	base	GEMAC base address
+*/
+void gemac_disable_stacked_vlan(void *base)
+{
+	writel (readl(base + EMAC_STACKED_VLAN_REG) & ~EMAC_ENABLE_STACKED_VLAN, base + EMAC_STACKED_VLAN_REG);
+}
+
+/** GEMAC enable pause rx function.
+* @param[in] base	GEMAC base address
+*/
+void gemac_enable_pause_rx(void *base)
+{
+	writel (readl(base + EMAC_NETWORK_CONFIG) | EMAC_ENABLE_PAUSE_RX, base + EMAC_NETWORK_CONFIG);
+}
+
+/** GEMAC disable pause rx function.
+* @param[in] base	GEMAC base address
+*/
+void gemac_disable_pause_rx(void *base)
+{
+	writel (readl(base + EMAC_NETWORK_CONFIG) & ~EMAC_ENABLE_PAUSE_RX, base + EMAC_NETWORK_CONFIG);
+}
+
+/** GEMAC wol configuration
+* @param[in] base	GEMAC base address
+* @param[in] wol_conf	WoL register configuration
+*/
+void gemac_set_wol(void *base, u32 wol_conf)
+{
+	writel(wol_conf, base + EMAC_WOL);
+}
+
+/** Sets Gemac bus width to 64bit
+ * @param[in] base       GEMAC base address
+ * @param[in] width     gemac bus width to be set possible values are 32/64/128
+ * */
+void gemac_set_bus_width(void *base, int width)
+{
+	u32 val = readl(base + EMAC_NETWORK_CONFIG);
+	switch(width)
+	{
+		case 32:
+			val = (val & ~EMAC_DATA_BUS_WIDTH_MASK) | EMAC_DATA_BUS_WIDTH_32;
+		case 128:
+			val = (val & ~EMAC_DATA_BUS_WIDTH_MASK) | EMAC_DATA_BUS_WIDTH_128;
+		case 64:
+		default:
+			val = (val & ~EMAC_DATA_BUS_WIDTH_MASK) | EMAC_DATA_BUS_WIDTH_64;
+
+	}
+	writel (val, base + EMAC_NETWORK_CONFIG);
+}
+
+/** Sets Gemac configuration.
+* @param[in] base	GEMAC base address
+* @param[in] cfg	GEMAC configuration
+*/
+void gemac_set_config(void *base, GEMAC_CFG *cfg)
+{
+	gemac_set_mode(base, cfg->mode);
+
+	gemac_set_speed(base, cfg->speed);
+
+	gemac_set_duplex(base,cfg->duplex);
+}
+#elif defined(CONFIG_PLATFORM_LS1012A)
+/**************************** MTIP GEMAC ***************************/
+
+/** Enable Rx Checksum Engine. With this enabled, Frame with bad IP, 
+ *   TCP or UDP checksums are discarded
+ *
+ * @param[in] base	GEMAC base address. 
+ */
+void gemac_enable_rx_checksum_offload(void *base)
+{
+	/*Do not find configuration to do this */
+}
+
+/** Disable Rx Checksum Engine.
+ *
+ * @param[in] base	GEMAC base address. 
+ */
+void gemac_disable_rx_checksum_offload(void *base)
+{
+	/*Do not find configuration to do this */
+}
+
+/** GEMAC set speed.
+* @param[in] base	GEMAC base address
+* @param[in] speed	GEMAC speed (10, 100 or 1000 Mbps)
+*/
+void gemac_set_speed(void *base, MAC_SPEED gem_speed)
+{
+	u32 ecr = readl(base + EMAC_ECNTRL_REG) & ~EMAC_ECNTRL_SPEED;
+	u32 rcr = readl(base + EMAC_RCNTRL_REG) & ~EMAC_RCNTRL_RMII_10T;
+
+	switch (gem_speed)
+	{
+		case SPEED_10M:
+			rcr |= EMAC_RCNTRL_RMII_10T;
+			break;
+
+
+		case SPEED_1000M:
+			ecr |= EMAC_ECNTRL_SPEED;
+			break;
+
+		case SPEED_100M:
+		default:
+			/*It is in 100M mode */
+			break;
+	}
+	writel(ecr, (base + EMAC_ECNTRL_REG));
+	writel(rcr, (base + EMAC_RCNTRL_REG));
+}
+
+/** GEMAC set duplex.
+* @param[in] base	GEMAC base address
+* @param[in] duplex	GEMAC duplex mode (Full, Half)
+*/
+void gemac_set_duplex(void *base, int duplex)
+{
+
+	if (duplex == DUPLEX_HALF) {
+		printk("%s() TODO\n", __func__);
+		writel(readl(base + EMAC_TCNTRL_REG) & ~EMAC_TCNTRL_FDEN, base + EMAC_TCNTRL_REG);
+		writel(readl(base + EMAC_RCNTRL_REG) | EMAC_RCNTRL_DRT, (base + EMAC_RCNTRL_REG));
+	}else{
+		writel(readl(base + EMAC_TCNTRL_REG) | EMAC_TCNTRL_FDEN, base + EMAC_TCNTRL_REG);
+		writel(readl(base + EMAC_RCNTRL_REG) & ~EMAC_RCNTRL_DRT, (base + EMAC_RCNTRL_REG));
+	}
+}
+
+/** GEMAC set mode.
+* @param[in] base	GEMAC base address
+* @param[in] mode	GEMAC operation mode (MII, RMII, RGMII, SGMII)
+*/
+void gemac_set_mode(void *base, int mode)
+{
+	u32 val = readl(base + EMAC_RCNTRL_REG);
+
+	/*Remove loopbank*/
+	val &= ~EMAC_RCNTRL_LOOP;
+
+	/*Enable flow control and MII mode*/
+	val |= (EMAC_RCNTRL_FCE | EMAC_RCNTRL_MII_MODE);
+
+	writel(val, base + EMAC_RCNTRL_REG);
+}
+
+/** GEMAC enable function.
+* @param[in] base	GEMAC base address
+*/
+void gemac_enable(void *base)
+{ 
+	writel(readl(base + EMAC_ECNTRL_REG) | EMAC_ECNTRL_ETHER_EN, base + EMAC_ECNTRL_REG);
+}
+
+/** GEMAC disable function.
+* @param[in] base	GEMAC base address
+*/
+void gemac_disable(void *base)
+{
+	writel(readl(base + EMAC_ECNTRL_REG) & ~EMAC_ECNTRL_ETHER_EN, base + EMAC_ECNTRL_REG);
+}
+
+/** GEMAC TX disable function.
+* @param[in] base	GEMAC base address
+*/
+void gemac_tx_disable(void *base)
+{
+	writel(readl(base + EMAC_TCNTRL_REG) | EMAC_TCNTRL_GTS, base + EMAC_TCNTRL_REG);
+}
+
+/** Sets the hash register of the MAC. 
+ * This register is used for matching unicast and multicast frames.
+ *
+ * @param[in] base	GEMAC base address.
+ * @param[in] hash	64-bit hash to be configured.	
+ */
+void gemac_set_hash( void *base, MAC_ADDR *hash )
+{
+	writel(hash->bottom,  base + EMAC_GALR);
+	writel(hash->top, base + EMAC_GAUR);
+}
+
+void gemac_set_laddrN(void *base, MAC_ADDR *address, unsigned int entry_index)
+{
+	if( (entry_index < 1) || (entry_index > EMAC_SPEC_ADDR_MAX) )
+		return;
+
+	entry_index = entry_index - 1;
+	if (entry_index < 1) {
+		writel(htonl(address->bottom),  base + EMAC_PHY_ADDR_LOW);
+		writel((htonl(address->top) | 0x8808), base + EMAC_PHY_ADDR_HIGH);
+	}
+	else
+	{
+		/* TODO for other entry_index */
+		/*printk("%s  for entry_index %d \n",__func__, entry_index); */
+		writel(htonl(address->bottom),  base + ((entry_index - 1) * 8) + EMAC_SMAC_0_0);
+		writel((htonl(address->top) | 0x8808), base + ((entry_index - 1) * 8) + EMAC_SMAC_0_1);
+	}
+
+}
+
+void gemac_clear_laddrN(void *base, unsigned int entry_index)
+{
+	if( (entry_index < 1) || (entry_index > EMAC_SPEC_ADDR_MAX) )
+		return;
+
+	entry_index = entry_index - 1;
+	if (entry_index < 1) {
+		writel(0, base + EMAC_PHY_ADDR_LOW);
+		writel(0, base + EMAC_PHY_ADDR_HIGH);
+	}
+	else
+	{
+		writel(0,  base + ((entry_index - 1) * 8) + EMAC_SMAC_0_0);
+		writel(0, base + ((entry_index - 1) * 8) + EMAC_SMAC_0_1);
+	}
+
+
+}
+
+/** Set the loopback mode of the MAC.  This can be either no loopback for normal
+ *   operation, local loopback through MAC internal loopback module or PHY
+ *   loopback for external loopback through a PHY.  This asserts the external loop
+ *   pin.
+ * 
+ * @param[in] base	GEMAC base address.
+ * @param[in] gem_loop	Loopback mode to be enabled. LB_LOCAL - MAC Loopback, 
+ *			LB_EXT - PHY Loopback.  
+ */
+void gemac_set_loop( void *base, MAC_LOOP gem_loop )
+{
+	printk("%s()\n", __func__);
+	writel(readl(base + EMAC_RCNTRL_REG) | EMAC_RCNTRL_LOOP, (base + EMAC_RCNTRL_REG));
+}
+
+
+/** GEMAC allow frames
+ * @param[in] base	GEMAC base address
+ */
+void gemac_enable_copy_all(void *base)
+{
+	writel(readl(base + EMAC_RCNTRL_REG) | EMAC_RCNTRL_PROM, (base + EMAC_RCNTRL_REG));
+}
+
+/** GEMAC do not allow frames
+ * @param[in] base	GEMAC base address
+*/
+void gemac_disable_copy_all(void *base)
+{
+	writel(readl(base + EMAC_RCNTRL_REG) & ~EMAC_RCNTRL_PROM, (base + EMAC_RCNTRL_REG));
+}
+
+/** GEMAC allow broadcast function.
+* @param[in] base	GEMAC base address
+*/
+void gemac_allow_broadcast(void *base)
+{
+	writel (readl(base + EMAC_RCNTRL_REG) & ~EMAC_RCNTRL_BC_REJ, base + EMAC_RCNTRL_REG);
+}
+
+/** GEMAC no broadcast function.
+* @param[in] base	GEMAC base address
+*/
+void gemac_no_broadcast(void *base)
+{
+	writel (readl(base + EMAC_RCNTRL_REG) | EMAC_RCNTRL_BC_REJ, base + EMAC_RCNTRL_REG);
+}
+
+/** GEMAC enable unicast function.
+* @param[in] base	GEMAC base address
+*/
+void gemac_enable_unicast(void *base)
+{
+	return;
+}
+
+/** GEMAC disable unicast function.
+* @param[in] base	GEMAC base address
+*/
+void gemac_disable_unicast(void *base)
+{
+	return;
+}
+
+/** GEMAC enable multicast function.
+* @param[in] base	GEMAC base address
+*/
+void gemac_enable_multicast(void *base)
+{
+	return;
+}
+
+/** GEMAC disable multicast function.
+* @param[in]	base	GEMAC base address
+*/
+void gemac_disable_multicast(void *base)
+{
+	/* TODO how to disable multicast? */
+	return;
+}
+
+/** GEMAC enable fcs rx function.
+* @param[in]	base	GEMAC base address
+*/
+void gemac_enable_fcs_rx(void *base)
+{
+	/*Do not find configuration to do this */
+}
+
+/** GEMAC disable fcs rx function.
+* @param[in]	base	GEMAC base address
+*/
+void gemac_disable_fcs_rx(void *base)
+{
+	/*Do not find configuration to do this */
+}
+
+
+/** GEMAC enable 1536 rx function.
+* @param[in]	base	GEMAC base address
+*/
+void gemac_enable_1536_rx(void *base)
+{
+	/* Set 1536 as Maximum frame length */
+	writel (readl(base + EMAC_RCNTRL_REG) | (1536 << 16), base + EMAC_RCNTRL_REG);
+}
+
+/** GEMAC enable jumbo function.
+* @param[in]	base	GEMAC base address
+*/
+void gemac_enable_rx_jmb(void *base)
+{
+	/*TODO what is the jumbo size supported by MTIP */
+	writel (readl(base + EMAC_RCNTRL_REG) | (JUMBO_FRAME_SIZE << 16), base + EMAC_RCNTRL_REG);
+}
+
+/** GEMAC enable stacked vlan function.
+* @param[in]	base	GEMAC base address
+*/
+void gemac_enable_stacked_vlan(void *base)
+{
+	/* MTIP doesn't support stacked vlan */
+	return;
+}
+
+/** GEMAC enable pause rx function.
+* @param[in] base	GEMAC base address
+*/
+void gemac_enable_pause_rx(void *base)
+{
+	writel (readl(base + EMAC_RCNTRL_REG) | EMAC_RCNTRL_FCE, base + EMAC_RCNTRL_REG);
+}
+
+/** GEMAC disable pause rx function.
+* @param[in] base	GEMAC base address
+*/
+void gemac_disable_pause_rx(void *base)
+{
+	writel (readl(base + EMAC_RCNTRL_REG) & ~EMAC_RCNTRL_FCE, base + EMAC_RCNTRL_REG);
+}
+
+/** GEMAC wol configuration
+* @param[in] base	GEMAC base address
+* @param[in] wol_conf	WoL register configuration
+*/
+void gemac_set_wol(void *base, u32 wol_conf)
+{
+	printk("%s() TODO\n", __func__);
+}
+
+/** Sets Gemac bus width to 64bit
+ * @param[in] base       GEMAC base address
+ * @param[in] width     gemac bus width to be set possible values are 32/64/128
+ * */
+void gemac_set_bus_width(void *base, int width)
+{
+}
+
+/** Sets Gemac configuration.
+* @param[in] base	GEMAC base address
+* @param[in] cfg	GEMAC configuration
+*/
+void gemac_set_config(void *base, GEMAC_CFG *cfg)
+{
+
+	/*GEMAC config taken from VLSI */
+	writel(0x00000004, base + EMAC_TFWR_STR_FWD);
+	writel(0x00000005, base + EMAC_RX_SECTIOM_FULL);
+	writel(0x00003fff, base + EMAC_TRUNC_FL);
+	writel(0x00000030, base + EMAC_TX_SECTION_EMPTY);
+	writel(0x00000000, base + EMAC_MIB_CTRL_STS_REG);
+
+	gemac_set_mode(base, cfg->mode);
+
+	gemac_set_speed(base, cfg->speed);
+
+	gemac_set_duplex(base,cfg->duplex);
+}
+
+
+#endif //CONFIG_PLATFORM_LS1012A)
+
+
+
+/**************************** GPI ***************************/
+
+/** Initializes a GPI block.
+* @param[in] base	GPI base address
+* @param[in] cfg	GPI configuration
+*/
+void gpi_init(void *base, GPI_CFG *cfg)
+{ 
+	gpi_reset(base);
+
+	gpi_disable(base);
+
+	gpi_set_config(base, cfg);
+}
+
+/** Resets a GPI block.
+* @param[in] base	GPI base address
+*/
+void gpi_reset(void *base)
+{
+	writel (CORE_SW_RESET, base + GPI_CTRL);
+}
+
+/** Enables a GPI block.
+* @param[in] base	GPI base address
+*/
+void gpi_enable(void *base)
+{
+	writel (CORE_ENABLE, base + GPI_CTRL);
+}
+
+/** Disables a GPI block.
+* @param[in] base	GPI base address
+*/
+void gpi_disable(void *base)
+{
+	writel (CORE_DISABLE, base + GPI_CTRL);
+}
+
+
+/** Sets the configuration of a GPI block.
+* @param[in] base	GPI base address
+* @param[in] cfg	GPI configuration
+*/
+void gpi_set_config(void *base, GPI_CFG *cfg)
+{  
+	writel (CBUS_VIRT_TO_PFE(BMU1_BASE_ADDR + BMU_ALLOC_CTRL),	base + GPI_LMEM_ALLOC_ADDR);
+	writel (CBUS_VIRT_TO_PFE(BMU1_BASE_ADDR + BMU_FREE_CTRL),	base + GPI_LMEM_FREE_ADDR);
+	writel (CBUS_VIRT_TO_PFE(BMU2_BASE_ADDR + BMU_ALLOC_CTRL),	base + GPI_DDR_ALLOC_ADDR);
+	writel (CBUS_VIRT_TO_PFE(BMU2_BASE_ADDR + BMU_FREE_CTRL),	base + GPI_DDR_FREE_ADDR);
+	writel (CBUS_VIRT_TO_PFE(CLASS_INQ_PKTPTR),			base + GPI_CLASS_ADDR);
+ 	writel (DDR_HDR_SIZE,						base + GPI_DDR_DATA_OFFSET);
+	writel (LMEM_HDR_SIZE,						base + GPI_LMEM_DATA_OFFSET);
+	writel (0,							base + GPI_LMEM_SEC_BUF_DATA_OFFSET);
+	writel (0,							base + GPI_DDR_SEC_BUF_DATA_OFFSET);
+	writel ((DDR_HDR_SIZE << 16) | LMEM_HDR_SIZE,			base + GPI_HDR_SIZE);
+	writel ((DDR_BUF_SIZE << 16) | LMEM_BUF_SIZE,			base + GPI_BUF_SIZE);
+	
+	writel (((cfg->lmem_rtry_cnt << 16) | (GPI_DDR_BUF_EN << 1) | GPI_LMEM_BUF_EN),	base + GPI_RX_CONFIG);
+	writel (cfg->tmlf_txthres,					base + GPI_TMLF_TX);
+	writel (cfg->aseq_len,						base + GPI_DTX_ASEQ);
+	writel (1,							base + GPI_TOE_CHKSUM_EN);
+}
+
+/**************************** CLASSIFIER ***************************/
+
+/** Initializes CLASSIFIER block.
+* @param[in] cfg	CLASSIFIER configuration
+*/
+void class_init(CLASS_CFG *cfg)
+{
+	class_reset();
+	
+	class_disable();
+	
+	class_set_config(cfg);
+}
+
+/** Resets CLASSIFIER block.
+*
+*/
+void class_reset(void)
+{
+	writel(CORE_SW_RESET, CLASS_TX_CTRL);
+}
+
+/** Enables all CLASS-PE's cores.
+*
+*/
+void class_enable(void)
+{
+	writel(CORE_ENABLE, CLASS_TX_CTRL);
+}
+
+/** Disables all CLASS-PE's cores.
+*
+*/
+void class_disable(void)
+{
+	writel(CORE_DISABLE, CLASS_TX_CTRL); 
+}
+
+/** Sets the configuration of the CLASSIFIER block.
+* @param[in] cfg	CLASSIFIER configuration
+*/
+void class_set_config(CLASS_CFG *cfg)
+{
+	u32 val;
+
+	/* Initialize route table */
+	if (!cfg->resume)
+		memset(DDR_PHYS_TO_VIRT(cfg->route_table_baseaddr), 0, (1 << cfg->route_table_hash_bits) * CLASS_ROUTE_SIZE);
+
+#if !defined(LS1012A_PFE_RESET_WA)
+	writel(cfg->pe_sys_clk_ratio,	CLASS_PE_SYS_CLK_RATIO);
+#endif
+
+	writel((DDR_HDR_SIZE << 16) | LMEM_HDR_SIZE,	CLASS_HDR_SIZE);
+	writel(LMEM_BUF_SIZE,				CLASS_LMEM_BUF_SIZE);
+	writel(CLASS_ROUTE_ENTRY_SIZE(CLASS_ROUTE_SIZE) | CLASS_ROUTE_HASH_SIZE(cfg->route_table_hash_bits),	CLASS_ROUTE_HASH_ENTRY_SIZE);
+	writel(HIF_PKT_CLASS_EN| HIF_PKT_OFFSET(sizeof(struct hif_hdr)),     CLASS_HIF_PARSE);
+
+	val = HASH_CRC_PORT_IP | QB2BUS_LE;
+
+#if defined(CONFIG_IP_ALIGNED)
+	val |= IP_ALIGNED;
+#endif
+
+	/* Class PE packet steering will only work if TOE mode, bridge fetch or
+	 * route fetch are enabled (see class/qb_fet.v). Route fetch would trigger
+	 * additional memory copies (likely from DDR because of hash table size, which
+	 * cannot be reduced because PE software still relies on hash value computed
+	 *  in HW), so when not in TOE mode we simply enable HW bridge fetch even
+	 * though we don't use it.
+	 */
+	if (cfg->toe_mode)
+		val |= CLASS_TOE;
+	else
+	        val |= HW_BRIDGE_FETCH;
+
+	writel(val, CLASS_ROUTE_MULTI);
+
+	writel(DDR_PHYS_TO_PFE(cfg->route_table_baseaddr),		CLASS_ROUTE_TABLE_BASE);
+	writel(CLASS_PE0_RO_DM_ADDR0_VAL,		CLASS_PE0_RO_DM_ADDR0);
+	writel(CLASS_PE0_RO_DM_ADDR1_VAL,		CLASS_PE0_RO_DM_ADDR1);
+	writel(CLASS_PE0_QB_DM_ADDR0_VAL,		CLASS_PE0_QB_DM_ADDR0);
+	writel(CLASS_PE0_QB_DM_ADDR1_VAL,		CLASS_PE0_QB_DM_ADDR1);
+	writel(CBUS_VIRT_TO_PFE(TMU_PHY_INQ_PKTPTR),	CLASS_TM_INQ_ADDR);
+
+	writel(23, CLASS_AFULL_THRES);
+	writel(23, CLASS_TSQ_FIFO_THRES);
+
+	writel(24, CLASS_MAX_BUF_CNT);
+	writel(24, CLASS_TSQ_MAX_CNT);
+}
+
+/**************************** TMU ***************************/
+
+void tmu_reset(void)
+{
+	writel(SW_RESET, TMU_CTRL);
+}
+
+/** Initializes TMU block.
+* @param[in] cfg	TMU configuration
+*/
+void tmu_init(TMU_CFG *cfg)
+{
+	int q, phyno;
+
+	tmu_disable(0xF);
+	mdelay(10);
+
+#if !defined(LS1012A_PFE_RESET_WA)
+	/* keep in soft reset */
+	writel(SW_RESET,                     TMU_CTRL);
+#endif
+	writel(0x3,						TMU_SYS_GENERIC_CONTROL);
+	writel(750,						TMU_INQ_WATERMARK);
+	writel(CBUS_VIRT_TO_PFE(EGPI1_BASE_ADDR + GPI_INQ_PKTPTR),	TMU_PHY0_INQ_ADDR);
+	writel(CBUS_VIRT_TO_PFE(EGPI2_BASE_ADDR + GPI_INQ_PKTPTR),	TMU_PHY1_INQ_ADDR);
+#if !defined(CONFIG_PLATFORM_LS1012A)
+	writel(CBUS_VIRT_TO_PFE(EGPI3_BASE_ADDR + GPI_INQ_PKTPTR),	TMU_PHY2_INQ_ADDR);
+#endif
+	writel(CBUS_VIRT_TO_PFE(HGPI_BASE_ADDR + GPI_INQ_PKTPTR),	TMU_PHY3_INQ_ADDR);
+	writel(CBUS_VIRT_TO_PFE(HIF_NOCPY_RX_INQ0_PKTPTR),		TMU_PHY4_INQ_ADDR);
+	writel(CBUS_VIRT_TO_PFE(UTIL_INQ_PKTPTR),			TMU_PHY5_INQ_ADDR);
+	writel(CBUS_VIRT_TO_PFE(BMU2_BASE_ADDR + BMU_FREE_CTRL), 	TMU_BMU_INQ_ADDR);
+
+	writel(0x3FF,	TMU_TDQ0_SCH_CTRL);	// enabling all 10 schedulers [9:0] of each TDQ 
+	writel(0x3FF,	TMU_TDQ1_SCH_CTRL);
+#if !defined(CONFIG_PLATFORM_LS1012A)
+	writel(0x3FF,	TMU_TDQ2_SCH_CTRL);
+#endif
+	writel(0x3FF,	TMU_TDQ3_SCH_CTRL);
+
+#if !defined(LS1012A_PFE_RESET_WA)
+	writel(cfg->pe_sys_clk_ratio,	TMU_PE_SYS_CLK_RATIO);
+#endif
+
+#if !defined(LS1012A_PFE_RESET_WA)
+	writel(DDR_PHYS_TO_PFE(cfg->llm_base_addr),	TMU_LLM_BASE_ADDR);	// Extra packet pointers will be stored from this address onwards
+
+	writel(cfg->llm_queue_len,	TMU_LLM_QUE_LEN);
+	writel(5,			TMU_TDQ_IIFG_CFG);
+	writel(DDR_BUF_SIZE,		TMU_BMU_BUF_SIZE);
+
+	writel(0x0,			TMU_CTRL);
+
+	/* MEM init */
+	printk(KERN_INFO "%s: mem init\n", __func__);
+	writel(MEM_INIT,	TMU_CTRL);
+
+	while(!(readl(TMU_CTRL) & MEM_INIT_DONE)) ;
+
+	/* LLM init */
+	printk(KERN_INFO "%s: lmem init\n", __func__);
+	writel(LLM_INIT,	TMU_CTRL);
+
+	while(!(readl(TMU_CTRL) & LLM_INIT_DONE)) ;
+#endif
+	// set up each queue for tail drop
+	for (phyno = 0; phyno < 4; phyno++)
+	{
+#if defined(CONFIG_PLATFORM_LS1012A)
+		if(phyno == 2) continue;
+#endif
+		for (q = 0; q < 16; q++)
+		{
+			u32 qdepth;
+			writel((phyno << 8) | q, TMU_TEQ_CTRL);
+			writel(1 << 22, TMU_TEQ_QCFG); //Enable tail drop
+
+			if (phyno == 3)
+				qdepth = DEFAULT_TMU3_QDEPTH;
+			else
+				qdepth = (q == 0) ? DEFAULT_Q0_QDEPTH : DEFAULT_MAX_QDEPTH;
+
+			// LOG: 68855
+			// The following is a workaround for the reordered packet and BMU2 buffer leakage issue.
+			if (CHIP_REVISION() == 0)
+				qdepth = 31;
+
+			writel(qdepth << 18, TMU_TEQ_HW_PROB_CFG2);
+			writel(qdepth >> 14, TMU_TEQ_HW_PROB_CFG3);
+		}
+	}
+
+#ifdef CFG_LRO
+	/* Set TMU-3 queue 5 (LRO) in no-drop mode */
+	writel((3 << 8) | TMU_QUEUE_LRO, TMU_TEQ_CTRL);
+	writel(0, TMU_TEQ_QCFG);
+#endif
+
+	writel(0x05, TMU_TEQ_DISABLE_DROPCHK);
+
+	writel(0x0, TMU_CTRL);
+}
+
+/** Enables TMU-PE cores.
+* @param[in] pe_mask	TMU PE mask
+*/
+void tmu_enable(u32 pe_mask)
+{
+	writel(readl(TMU_TX_CTRL) | (pe_mask & 0xF), TMU_TX_CTRL);
+}
+
+/** Disables TMU cores.
+* @param[in] pe_mask	TMU PE mask
+*/
+void tmu_disable(u32 pe_mask)
+{
+	writel(readl(TMU_TX_CTRL) & ~(pe_mask & 0xF), TMU_TX_CTRL);
+}
+/** This will return the tmu queue status
+ * @param[in] if_id	gem interface id or TMU index
+ * @return		returns the bit mask of busy queues, zero means all queues are empty
+ */
+u32 tmu_qstatus(u32 if_id)
+{
+	return cpu_to_be32(pe_dmem_read(TMU0_ID+if_id, PESTATUS_ADDR_TMU + offsetof(PE_STATUS, tmu_qstatus), 4));
+}
+
+u32 tmu_pkts_processed(u32 if_id)
+{
+	return cpu_to_be32(pe_dmem_read(TMU0_ID+if_id, PESTATUS_ADDR_TMU + offsetof(PE_STATUS, rx), 4));
+}
+/**************************** UTIL ***************************/
+
+/** Resets UTIL block.
+*/
+void util_reset(void)
+{
+	writel(CORE_SW_RESET, UTIL_TX_CTRL);
+}
+
+/** Initializes UTIL block.
+* @param[in] cfg	UTIL configuration
+*/
+void util_init(UTIL_CFG *cfg)
+{
+	writel(cfg->pe_sys_clk_ratio,   UTIL_PE_SYS_CLK_RATIO);
+}
+
+/** Enables UTIL-PE core.
+*
+*/
+void util_enable(void)
+{
+	writel(CORE_ENABLE, UTIL_TX_CTRL);
+}
+
+/** Disables UTIL-PE core.
+*
+*/
+void util_disable(void)
+{
+	writel(CORE_DISABLE, UTIL_TX_CTRL);
+}
+
+/**************************** HIF ***************************/
+
+/** Initializes HIF no copy block.
+*
+*/
+void hif_nocpy_init(void)
+{
+	writel(4,							HIF_NOCPY_TX_PORT_NO);
+	writel(CBUS_VIRT_TO_PFE(BMU1_BASE_ADDR + BMU_ALLOC_CTRL),		HIF_NOCPY_LMEM_ALLOC_ADDR);
+	writel(CBUS_VIRT_TO_PFE(CLASS_INQ_PKTPTR),	HIF_NOCPY_CLASS_ADDR);
+	writel(CBUS_VIRT_TO_PFE(TMU_PHY_INQ_PKTPTR),	HIF_NOCPY_TMU_PORT0_ADDR);
+	writel(HIF_RX_POLL_CTRL_CYCLE<<16|HIF_TX_POLL_CTRL_CYCLE, HIF_NOCPY_POLL_CTRL); 
+}
+
+/** Enable hif_nocpy tx DMA and interrupt
+*
+*/
+void hif_nocpy_tx_enable(void)
+{
+	/*TODO not sure poll_cntrl_en is required or not */
+	writel( HIF_CTRL_DMA_EN, HIF_NOCPY_TX_CTRL);
+	//writel((readl(HIF_NOCPY_INT_ENABLE) | HIF_INT_EN | HIF_TXPKT_INT_EN), HIF_NOCPY_INT_ENABLE);
+}
+
+/** Disable hif_nocpy tx DMA and interrupt
+*
+*/
+void hif_nocpy_tx_disable(void)
+{
+	u32     hif_int;
+
+	writel(0, HIF_NOCPY_TX_CTRL);
+
+	hif_int = readl(HIF_NOCPY_INT_ENABLE);
+	hif_int &= HIF_TXPKT_INT_EN;
+	writel(hif_int, HIF_NOCPY_INT_ENABLE);
+}
+
+/** Enable hif rx DMA and interrupt
+*
+*/
+void hif_nocpy_rx_enable(void)
+{
+	hif_nocpy_rx_dma_start();
+	writel((readl(HIF_NOCPY_INT_ENABLE) | HIF_INT_EN | HIF_RXPKT_INT_EN), HIF_NOCPY_INT_ENABLE);
+}
+
+/** Disable hif_nocpy rx DMA and interrupt
+*
+*/
+void hif_nocpy_rx_disable(void)
+{
+	u32     hif_int;
+
+	writel(0, HIF_NOCPY_RX_CTRL);
+
+	hif_int = readl(HIF_NOCPY_INT_ENABLE);
+	hif_int &= HIF_RXPKT_INT_EN;
+	writel(hif_int, HIF_NOCPY_INT_ENABLE);
+
+}
+/** Initializes HIF copy block.
+*
+*/
+void hif_init(void)
+{
+	/*Initialize HIF registers*/
+	writel((HIF_RX_POLL_CTRL_CYCLE << 16) | HIF_TX_POLL_CTRL_CYCLE, HIF_POLL_CTRL); 
+}
+
+/** Enable hif tx DMA and interrupt
+*
+*/
+void hif_tx_enable(void)
+{
+	/*TODO not sure poll_cntrl_en is required or not */
+	writel(HIF_CTRL_DMA_EN, HIF_TX_CTRL);
+	writel((readl(HIF_INT_ENABLE) | HIF_INT_EN | HIF_TXPKT_INT_EN), HIF_INT_ENABLE);
+}
+
+/** Disable hif tx DMA and interrupt
+*
+*/
+void hif_tx_disable(void)
+{
+	u32	hif_int;
+
+	writel(0, HIF_TX_CTRL);
+
+	hif_int = readl(HIF_INT_ENABLE);
+	hif_int &= HIF_TXPKT_INT_EN;
+	writel(hif_int, HIF_INT_ENABLE);
+}
+
+/** Enable hif rx DMA and interrupt
+*
+*/
+void hif_rx_enable(void)
+{
+	hif_rx_dma_start();
+	writel((readl(HIF_INT_ENABLE) | HIF_INT_EN | HIF_RXPKT_INT_EN), HIF_INT_ENABLE);
+}
+
+/** Disable hif rx DMA and interrupt
+*
+*/
+void hif_rx_disable(void)
+{
+	u32	hif_int;
+
+	writel(0, HIF_RX_CTRL);
+
+	hif_int = readl(HIF_INT_ENABLE);
+	hif_int &= HIF_RXPKT_INT_EN;
+	writel(hif_int, HIF_INT_ENABLE);
+
+}
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/pfe_hif.c
@@ -0,0 +1,939 @@
+/*
+ *
+ *  Copyright (C) 2007 Freescale Semiconductor, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+
+#ifdef __KERNEL__
+#include <linux/kernel.h>
+#include <linux/interrupt.h>
+#include <linux/dma-mapping.h>
+#include <linux/dmapool.h>
+#include <linux/sched.h>
+#include <linux/module.h>
+#include <linux/list.h>
+#include <linux/kthread.h>
+#include <linux/slab.h>
+
+#include <asm/io.h>
+#include <asm/irq.h>
+#else
+#include "platform.h"
+#endif
+
+
+#include "pfe_mod.h"
+#if 0
+#define DMA_MAP_SINGLE(dev, vaddr, size, direction)	dma_map_single(dev, vaddr, size, direction)
+#define DMA_UNMAP_SINGLE(dev, vaddr, size, direction)	dma_unmap_single(dev, vaddr, size, direction)
+void ct_flush(void *addr, u32 size)
+{
+	dma_map_single(pfe->dev, addr, size, DMA_TO_DEVICE);
+}
+#else
+#define DMA_UNMAP_SINGLE(dev, vaddr, size, direction)
+#define DMA_MAP_SINGLE(dev, vaddr, size, direction)	virt_to_phys(vaddr)
+#define ct_flush(addr, sz)
+#endif
+
+#define HIF_INT_MASK	(HIF_INT | HIF_RXPKT_INT)
+
+#define inc_cl_idx(idxname) idxname = (idxname+1) & (queue->size-1)
+#define inc_hif_rxidx(idxname) idxname = (idxname+1) & (hif->RxRingSize-1)
+#define inc_hif_txidx(idxname) idxname = (idxname+1) & (hif->TxRingSize-1)
+
+unsigned char napi_first_batch = 0;
+
+static int pfe_hif_alloc_descr(struct pfe_hif *hif)
+{
+#if !defined(CONFIG_PLATFORM_PCI)
+	void *addr;
+	dma_addr_t dma_addr;
+	int err = 0;
+
+	printk(KERN_INFO "%s\n", __func__);
+	addr = dma_alloc_coherent(pfe->dev,
+			HIF_RX_DESC_NT * sizeof(struct hif_desc) + HIF_TX_DESC_NT * sizeof(struct hif_desc),
+			&dma_addr, GFP_KERNEL);
+
+	if (!addr) {
+		printk(KERN_ERR "%s: Could not allocate buffer descriptors!\n", __func__);
+		err = -ENOMEM;
+		goto err0;
+	}
+
+	hif->descr_baseaddr_p = dma_addr;
+	hif->descr_baseaddr_v = addr;
+#else
+	hif->descr_baseaddr_p = pfe->ddr_phys_baseaddr + HIF_DESC_BASEADDR;
+	hif->descr_baseaddr_v = pfe->ddr_baseaddr + HIF_DESC_BASEADDR;
+#endif
+	hif->RxRingSize = HIF_RX_DESC_NT;
+	hif->TxRingSize = HIF_TX_DESC_NT;
+
+	return 0;
+
+err0:
+	return err;
+}
+
+static void pfe_hif_free_descr(struct pfe_hif *hif)
+{
+	printk(KERN_INFO "%s\n", __func__);
+#if !defined(CONFIG_PLATFORM_PCI)
+	dma_free_coherent(pfe->dev,
+			hif->RxRingSize * sizeof(struct hif_desc) + hif->TxRingSize * sizeof(struct hif_desc),
+			hif->descr_baseaddr_v, hif->descr_baseaddr_p);
+#endif
+}
+void pfe_hif_desc_dump(struct pfe_hif *hif)
+{
+	struct hif_desc	*desc;
+	unsigned long desc_p;
+	int ii=0;
+
+	printk(KERN_INFO "%s\n", __func__);
+
+	desc = hif->RxBase;
+	desc_p = (u32)((u64)desc - (u64)hif->descr_baseaddr_v + hif->descr_baseaddr_p);
+
+	printk("HIF Rx desc base %p physical %x\n", desc, (u32)desc_p);
+	for (ii = 0; ii < hif->RxRingSize; ii++) {
+		printk(KERN_INFO "status: %08x, ctrl: %08x, data: %08x, next: %x\n",
+				desc->status, desc->ctrl, desc->data, desc->next);
+		desc++;
+	}
+
+	desc = hif->TxBase;
+	desc_p = ((u64)desc - (u64)hif->descr_baseaddr_v + hif->descr_baseaddr_p);
+
+	printk("HIF Tx desc base %p physical %x\n", desc, (u32)desc_p);
+	for (ii = 0; ii < hif->TxRingSize; ii++) {
+		printk(KERN_INFO "status: %08x, ctrl: %08x, data: %08x, next: %x\n",
+				desc->status, desc->ctrl, desc->data, desc->next);
+		desc++;
+	}
+
+}
+
+/* pfe_hif_release_buffers
+ *
+ */
+static void pfe_hif_release_buffers(struct pfe_hif *hif)
+{
+	struct hif_desc	*desc;
+	int i = 0;
+
+	hif->RxBase = hif->descr_baseaddr_v;
+
+	printk(KERN_INFO "%s\n", __func__);
+	/*Free Rx buffers */
+#if !defined(CONFIG_PLATFORM_PCI)
+	desc = hif->RxBase;
+	for (i = 0; i < hif->RxRingSize; i++) {
+		if (desc->data) {
+			if ((i < hif->shm->rx_buf_pool_cnt) && (hif->shm->rx_buf_pool[i] == NULL)) {
+				//dma_unmap_single(hif->dev, desc->data,  hif->rx_buf_len[i], DMA_FROM_DEVICE);
+				DMA_UNMAP_SINGLE(hif->dev, desc->data,  hif->rx_buf_len[i], DMA_FROM_DEVICE);
+				hif->shm->rx_buf_pool[i] = hif->rx_buf_addr[i];
+			}
+			else {
+				/*TODO This should not happen*/
+				printk(KERN_ERR "%s: buffer pool already full\n", __func__);
+			}
+		}
+
+		desc->data = 0;
+		desc->status = 0;
+		desc->ctrl =  0;
+		desc++;
+	}
+#endif
+}
+
+
+/*
+ * pfe_hif_init_buffers
+ * This function initializes the HIF Rx/Tx ring descriptors and
+ * initialize Rx queue with buffers.
+ */
+static int pfe_hif_init_buffers(struct pfe_hif *hif)
+{
+	struct hif_desc	*desc, *first_desc_p;
+	u32 data;
+	int i = 0;
+
+	printk(KERN_INFO "%s\n", __func__);
+
+	/* Check enough Rx buffers available in the shared memory */
+	if (hif->shm->rx_buf_pool_cnt < hif->RxRingSize)
+		return -ENOMEM;
+
+	hif->RxBase = hif->descr_baseaddr_v;
+	memset(hif->RxBase, 0, hif->RxRingSize * sizeof(struct hif_desc));
+
+	/*Initialize Rx descriptors */
+	desc = hif->RxBase;
+	first_desc_p = (struct hif_desc *)hif->descr_baseaddr_p;
+
+	for (i = 0; i < hif->RxRingSize; i++) {
+		/* Initialize Rx buffers from the shared memory */
+
+#if defined(CONFIG_PLATFORM_PCI)
+		data = pfe->ddr_phys_baseaddr + HIF_RX_PKT_DDR_BASEADDR + i * DDR_BUF_SIZE;
+#else
+		data = (u32)DMA_MAP_SINGLE(hif->dev, hif->shm->rx_buf_pool[i], pfe_pkt_size, DMA_FROM_DEVICE);
+		hif->rx_buf_addr[i] = hif->shm->rx_buf_pool[i];
+		hif->rx_buf_len[i] = pfe_pkt_size;
+	//	printk("#%d %p %p %d\n", i, data, hif->rx_buf_addr[i], hif->rx_buf_len[i]);
+		hif->shm->rx_buf_pool[i] = NULL;
+#endif
+		if (likely(dma_mapping_error(hif->dev, data) == 0)) {
+			desc->data = DDR_PHYS_TO_PFE(data);
+		} else {
+			printk(KERN_ERR "%s : low on mem\n",  __func__);
+
+			goto err;
+		}
+
+		desc->status = 0;
+		wmb();
+		desc->ctrl = BD_CTRL_PKT_INT_EN | BD_CTRL_LIFM | BD_CTRL_DIR |
+			BD_CTRL_DESC_EN | BD_BUF_LEN(pfe_pkt_size);
+		/* Chain descriptors */
+		desc->next = (u32)DDR_PHYS_TO_PFE(first_desc_p + i + 1);
+		desc++;
+	}
+
+	/* Overwrite last descriptor to chain it to first one*/
+	desc--;
+	desc->next = (u32)DDR_PHYS_TO_PFE(first_desc_p);
+
+	hif->RxtocleanIndex = 0;
+
+	/*Initialize Rx buffer descriptor ring base address */
+	writel(DDR_PHYS_TO_PFE(hif->descr_baseaddr_p), HIF_RX_BDP_ADDR);
+
+	hif->TxBase = hif->RxBase + hif->RxRingSize;
+	first_desc_p = (struct hif_desc *)hif->descr_baseaddr_p + hif->RxRingSize;
+	memset(hif->TxBase, 0, hif->TxRingSize * sizeof(struct hif_desc));
+
+	/*Initialize tx descriptors */
+	desc = hif->TxBase;
+
+	for (i = 0; i < hif->TxRingSize; i++) {
+		/* Chain descriptors */
+		desc->next = (u32)DDR_PHYS_TO_PFE(first_desc_p + i + 1);
+#if defined(CONFIG_PLATFORM_PCI)
+		desc->data =  pfe->ddr_phys_baseaddr + HIF_TX_PKT_DDR_BASEADDR + i * DDR_BUF_SIZE;
+#endif
+		desc->ctrl = 0;
+		desc++;
+	}
+
+	/* Overwrite last descriptor to chain it to first one */
+	desc--;
+	desc->next = (u32)DDR_PHYS_TO_PFE(first_desc_p);
+	hif->TxAvail = hif->TxRingSize;
+	hif->Txtosend = 0;
+	hif->Txtoclean = 0;
+	hif->Txtoflush = 0;
+
+	/*Initialize Tx buffer descriptor ring base address */
+	writel((u32)DDR_PHYS_TO_PFE(first_desc_p), HIF_TX_BDP_ADDR);
+
+	return 0;
+
+err:
+	pfe_hif_release_buffers(hif);
+	return -ENOMEM;
+}
+
+/* pfe_hif_client_register
+ *
+ * This function used to register a client driver with the HIF driver.
+ *
+ * Return value:
+ * 0 - on Successful registration
+ */
+static int pfe_hif_client_register(struct pfe_hif *hif, u32 client_id, struct hif_client_shm *client_shm)
+{
+	struct hif_client *client = &hif->client[client_id];
+	u32 i, cnt;
+	struct rx_queue_desc *rx_qbase;
+	struct tx_queue_desc *tx_qbase;
+	struct hif_rx_queue *rx_queue;
+	struct hif_tx_queue *tx_queue;
+	int err = 0;
+
+	printk(KERN_INFO "%s\n", __func__);
+
+	spin_lock_bh(&hif->tx_lock);
+
+	if (test_bit(client_id, &hif->shm->gClient_status[0])) {
+		printk(KERN_ERR "%s: client %d already registered\n", __func__, client_id);
+		err = -1;
+		goto unlock;
+	}
+
+	memset(client, 0, sizeof(struct hif_client));
+
+	/*Initialize client Rx queues baseaddr, size */
+
+	cnt = CLIENT_CTRL_RX_Q_CNT(client_shm->ctrl);
+	/*Check if client is requesting for more queues than supported */
+	if (cnt > HIF_CLIENT_QUEUES_MAX)
+		cnt = HIF_CLIENT_QUEUES_MAX;
+
+	client->rx_qn = cnt;
+	rx_qbase = (struct rx_queue_desc *)client_shm->rx_qbase;
+	for (i = 0; i < cnt; i++)
+	{
+		rx_queue = &client->rx_q[i];
+		rx_queue->base = rx_qbase + i * client_shm->rx_qsize;
+		rx_queue->size = client_shm->rx_qsize;
+		rx_queue->write_idx = 0;
+	}
+
+	/*Initialize client Tx queues baseaddr, size */
+	cnt = CLIENT_CTRL_TX_Q_CNT(client_shm->ctrl);
+
+	/*Check if client is requesting for more queues than supported */
+	if (cnt > HIF_CLIENT_QUEUES_MAX)
+		cnt = HIF_CLIENT_QUEUES_MAX;
+
+	client->tx_qn = cnt;
+	tx_qbase = (struct tx_queue_desc *)client_shm->tx_qbase;
+	for (i = 0; i < cnt; i++)
+	{
+		tx_queue = &client->tx_q[i];
+		tx_queue->base = tx_qbase + i * client_shm->tx_qsize;
+		tx_queue->size = client_shm->tx_qsize;
+		tx_queue->ack_idx = 0;
+	}
+
+	set_bit(client_id, &hif->shm->gClient_status[0]);
+
+unlock:
+	spin_unlock_bh(&hif->tx_lock);
+
+	return err;
+}
+
+
+/* pfe_hif_client_unregister
+ *
+ * This function used to unregister a client  from the HIF driver.
+ *
+ */
+static void pfe_hif_client_unregister(struct pfe_hif *hif, u32 client_id)
+{
+	printk(KERN_INFO "%s\n", __func__);
+
+	/* Mark client as no longer available (which prevents further packet receive for this client) */
+	spin_lock_bh(&hif->tx_lock);
+
+	if (!test_bit(client_id, &hif->shm->gClient_status[0])) {
+		printk(KERN_ERR "%s: client %d not registered\n", __func__, client_id);
+
+		spin_unlock_bh(&hif->tx_lock);
+		return;
+	}
+
+	clear_bit(client_id, &hif->shm->gClient_status[0]);
+
+	spin_unlock_bh(&hif->tx_lock);
+}
+
+/* client_put_rxpacket-
+ * This functions puts the Rx pkt  in the given client Rx queue.
+ * It actually swap the Rx pkt in the client Rx descriptor buffer
+ * and returns the free buffer from it.
+ *
+ * If the funtion returns NULL means client Rx queue is full and
+ * packet couldn't send to client queue.
+ */
+static void *client_put_rxpacket(struct hif_rx_queue *queue, void *pkt, u32 len, u32 flags, u32 client_ctrl, u32 *rem_len)
+{
+	void *free_pkt = NULL;
+	struct rx_queue_desc *desc = queue->base + queue->write_idx;
+
+	if (desc->ctrl & CL_DESC_OWN) {
+#if defined(CONFIG_PLATFORM_PCI)
+		memcpy(desc->data, pkt, len);
+		free_pkt = PFE_HOST_TO_PCI(pkt);
+		smp_wmb();
+		desc->ctrl = CL_DESC_BUF_LEN(len) | flags;
+		inc_cl_idx(queue->write_idx);
+#else
+		//TODO: move allocations after Rx loop to improve instruction cache locality
+		if (page_mode) {
+			int rem_page_size = PAGE_SIZE -  PRESENT_OFST_IN_PAGE(pkt);
+			int cur_pkt_size = ROUND_MIN_RX_SIZE(len +  pfe_pkt_headroom);
+			*rem_len = (rem_page_size - cur_pkt_size);
+			//printk("%p rem_len %d cur_len %d buf_len %d\n", pkt, rem_page_size, cur_pkt_size, *rem_len);
+			if (*rem_len)
+			{
+				free_pkt = pkt + cur_pkt_size;
+				get_page(virt_to_page(free_pkt));
+			} else {
+				free_pkt = (void *)__get_free_page(GFP_ATOMIC | GFP_DMA_PFE);
+				*rem_len = pfe_pkt_size;
+			}
+		} else {
+			free_pkt = kmalloc(PFE_BUF_SIZE, GFP_ATOMIC | GFP_DMA_PFE);
+			*rem_len = PFE_BUF_SIZE - pfe_pkt_headroom;
+		}
+
+		if (free_pkt) {
+			desc->data = pkt;
+			desc->client_ctrl = client_ctrl;
+			smp_wmb();
+			desc->ctrl = CL_DESC_BUF_LEN(len) | flags;
+			inc_cl_idx(queue->write_idx);
+			free_pkt += pfe_pkt_headroom;
+		}
+#endif
+	}
+
+	return free_pkt;
+}
+
+
+/* pfe_hif_rx_process-
+ * This function does pfe hif rx queue processing.
+ * Dequeue packet from Rx queue and send it to corresponding client queue 
+ */
+static int pfe_hif_rx_process(struct pfe_hif *hif, int budget)
+{
+	struct hif_desc	*desc;
+	struct hif_hdr *pkt_hdr;
+	struct __hif_hdr hif_hdr;
+	void *free_buf;
+	int rtc, len, rx_processed = 0;
+	struct __hif_desc local_desc;
+	int flags;
+	unsigned int desc_p;
+	unsigned int buf_size = 0;
+
+	spin_lock_bh(&hif->lock);
+
+	rtc = hif->RxtocleanIndex;
+
+	while (rx_processed < budget)
+	{
+		/*TODO may need to implement rx process budget */
+		desc = hif->RxBase + rtc;
+
+		__memcpy12(&local_desc, desc);
+
+		/* ACK pending Rx interrupt */
+		if (local_desc.ctrl & BD_CTRL_DESC_EN) {
+			writel(HIF_INT_MASK, HIF_INT_SRC);
+
+			if(rx_processed == 0)
+			{
+				if(napi_first_batch == 1)
+				{
+					desc_p = hif->descr_baseaddr_p + ((unsigned long int)(desc) - (unsigned long int)hif->descr_baseaddr_v);
+#if defined(CONFIG_PLATFORM_C2000)
+					outer_inv_range(desc_p, (desc_p + 16));
+#endif
+					napi_first_batch = 0;
+				}
+			}
+
+			__memcpy12(&local_desc, desc);
+
+			if (local_desc.ctrl & BD_CTRL_DESC_EN)
+				break;
+		}
+
+		napi_first_batch = 0;
+
+#ifdef HIF_NAPI_STATS
+		hif->napi_counters[NAPI_DESC_COUNT]++;
+#endif
+		len = BD_BUF_LEN(local_desc.ctrl);
+#if defined(CONFIG_PLATFORM_PCI)
+		pkt_hdr = &hif_hdr;
+		memcpy(pkt_hdr, (void *)PFE_PCI_TO_HOST(local_desc.data), sizeof(struct hif_hdr));
+#else
+		//dma_unmap_single(hif->dev, DDR_PFE_TO_PHYS(local_desc.data),  hif->rx_buf_len[rtc], DMA_FROM_DEVICE);
+		DMA_UNMAP_SINGLE(hif->dev, DDR_PFE_TO_PHYS(local_desc.data),  hif->rx_buf_len[rtc], DMA_FROM_DEVICE);
+
+		pkt_hdr = (struct hif_hdr *)hif->rx_buf_addr[rtc];
+
+		/* Track last HIF header received */
+		if (!hif->started) {
+			hif->started = 1;
+
+			__memcpy8(&hif_hdr, pkt_hdr);
+
+			hif->qno = hif_hdr.hdr.qNo;
+			hif->client_id = hif_hdr.hdr.client_id;
+			hif->client_ctrl = (hif_hdr.hdr.client_ctrl1 << 16) | hif_hdr.hdr.client_ctrl;
+			flags = CL_DESC_FIRST;
+
+//			printk(KERN_INFO "start of packet: id %d, q %d, len %d, flags %x %x\n", hif->client_id, hif->qno, len, local_desc.ctrl, hif->client_ctrl);
+		}
+		else {
+//			printk(KERN_INFO "continuation: id %d, q %d, len %d, flags %x\n", hif->client_id, hif->qno, len, local_desc.ctrl);
+			flags = 0;
+		}
+
+		if (local_desc.ctrl & BD_CTRL_LIFM)
+			flags |= CL_DESC_LAST;
+#endif
+		/* Check for valid client id and still registered */
+		if ((hif->client_id >= HIF_CLIENTS_MAX) || !(test_bit(hif->client_id, &hif->shm->gClient_status[0]))) {
+			if (printk_ratelimit())
+				printk(KERN_ERR "%s: packet with invalid client id %d qNo %d\n", __func__, hif->client_id, hif->qno);
+
+#if defined(CONFIG_PLATFORM_PCI)
+			free_buf = local_desc.data;
+#else
+			free_buf = pkt_hdr;
+#endif
+			goto pkt_drop;
+		}
+
+		/* Check to valid queue number */
+		if (hif->client[hif->client_id].rx_qn <= hif->qno) {
+			printk(KERN_INFO "%s: packet with invalid queue: %d\n", __func__, hif->qno);
+			hif->qno = 0;
+		}
+
+#if defined(CONFIG_PLATFORM_PCI)
+		free_buf = client_put_rxpacket(&hif->client[hif->client_id].rx_q[hif->qno],
+				(void *)PFE_PCI_TO_HOST(desc->data), len, flags, hif->client_ctrl, &buf_zize);
+#else
+		free_buf = client_put_rxpacket(&hif->client[hif->client_id].rx_q[hif->qno],
+				(void *)pkt_hdr, len, flags, hif->client_ctrl, &buf_size);
+#endif
+
+		hif_lib_indicate_client(hif->client_id, EVENT_RX_PKT_IND, hif->qno);
+
+		if (unlikely(!free_buf)) {
+#ifdef HIF_NAPI_STATS
+			hif->napi_counters[NAPI_CLIENT_FULL_COUNT]++;
+#endif
+			/* If we want to keep in polling mode to retry later, we need to tell napi that we consumed
+			the full budget or we will hit a livelock scenario. The core code keeps this napi instance
+			at the head of the list and none of the other instances get to run */
+			rx_processed = budget;
+
+			if (flags & CL_DESC_FIRST)
+				hif->started = 0;
+
+			break;
+		}
+
+	pkt_drop:
+#if defined(CONFIG_PLATFORM_PCI)
+		desc->data = (u32)free_buf;
+#else
+		/*Fill free buffer in the descriptor */
+		hif->rx_buf_addr[rtc] = free_buf;
+		hif->rx_buf_len[rtc] = min(pfe_pkt_size, buf_size);
+		desc->data = DDR_PHYS_TO_PFE((u32)DMA_MAP_SINGLE(hif->dev, free_buf, hif->rx_buf_len[rtc], DMA_FROM_DEVICE));
+		//printk("#%p %p %d\n", desc->data, hif->rx_buf_addr[rtc], hif->rx_buf_len[rtc]);
+#endif
+		wmb();
+		desc->ctrl = BD_CTRL_PKT_INT_EN | BD_CTRL_LIFM | BD_CTRL_DIR |
+			BD_CTRL_DESC_EN | BD_BUF_LEN(hif->rx_buf_len[rtc]);
+
+		inc_hif_rxidx(rtc);
+
+		if (local_desc.ctrl & BD_CTRL_LIFM) {
+			if (!(hif->client_ctrl & HIF_CTRL_RX_CONTINUED)) {
+				rx_processed++;
+
+#ifdef HIF_NAPI_STATS
+				hif->napi_counters[NAPI_PACKET_COUNT]++;
+#endif
+			}
+			hif->started = 0;
+		}
+	}
+
+	hif->RxtocleanIndex = rtc;
+	spin_unlock_bh(&hif->lock);
+
+	/* we made some progress, re-start rx dma in case it stopped */
+	hif_rx_dma_start();
+
+	return rx_processed;
+}
+
+
+/* client_ack_txpacket-
+ * This function ack the Tx packet in the give client Tx queue by resetting
+ * ownership bit in the descriptor.
+ */
+static int client_ack_txpacket(struct pfe_hif *hif, unsigned int client_id, unsigned int q_no)
+{
+	struct hif_tx_queue *queue = &hif->client[client_id].tx_q[q_no];
+	struct tx_queue_desc *desc = queue->base + queue->ack_idx;
+
+	if (desc->ctrl & CL_DESC_OWN) {
+		/*TODO Do we need to match the pkt address also? */
+		desc->ctrl &= ~CL_DESC_OWN;
+		inc_cl_idx(queue->ack_idx);
+
+		return 0;
+	}
+	else {
+		/*This should not happen */
+		printk(KERN_ERR "%s: %d %d %d %d %d %p %d\n", __func__, hif->Txtosend, hif->Txtoclean, hif->TxAvail, client_id, q_no, queue, queue->ack_idx);
+		BUG();
+		return 1;
+	}
+}
+
+void __hif_tx_done_process(struct pfe_hif *hif, int count)
+{
+	struct hif_desc *desc;
+	struct hif_desc_sw *desc_sw;
+	int ttc, tx_avl;
+
+	ttc = hif->Txtoclean;
+	tx_avl = hif->TxAvail;
+
+	while ((tx_avl < hif->TxRingSize) && count--) {
+		desc = hif->TxBase + ttc;
+
+		if (desc->ctrl & BD_CTRL_DESC_EN)
+			break;
+
+		desc_sw = &hif->tx_sw_queue[ttc];
+
+		if (desc_sw->data) {
+#if !defined(CONFIG_PLATFORM_PCI)
+			//dmap_unmap_single(hif->dev, desc_sw->data, desc_sw->len, DMA_TO_DEVICE);
+			DMA_UNMAP_SINGLE(hif->dev, desc_sw->data, desc_sw->len, DMA_TO_DEVICE);
+#endif
+		}
+		client_ack_txpacket(hif, desc_sw->client_id, desc_sw->q_no);
+
+		inc_hif_txidx(ttc);
+		tx_avl++;
+	}
+
+	hif->Txtoclean = ttc;
+	hif->TxAvail = tx_avl;
+}
+
+
+/* __hif_xmit_pkt -
+ * This function puts one packet in the HIF Tx queue
+ */
+void __hif_xmit_pkt(struct pfe_hif *hif, unsigned int client_id, unsigned int q_no, void *data, u32 len, unsigned int flags)
+{
+	struct hif_desc	*desc;
+	struct hif_desc_sw *desc_sw;
+
+#if defined(CONFIG_PLATFORM_EMULATION)
+	{
+		struct hif_queue *queue = &hif->client[client_id].rx_q[0];
+		struct queue_desc *qdesc = queue->base + queue->write_idx;
+		void *buf;
+
+		printk("%s: packet loop backed client_id:%d qno:%d data : %p len:%d\n", __func__, client_id, q_no, data, len);
+#if 1
+		if (qdesc->ctrl & CL_DESC_OWN) {
+			buf = (void *)qdesc->data;
+			memcpy(buf, data, len);
+			wmb();
+			qdesc->ctrl = CL_DESC_BUF_LEN(len);
+			inc_cl_idx(queue->write_idx);
+			printk("%s: packet loop backed..\n", __func__);
+			hif_lib_indicate_client(client_id, EVENT_RX_PKT_IND, q_no);
+			client_ack_txpacket(&hif->client[client_id].tx_q[q_no]);
+		}
+#endif
+	}
+
+#else
+	desc = hif->TxBase + hif->Txtosend;
+	desc_sw = &hif->tx_sw_queue[hif->Txtosend];
+
+	desc_sw->len = len;
+	desc_sw->client_id = client_id;
+	desc_sw->q_no = q_no;
+	desc_sw->flags = flags;
+
+#if !defined(CONFIG_PLATFORM_PCI)
+	if (flags & HIF_DONT_DMA_MAP) {
+		desc_sw->data = 0;
+		desc->data = (u32)DDR_PHYS_TO_PFE(data);
+	} else {
+		desc_sw->data = DMA_MAP_SINGLE(hif->dev, data, len, DMA_TO_DEVICE);
+		desc->data = (u32)DDR_PHYS_TO_PFE(desc_sw->data);
+	}
+#else
+#define ALIGN32(x)	((x) & ~0x3)
+	memcpy(PFE_PCI_TO_HOST(desc->data), data, ALIGN32(len+0x3));
+#endif
+
+	inc_hif_txidx(hif->Txtosend);
+	hif->TxAvail--;
+
+	/* For TSO we skip actual TX until the last descriptor */
+	/* This reduce the number of required wmb() */
+	if ((flags & HIF_TSO) && (!((flags & HIF_DATA_VALID) && (flags & HIF_LAST_BUFFER))))
+		goto skip_tx;
+
+	wmb();
+
+	do {
+		desc_sw = &hif->tx_sw_queue[hif->Txtoflush];
+		desc = hif->TxBase + hif->Txtoflush;
+
+		if (desc_sw->flags & HIF_LAST_BUFFER) {
+			if ((desc_sw->client_id < PFE_CL_VWD0) || (desc_sw->client_id > (PFE_CL_VWD0 + MAX_VAP_SUPPORT)))
+				desc->ctrl = BD_CTRL_LIFM | BD_CTRL_BRFETCH_DISABLE |
+						BD_CTRL_RTFETCH_DISABLE | BD_CTRL_PARSE_DISABLE |
+						BD_CTRL_DESC_EN | BD_BUF_LEN(desc_sw->len);
+			else {
+
+				desc->ctrl = BD_CTRL_LIFM | BD_CTRL_DESC_EN | BD_BUF_LEN(desc_sw->len);
+			}
+		}
+		else
+			desc->ctrl = BD_CTRL_DESC_EN | BD_BUF_LEN(desc_sw->len);
+
+		inc_hif_txidx(hif->Txtoflush);
+	}
+	while (hif->Txtoflush != hif->Txtosend);
+
+skip_tx:
+	return;
+
+#endif
+}
+
+
+int hif_xmit_pkt(struct pfe_hif *hif, unsigned int client_id, unsigned int q_no, void *data, unsigned int len)
+{
+	int rc = 0;
+
+	spin_lock_bh(&hif->tx_lock);
+
+	if (!hif->TxAvail)
+		rc = 1;
+	else {
+		__hif_xmit_pkt(hif, client_id, q_no, data, len, HIF_FIRST_BUFFER | HIF_LAST_BUFFER);
+		hif_tx_dma_start();
+	}
+	if (hif->TxAvail < (hif->TxRingSize >> 1))
+		__hif_tx_done_process(hif, TX_FREE_MAX_COUNT);
+
+	spin_unlock_bh(&hif->tx_lock);
+
+	return rc;
+}
+
+/* hif_isr-
+ * This ISR routine processes Rx/Tx done interrupts from the HIF hardware block
+ */
+static irqreturn_t hif_isr(int irq, void *dev_id)
+{
+	struct pfe_hif *hif = (struct pfe_hif *) dev_id;
+	int int_status;
+
+	/*Read hif interrupt source register */
+	int_status = readl_relaxed(HIF_INT_SRC);
+
+	if ((int_status & HIF_INT) == 0)
+		return(IRQ_NONE);
+
+	int_status &= ~(HIF_INT);
+
+	if (int_status & HIF_RXPKT_INT) {
+		int_status &= ~(HIF_RXPKT_INT);
+
+		/* Disable interrupts */
+		writel_relaxed(0, HIF_INT_ENABLE);
+		
+		napi_first_batch = 1;
+		
+		if (napi_schedule_prep(&hif->napi))
+		{
+#ifdef HIF_NAPI_STATS
+			hif->napi_counters[NAPI_SCHED_COUNT]++;
+#endif
+			__napi_schedule(&hif->napi);
+		}
+	}
+
+	if (int_status) {
+		printk(KERN_INFO "%s : Invalid interrupt : %d\n", __func__, int_status);
+		writel(int_status, HIF_INT_SRC);
+	}
+
+	return IRQ_HANDLED;
+}
+
+
+void hif_process_client_req(struct pfe_hif *hif, int req, int data1, int data2)
+{
+	unsigned int client_id = data1;
+
+	if (client_id >= HIF_CLIENTS_MAX)
+	{
+		printk(KERN_ERR "%s: client id %d out of bounds\n", __func__, client_id);
+		return;
+	}
+
+	switch (req) {
+		case REQUEST_CL_REGISTER:
+			/* Request for register a client */
+			printk(KERN_INFO "%s: register client_id %d\n", __func__, client_id);
+			pfe_hif_client_register(hif, client_id, (struct hif_client_shm *)&hif->shm->client[client_id]);
+			break;
+
+		case REQUEST_CL_UNREGISTER:
+			printk(KERN_INFO "%s: unregister client_id %d\n", __func__, client_id);
+
+			/* Request for unregister a client */
+			pfe_hif_client_unregister(hif, client_id);
+
+			break;
+
+		default:
+			printk(KERN_ERR "%s: unsupported request %d\n", __func__, req);
+			break;
+	}
+
+	/*TODO check for TMU queue resume request */
+
+	/*Process client Tx queues
+	 * Currently we don't have checking for tx pending*/
+}
+
+/** pfe_hif_rx_poll
+ *  This function is NAPI poll function to process HIF Rx queue.
+ */
+static int pfe_hif_rx_poll(struct napi_struct *napi, int budget)
+{
+	struct pfe_hif *hif = container_of(napi, struct pfe_hif, napi);
+	int work_done;
+
+#ifdef HIF_NAPI_STATS
+	hif->napi_counters[NAPI_POLL_COUNT]++;
+#endif
+
+	work_done = pfe_hif_rx_process(hif, budget);
+
+	if (work_done < budget)
+	{
+		napi_complete(napi);
+		writel_relaxed(HIF_INT_MASK, HIF_INT_ENABLE);
+	}
+#ifdef HIF_NAPI_STATS
+	else
+		hif->napi_counters[NAPI_FULL_BUDGET_COUNT]++;
+#endif
+
+	return work_done;
+}
+
+/* pfe_hif_init
+ * This function initializes the baseaddresses and irq, etc.
+ */
+int pfe_hif_init(struct pfe *pfe)
+{
+	struct pfe_hif *hif = &pfe->hif;
+	int err;
+
+	printk(KERN_INFO "%s\n", __func__);
+
+	hif->dev = pfe->dev;
+	hif->irq = pfe->hif_irq;
+
+	if ((err = pfe_hif_alloc_descr(hif))) {
+		goto err0;
+	}
+
+	if (pfe_hif_init_buffers(hif)) { 
+		printk(KERN_ERR "%s: Could not initialize buffer descriptors\n", __func__);
+		err = -ENOMEM;
+		goto err1;
+	}
+
+	/* Initilize NAPI for Rx processing */
+	init_dummy_netdev(&hif->dummy_dev);
+	netif_napi_add(&hif->dummy_dev, &hif->napi, pfe_hif_rx_poll, HIF_RX_POLL_WEIGHT);
+	napi_enable(&hif->napi);
+
+	spin_lock_init(&hif->tx_lock);
+	spin_lock_init(&hif->lock);
+
+	hif_init();
+	hif_rx_enable();
+	hif_tx_enable();
+
+	/* Disable tx done interrupt */
+	writel(HIF_INT_MASK, HIF_INT_ENABLE);
+
+	gpi_enable(HGPI_BASE_ADDR);
+
+#ifdef __KERNEL__
+	err = request_irq(hif->irq, hif_isr, 0, "pfe_hif", hif);
+	if (err) {
+		printk(KERN_ERR "%s: failed to get the hif IRQ = %d\n",  __func__, hif->irq);
+		goto err1;
+	}
+#else
+	/*TODO register interrupts */
+#endif
+
+	return 0;
+err1:
+	pfe_hif_free_descr(hif);
+err0:
+	return err;
+}
+
+/* pfe_hif_exit-
+ */
+void pfe_hif_exit(struct pfe *pfe)
+{
+	struct pfe_hif *hif = &pfe->hif;
+
+	printk(KERN_INFO "%s\n", __func__);
+
+	spin_lock_bh(&hif->lock);
+	hif->shm->gClient_status[0] = 0;
+	hif->shm->gClient_status[1] = 0; /* Make sure all clients are disabled */
+
+	spin_unlock_bh(&hif->lock);
+
+	/*Disable Rx/Tx */
+	gpi_disable(HGPI_BASE_ADDR);
+	hif_rx_disable();
+	hif_tx_disable();
+
+	napi_disable(&hif->napi);
+	netif_napi_del(&hif->napi);
+
+#ifdef __KERNEL__
+	free_irq(hif->irq, hif);
+#endif
+	pfe_hif_release_buffers(hif);
+	pfe_hif_free_descr(hif);
+}
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/pfe_hif.h
@@ -0,0 +1,322 @@
+/*
+ *
+ *  Copyright (C) 2007 Freescale Semiconductor, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+
+#ifndef _PFE_HIF_H_
+#define _PFE_HIF_H_
+
+#include <linux/netdevice.h>
+
+#define HIF_NAPI_STATS
+
+#define HIF_CLIENT_QUEUES_MAX	16
+#define HIF_RX_POLL_WEIGHT	64
+
+#define HIF_RX_PKT_MIN_SIZE 0x800 /* 2KB */
+#define HIF_RX_PKT_MIN_SIZE_MASK ~(HIF_RX_PKT_MIN_SIZE - 1)
+#define ROUND_MIN_RX_SIZE(_sz) ((_sz + (HIF_RX_PKT_MIN_SIZE - 1)) & HIF_RX_PKT_MIN_SIZE_MASK)
+#define PRESENT_OFST_IN_PAGE(_buf) (((unsigned long int)_buf & (PAGE_SIZE - 1)) & HIF_RX_PKT_MIN_SIZE_MASK)
+
+enum {
+	NAPI_SCHED_COUNT = 0,
+	NAPI_POLL_COUNT,
+	NAPI_PACKET_COUNT,
+	NAPI_DESC_COUNT,
+	NAPI_FULL_BUDGET_COUNT,
+	NAPI_CLIENT_FULL_COUNT,
+	NAPI_MAX_COUNT
+};
+
+
+/* XXX  HIF_TX_DESC_NT value should be always greter than 4,
+ *      Otherwise HIF_TX_POLL_MARK will become zero.
+ */
+#if defined(CONFIG_PLATFORM_PCI)
+#define HIF_RX_DESC_NT		4
+#define HIF_TX_DESC_NT		4
+#else
+#if defined(CONFIG_COMCERTO_64K_PAGES) 
+#define HIF_RX_DESC_NT		64
+#else
+#define HIF_RX_DESC_NT		256
+#endif
+#define HIF_TX_DESC_NT		2048
+#endif
+
+#define HIF_FIRST_BUFFER		(1 << 0)
+#define HIF_LAST_BUFFER		(1 << 1)
+#define HIF_DONT_DMA_MAP		(1 << 2) //TODO merge it with TSO
+#define HIF_DATA_VALID			(1 << 3)
+#define HIF_TSO			(1 << 4)
+
+#define MAX_VAP_SUPPORT 3
+#define MAX_WIFI_VAPS MAX_VAP_SUPPORT
+
+enum {
+	PFE_CL_GEM0 = 0,
+	PFE_CL_GEM1,
+	PFE_CL_GEM2,
+	PFE_CL_VWD0,
+	PFE_CL_VWD_LAST = PFE_CL_VWD0 + MAX_VAP_SUPPORT,
+	PFE_CL_PCAP0,
+	HIF_CLIENTS_MAX
+};
+
+/*structure to store client queue info */
+struct hif_rx_queue {
+	struct rx_queue_desc *base;
+	u32	size;
+	u32	write_idx;
+};
+
+struct hif_tx_queue {
+	struct tx_queue_desc *base;
+	u32	size;
+	u32	ack_idx;
+};
+
+/*Structure to store the client info */
+struct hif_client {
+	int	rx_qn;
+	struct hif_rx_queue 	rx_q[HIF_CLIENT_QUEUES_MAX];
+	int	tx_qn;
+	struct hif_tx_queue	tx_q[HIF_CLIENT_QUEUES_MAX];
+};
+
+/*HIF hardware buffer descriptor */
+struct hif_desc {
+	volatile u32 ctrl;
+	volatile u32 status;
+	volatile u32 data;
+	volatile u32 next;
+};
+
+struct __hif_desc {
+	u32 ctrl;
+	u32 status;
+	u32 data;
+};
+
+struct hif_desc_sw {
+	dma_addr_t data;
+	u16 len;
+	u8 client_id;
+	u8 q_no;
+	u16 flags;
+};
+
+struct hif_hdr {
+	u8 client_id;
+	u8 qNo;
+	u16 client_ctrl;
+	u16 client_ctrl1;
+};
+
+struct __hif_hdr {
+	union {
+		struct hif_hdr hdr;
+		u32 word[2];
+	};
+};
+
+struct hif_lro_hdr {
+	u16 data_offset;
+	u16 mss;
+};
+
+struct hif_ipsec_hdr {
+	u16	sa_handle[2];
+}__attribute__((packed));
+
+#define MAX_TSO_BUF_DESCS 5
+struct hif_tso_buf_desc {
+	u32	addr;
+	u32	ctrl;
+#define TSO_CTRL_LAST_BUFFER (1 << 31)
+};
+
+struct hif_tso_hdr {
+	struct	hif_hdr pkt_hdr;
+	u16	ip_off;
+	u16	ip_id;
+	u16	ip_len;
+	u16	tcp_off;
+	u32	tcp_seq;
+} __attribute__((packed));
+
+struct hif_tso_hdr_nocpy {
+	struct	hif_tso_hdr tso_hdr;
+	struct hif_tso_buf_desc bdesc[MAX_TSO_BUF_DESCS];
+} __attribute__((packed));
+
+struct hif_pcap_hdr {
+	u8	ifindex;
+	u8 	unused;
+	u16	seqno;
+	u32	timestamp;
+}__attribute__((packed));
+
+/*  HIF_CTRL_TX... defines */
+#define HIF_CTRL_TX_TSO_NOCPY		(1 << 8)
+#define HIF_CTRL_TX_IPSEC_OUT		(1 << 7)
+#define HIF_CTRL_TX_OWN_MAC		(1 << 6)
+#define HIF_CTRL_TX_TSO_END		(1 << 5)
+#define HIF_CTRL_TX_TSO6		(1 << 4)
+#define HIF_CTRL_TX_TSO			(1 << 3)
+#define HIF_CTRL_TX_CHECKSUM		(1 << 2)
+#define HIF_CTRL_TX_CSUM_VALIDATE	(1 << 1)
+#define HIF_CTRL_TX_WIFI		(1 << 0)
+
+/*  HIF_CTRL_RX... defines */
+#define HIF_CTRL_RX_OFFSET_OFST		(24)
+#define HIF_CTRL_RX_PE_ID_OFST		(16)
+#define HIF_CTRL_RX_IPSEC_IN		(1 << 4)
+#define HIF_CTRL_RX_WIFI_EXPT		(1 << 3)
+#define HIF_CTRL_RX_CHECKSUMMED		(1 << 2)
+#define HIF_CTRL_RX_CONTINUED		(1 << 1)
+#define HIF_CTRL_RX_WIFI_HEADROOM	(1 << 0)
+
+#define HIF_CTRL_VAPID_OFST		(8)
+
+struct pfe_hif {
+	/* To store registered clients in hif layer */
+	struct hif_client client[HIF_CLIENTS_MAX];
+	struct hif_shm *shm;
+	int	irq;
+
+	void	*descr_baseaddr_v;
+	unsigned long	descr_baseaddr_p;
+
+	struct hif_desc *RxBase;
+	u32	RxRingSize;
+	u32	RxtocleanIndex;
+	void	*rx_buf_addr[HIF_RX_DESC_NT];
+	int	rx_buf_len[HIF_RX_DESC_NT];
+	unsigned int qno;
+	unsigned int client_id;
+	unsigned int client_ctrl;
+	unsigned int started;
+
+	struct hif_desc *TxBase;
+	u32	TxRingSize;
+	u32	Txtosend;
+	u32	Txtoclean;
+	u32	TxAvail;
+	u32	Txtoflush;
+	struct hif_desc_sw tx_sw_queue[HIF_TX_DESC_NT];
+	struct hif_tso_hdr_nocpy *tso_hdr_v;
+	dma_addr_t tso_hdr_p;
+
+	spinlock_t tx_lock;
+	spinlock_t lock;
+	struct net_device	dummy_dev;
+	struct napi_struct	napi;
+	struct device *dev;
+
+#ifdef CONFIG_HOTPLUG_CPU
+	struct notifier_block   cpu_notify;
+#endif
+
+#ifdef HIF_NAPI_STATS
+	unsigned int napi_counters[NAPI_MAX_COUNT];
+#endif
+};
+
+void __hif_xmit_pkt(struct pfe_hif *hif, unsigned int client_id, unsigned int q_no, void *data, u32 len, unsigned int flags);
+int hif_xmit_pkt(struct pfe_hif *hif, unsigned int client_id, unsigned int q_no, void *data, unsigned int len);
+void __hif_tx_done_process(struct pfe_hif *hif, int count);
+void hif_process_client_req(struct pfe_hif *hif, int req, int data1, int data2);
+int pfe_hif_init(struct pfe *pfe);
+void pfe_hif_exit(struct pfe *pfe);
+
+static inline void hif_tx_done_process(struct pfe_hif *hif, int count)
+{
+	spin_lock_bh(&hif->tx_lock);
+	__hif_tx_done_process(hif, count);
+	spin_unlock_bh(&hif->tx_lock);
+}
+
+static inline void hif_tx_lock(struct pfe_hif *hif)
+{
+	spin_lock_bh(&hif->tx_lock);
+}
+
+static inline void hif_tx_unlock(struct pfe_hif *hif)
+{
+	spin_unlock_bh(&hif->tx_lock);
+}
+
+static inline int __hif_tx_avail(struct pfe_hif *hif)
+{
+	return hif->TxAvail;
+}
+
+#if defined(CONFIG_PLATFORM_C2000)
+static inline void __memcpy8(void *dst, void *src)
+{
+	asm volatile (	"ldm %1, {r9, r10}\n\t"
+			"stm %0, {r9, r10}\n\t"
+			:
+			: "r" (dst), "r" (src)
+			: "r9", "r10", "memory"
+		);
+}
+
+static inline void __memcpy12(void *dst, void *src)
+{
+	asm volatile (	"ldm %1, {r8, r9, r10}\n\t"
+			"stm %0, {r8, r9, r10}\n\t"
+			:
+			: "r" (dst), "r" (src)
+			: "r8", "r9", "r10", "memory"
+		);
+}
+
+static inline void __memcpy16(void *dst, void *src)
+{
+	asm volatile (	"ldm %1, {r7, r8, r9, r10}\n\t"
+			"stm %0, {r7, r8, r9, r10}\n\t"
+			:
+			: "r"(dst), "r"(src)
+			: "r7", "r8", "r9", "r10", "memory"
+		);
+}
+
+#define HIF_MEMCPY_BURSTSIZE 32                 /*__memcpy copy 32byte in a burst*/
+static inline void __memcpy(void *dst, void *src, unsigned int len)
+{
+	void *end = src + len;
+
+	dst = (void *)((unsigned long)dst & ~0x3);
+	src = (void *)((unsigned long)src & ~0x3);
+
+	while (src < end) {
+		asm volatile (	"ldm %1!, {r3, r4, r5, r6, r7, r8, r9, r10}\n\t"
+				"stm %0!, {r3, r4, r5, r6, r7, r8, r9, r10}\n\t"
+				: "+r"(dst), "+r"(src)
+				:
+				: "r3", "r4", "r5", "r6", "r7", "r8", "r9", "r10", "memory"
+			);
+	}
+}
+#else
+#define __memcpy8(dst, src)		memcpy(dst, src, 8)
+#define __memcpy12(dst, src)		memcpy(dst, src, 12)
+#define __memcpy(dst, src, len)		memcpy(dst, src, len)
+#endif
+#endif /* _PFE_HIF_H_ */
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/pfe_hif_lib.c
@@ -0,0 +1,658 @@
+/*
+ *
+ *  Copyright (C) 2007 Freescale Semiconductor, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+
+#include <linux/version.h>
+#if LINUX_VERSION_CODE < KERNEL_VERSION(3,10,0)
+#include <asm/system.h>
+#endif
+#include <linux/kernel.h>
+#include <linux/slab.h>
+#include <linux/interrupt.h>
+#include <linux/workqueue.h>
+#include <linux/dma-mapping.h>
+#include <linux/dmapool.h>
+#include <linux/sched.h>
+#include <linux/skbuff.h>
+#include <linux/moduleparam.h>
+#include <linux/cpu.h>
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,10,0)
+//#include <asm/system_info.h>
+#endif
+
+#include "pfe_mod.h"
+#include "pfe_hif.h"
+#include "pfe_hif_lib.h"
+#include "pfe_ctrl_hal.h"
+
+
+unsigned int lro_mode = 0;
+unsigned int page_mode = 0;
+unsigned int tx_qos = 0;
+unsigned int pfe_pkt_size;
+unsigned int pfe_pkt_headroom;
+unsigned int emac_txq_cnt;
+
+/** @pfe_hal_lib.c.
+ * Common functions used by HIF client drivers
+ */
+
+/*HIF shared memory Global variable */
+struct hif_shm ghif_shm;
+
+/* TMU tx transmitted packets counter, 1 per TMU */
+unsigned int TMU_DMEM_SH(tx_trans)[EMAC_TXQ_CNT];
+
+/* Cleanup the HIF shared memory, release HIF rx_buffer_pool.
+ * This function should be called after pfe_hif_exit
+ *
+ * @param[in] hif_shm		Shared memory address location in DDR
+ */
+static void pfe_hif_shm_clean(struct hif_shm *hif_shm)
+{
+	int i;
+	void *pkt;
+
+	for (i = 0; i < hif_shm->rx_buf_pool_cnt; i++) {
+		pkt = hif_shm->rx_buf_pool[i];
+		if (pkt) {
+			hif_shm->rx_buf_pool[i] = NULL;
+			pkt -= pfe_pkt_headroom;
+
+			if (page_mode) {
+				put_page(virt_to_page(pkt));
+			} else
+				kfree(pkt);
+		}
+	}
+}
+
+/* Initialize shared memory used between HIF driver and clients, 
+ * allocate rx_buffer_pool required for HIF Rx descriptors.
+ * This function should be called before initializing HIF driver.
+ *
+ * @param[in] hif_shm		Shared memory address location in DDR
+ * @rerurn			0 - on succes, <0 on fail to initialize
+ */
+static int pfe_hif_shm_init(struct hif_shm *hif_shm)
+{
+	int i;
+	void *pkt;
+
+	memset(hif_shm, 0, sizeof(struct hif_shm));
+	hif_shm->rx_buf_pool_cnt = HIF_RX_DESC_NT;
+
+	for (i = 0; i < hif_shm->rx_buf_pool_cnt; i++) {
+		if (page_mode) {
+			pkt = (void *)__get_free_page(GFP_KERNEL | GFP_DMA_PFE);
+		} else
+			pkt = kmalloc(PFE_BUF_SIZE, GFP_KERNEL | GFP_DMA_PFE);
+
+		if (pkt)
+			hif_shm->rx_buf_pool[i] = pkt + pfe_pkt_headroom;
+		else
+			goto err0;
+	}
+
+	return 0;
+
+err0:
+	printk(KERN_ERR "%s Low memory\n", __func__);
+	pfe_hif_shm_clean(hif_shm);
+	return -ENOMEM;
+}
+
+/*This function sends indication to HIF driver 
+ *
+ * @param[in] hif	hif context
+ **/
+static void hif_lib_indicate_hif(struct pfe_hif *hif, int req, int data1, int data2)
+{
+	//TODO : If we separate HIF and HIF LIB, then send req and data through shared memory.
+
+	hif_process_client_req(hif, req, data1, data2);
+}
+
+void hif_lib_indicate_client(int client_id, int event_type, int qno)
+{
+	struct hif_client_s *client = pfe->hif_client[client_id];
+
+	/*
+	 * TODO : Right now, all events are queue number based. So we are masking events per queue 
+	 *        basis. Later if we add any events those do not depend on queue number, then we may
+	 *	  may need may need to add masking per event.
+	 */
+	if (!client || (event_type >= HIF_EVENT_MAX) || (qno >= HIF_CLIENT_QUEUES_MAX) )
+		return;
+
+	if (!test_and_set_bit(qno, &client->queue_mask[event_type])) {
+		client->event_handler(client->priv, event_type, qno);
+	}
+
+}
+
+
+/*This function releases Rx queue descriptors memory and pre-filled buffers
+ *
+ * @param[in] client	hif_client context
+ */
+static void hif_lib_client_release_rx_buffers(struct hif_client_s *client)
+{
+	struct rx_queue_desc *desc;
+	int qno, ii;
+	void *buf;
+
+	for (qno = 0; qno < client->rx_qn; qno++) {
+		desc = client->rx_q[qno].base;
+
+		for (ii = 0; ii < client->rx_q[qno].size; ii++) {
+			buf = (void *)desc->data;
+			if (buf) {
+				buf -= pfe_pkt_headroom;
+
+				if (page_mode)
+					free_page((unsigned long)buf);
+				else
+					kfree(buf);
+
+				desc->ctrl = 0;
+			}
+
+			desc++;
+		}
+	}
+
+	kfree(client->rx_qbase);
+}
+
+
+/*This function allocates memory for the rxq descriptors and pre-fill rx queues
+ * with buffers.
+ * @param[in] client	client context
+ * @param[in] q_size	size of the rxQ, all queues are of same size
+ */
+static int hif_lib_client_init_rx_buffers(struct hif_client_s *client, int q_size)
+{
+	struct rx_queue_desc *desc;
+	struct hif_client_rx_queue *queue;
+	int ii, qno;
+
+	/*Allocate memory for the client queues */
+	client->rx_qbase = kzalloc(client->rx_qn * q_size * sizeof(struct rx_queue_desc), GFP_KERNEL);
+	if (!client->rx_qbase){
+		goto err;
+	}
+
+	for (qno = 0; qno < client->rx_qn; qno++) {
+		queue = &client->rx_q[qno];
+
+		queue->base = client->rx_qbase + qno * q_size * sizeof(struct rx_queue_desc);
+		queue->size = q_size;
+		queue->read_idx = 0;
+		queue->write_idx = 0;
+
+		dbg_print_info("rx queue: %d, base: %p, size: %d \n", qno, queue->base, queue->size);
+	}
+
+	for (qno = 0; qno < client->rx_qn; qno++) {
+		queue = &client->rx_q[qno];
+		desc = queue->base;
+
+		for (ii = 0; ii < queue->size; ii++) {
+			desc->ctrl = CL_DESC_BUF_LEN(pfe_pkt_size) | CL_DESC_OWN;
+			desc++;
+		}
+	}
+
+	return 0;
+
+err:
+	return 1;
+}
+
+#define inc_cl_idx(idxname) idxname = (idxname+1) & (queue->size-1)
+
+static void hif_lib_client_cleanup_tx_queue(struct hif_client_tx_queue *queue)
+{
+	dbg_print_info( "%s\n", __func__);
+
+	/* Check if there are any pending packets. Client must flush the tx queues
+	before unregistering, by calling by calling hif_lib_tx_get_next_complete() */
+	/* Hif no longer calls since we are no longer registered */
+
+	if (queue->tx_pending)
+		printk(KERN_ERR "%s: pending transmit packets\n", __func__);
+}
+
+static void hif_lib_client_release_tx_buffers(struct hif_client_s *client)
+{
+	int qno;
+
+	dbg_print_info("%s\n", __func__);
+
+	for (qno = 0; qno < client->tx_qn; qno++) {
+		hif_lib_client_cleanup_tx_queue(&client->tx_q[qno]);
+	}
+
+	kfree(client->tx_qbase);
+}
+
+static int hif_lib_client_init_tx_buffers(struct hif_client_s *client, int q_size)
+{
+	struct hif_client_tx_queue *queue;
+	int qno;
+
+	client->tx_qbase = kzalloc(client->tx_qn * q_size * sizeof(struct tx_queue_desc), GFP_KERNEL);
+	if (!client->tx_qbase) {
+		return 1;
+	}
+
+	for (qno = 0; qno < client->tx_qn; qno++) {
+		queue = &client->tx_q[qno];
+
+		queue->base = client->tx_qbase + qno * q_size * sizeof(struct tx_queue_desc);
+		queue->size = q_size;
+		queue->read_idx = 0;
+		queue->write_idx = 0;
+		queue->tx_pending = 0;
+		queue->nocpy_flag = 0;
+		queue->prev_tmu_tx_pkts = 0;
+		queue->done_tmu_tx_pkts = 0;
+
+		dbg_print_info("tx queue: %d, base: %p, size: %d \n", qno, queue->base, queue->size);
+	}
+
+	return 0;
+}
+
+static int hif_lib_event_dummy( void *priv, int event_type, int qno)
+{
+	return 0;
+}
+
+int hif_lib_client_register(struct hif_client_s *client)
+{
+	struct hif_shm *hif_shm;
+	struct hif_client_shm *client_shm;
+	int err, i;
+//	int loop_cnt = 0;
+
+	dbg_print_info("%s\n", __func__);
+
+	/*Allocate memory before spin_lock*/
+	if (hif_lib_client_init_rx_buffers(client, client->rx_qsize)) {
+		err = -ENOMEM;
+		goto err_rx;
+	}
+
+	if (hif_lib_client_init_tx_buffers(client, client->tx_qsize)) {
+		err = -ENOMEM;
+		goto err_tx;
+	}
+
+	spin_lock_bh(&pfe->hif.lock);
+	if (!(client->pfe) || (client->id >= HIF_CLIENTS_MAX) || (pfe->hif_client[client->id])) {
+		err = -EINVAL;
+		goto err;
+	}
+
+	hif_shm = client->pfe->hif.shm;
+
+	if (!client->event_handler) 
+		client->event_handler = hif_lib_event_dummy;
+
+	/*Initialize client specific shared memory */
+	client_shm = (struct hif_client_shm *)&hif_shm->client[client->id];
+	client_shm->rx_qbase = (unsigned long int)client->rx_qbase;
+	client_shm->rx_qsize = client->rx_qsize;
+	client_shm->tx_qbase = (unsigned long int)client->tx_qbase;
+	client_shm->tx_qsize = client->tx_qsize;
+	client_shm->ctrl = (client->tx_qn << CLIENT_CTRL_TX_Q_CNT_OFST) | (client->rx_qn << CLIENT_CTRL_RX_Q_CNT_OFST);
+//	spin_lock_init(&client->rx_lock);
+
+	for (i = 0; i < HIF_EVENT_MAX; i++) {
+		client->queue_mask[i] = 0; /* By default all events are unmasked */
+	}
+
+	/*Indicate to HIF driver*/
+	hif_lib_indicate_hif(&pfe->hif, REQUEST_CL_REGISTER, client->id, 0);
+
+	dbg_print_info("%s: client: %p, client_id: %d, tx_qsize: %d, rx_qsize: %d\n",
+			__func__, client, client->id, client->tx_qsize, client->rx_qsize);
+
+	client->cpu_id = -1;
+
+	pfe->hif_client[client->id] = client;
+	spin_unlock_bh(&pfe->hif.lock);
+
+	return 0;
+
+err:
+	spin_unlock_bh(&pfe->hif.lock);
+	hif_lib_client_release_tx_buffers(client);
+
+err_tx:
+	hif_lib_client_release_rx_buffers(client);
+
+err_rx:
+	return err;
+}
+
+int hif_lib_client_unregister(struct hif_client_s *client)
+{
+	struct pfe *pfe = client->pfe;
+	u32 client_id = client->id;
+
+	printk(KERN_INFO "%s : client: %p, client_id: %d, txQ_depth: %d, rxQ_depth: %d\n",
+			__func__, client, client->id, client->tx_qsize, client->rx_qsize);
+
+
+	spin_lock_bh(&pfe->hif.lock);
+	hif_lib_indicate_hif(&pfe->hif, REQUEST_CL_UNREGISTER, client->id, 0);
+
+	hif_lib_client_release_tx_buffers(client);
+	hif_lib_client_release_rx_buffers(client);
+	pfe->hif_client[client_id] = NULL;
+	spin_unlock_bh(&pfe->hif.lock);
+
+	return 0;
+}
+
+int hif_lib_event_handler_start(struct hif_client_s *client, int event, int qno)
+{
+	struct hif_client_rx_queue *queue = &client->rx_q[qno];
+	struct rx_queue_desc *desc = queue->base + queue->read_idx;
+
+	if ((event >= HIF_EVENT_MAX) || ( qno >= HIF_CLIENT_QUEUES_MAX)) {
+		dbg_print_info("%s: Unsupported event : %d  queue number : %d\n", __func__, event, qno);
+		return -1;
+	}
+
+	test_and_clear_bit(qno, &client->queue_mask[event]);
+
+	switch (event) {
+	case EVENT_RX_PKT_IND:
+		if (!(desc->ctrl & CL_DESC_OWN))
+			 hif_lib_indicate_client(client->id, EVENT_RX_PKT_IND, qno);
+		break;
+
+	case EVENT_HIGH_RX_WM:
+	case EVENT_TXDONE_IND:
+	default:
+		break;
+	}
+
+	return 0;
+}
+
+
+/*This function gets one packet from the specified client queue
+ * It also refill the rx buffer */
+void *hif_lib_receive_pkt(struct hif_client_s *client, int qno, int *len, int *ofst, unsigned int *rx_ctrl, unsigned int *desc_ctrl, void **priv_data)
+{
+	struct hif_client_rx_queue *queue = &client->rx_q[qno];
+	struct rx_queue_desc *desc;
+	void *pkt = NULL;
+
+	//printk(KERN_INFO "%s\n", __func__);
+#if defined(CONFIG_PLATFORM_EMULATION)
+	printk(KERN_INFO "%s:qno:%d cid:%d desc:%p rdidx:%d \n", 
+			__func__, qno, client->id, desc, 
+			queue->read_idx);
+#endif
+
+	/* Following lock is to protect rx queue access from, hif_lib_event_handler_start.
+	 * In general below lock is not required, because hif_lib_xmit_pkt and
+	 * hif_lib_event_handler_start are called from napi poll and which is not 
+	 * re-entrant. But if some client use in different way this lock is required.
+	 */
+	//spin_lock_irqsave(&client->rx_lock, flags);
+	desc = queue->base + queue->read_idx;
+	if (!(desc->ctrl & CL_DESC_OWN)) {
+		pkt = desc->data - pfe_pkt_headroom;
+
+		*rx_ctrl = desc->client_ctrl;
+		*desc_ctrl = desc->ctrl;
+
+		if (desc->ctrl & CL_DESC_FIRST) {
+			u16 size = *rx_ctrl >> HIF_CTRL_RX_OFFSET_OFST;
+
+			if (size) {
+				*len = CL_DESC_BUF_LEN(desc->ctrl) - PFE_PKT_HEADER_SZ - size;
+				*ofst = pfe_pkt_headroom + PFE_PKT_HEADER_SZ + size;
+				*priv_data = desc->data + PFE_PKT_HEADER_SZ;
+			} else {
+				*len = CL_DESC_BUF_LEN(desc->ctrl) - PFE_PKT_HEADER_SZ;
+				*ofst = pfe_pkt_headroom + PFE_PKT_HEADER_SZ;
+				*priv_data = NULL;
+			}
+
+		} else {
+			*len = CL_DESC_BUF_LEN(desc->ctrl);
+			*ofst = pfe_pkt_headroom;
+		}
+
+		desc->data = NULL; // Needed so we don't free a buffer/page twice on module_exit
+		smp_wmb();
+
+		desc->ctrl = CL_DESC_BUF_LEN(pfe_pkt_size) | CL_DESC_OWN;
+		inc_cl_idx(queue->read_idx);
+	}
+
+	//spin_unlock_irqrestore(&client->rx_lock, flags);
+	return pkt;
+}
+
+static inline void hif_hdr_write(struct hif_hdr *pkt_hdr, unsigned int client_id, unsigned int qno, u32 client_ctrl)
+{
+	/* Optimize the write since the destinaton may be non-cacheable */
+	if (!((unsigned long)pkt_hdr & 0x3)) {
+		((u32 *)pkt_hdr)[0] = (client_ctrl << 16) | (qno << 8) | client_id;
+	} else {
+		((u16 *)pkt_hdr)[0] = (qno << 8) | (client_id & 0xFF);
+		((u16 *)pkt_hdr)[1] = (client_ctrl & 0xFFFF);
+	}
+}
+
+/*This function puts the given packet in the specific client queue */
+void __hif_lib_xmit_pkt(struct hif_client_s *client, unsigned int qno, void *data, unsigned int len, u32 client_ctrl, unsigned int flags, void *client_data)
+{
+	struct hif_client_tx_queue *queue = &client->tx_q[qno];
+	struct tx_queue_desc *desc = queue->base + queue->write_idx;
+
+	//printk(KERN_INFO "%s\n",__func__);
+
+	/* First buffer */
+	if (flags & HIF_FIRST_BUFFER)
+	{
+		data -= sizeof(struct hif_hdr);
+		len += sizeof(struct hif_hdr);
+
+		hif_hdr_write(data, client->id, qno, client_ctrl);
+	}
+
+	desc->data = client_data;
+	desc->ctrl = CL_DESC_OWN | CL_DESC_FLAGS(flags);
+
+	__hif_xmit_pkt(&pfe->hif, client->id, qno, data, len, flags);
+
+	inc_cl_idx(queue->write_idx);
+	queue->tx_pending++;
+	queue->jiffies_last_packet = jiffies;
+
+}
+
+/*This function puts the given packet in the specific client queue */
+int hif_lib_xmit_pkt(struct hif_client_s *client, unsigned int qno, void *data, unsigned int len, u32 client_ctrl, void *client_data)
+{
+	struct hif_client_tx_queue *queue = &client->tx_q[qno];
+	struct tx_queue_desc *desc = queue->base + queue->write_idx;
+
+	//printk(KERN_INFO "%s\n",__func__);
+
+	if (queue->tx_pending < queue->size) {
+		/*Construct pkt header */
+
+		data -= sizeof(struct hif_hdr);
+		len += sizeof(struct hif_hdr);
+
+		hif_hdr_write(data, client->id, qno, client_ctrl);
+
+		desc->data = client_data;
+		desc->ctrl = CL_DESC_OWN | CL_DESC_FLAGS(HIF_FIRST_BUFFER | HIF_LAST_BUFFER | HIF_DATA_VALID);
+
+		if (hif_xmit_pkt(&pfe->hif, client->id, qno, data, len))
+			return 1;
+
+		inc_cl_idx(queue->write_idx);
+		queue->tx_pending++;
+		queue->jiffies_last_packet = jiffies;
+
+		return 0;
+	}
+
+	dbg_print_info("%s Tx client %d qno %d is full\n",__func__, client->id, qno);
+	return 1;
+}
+
+void *hif_lib_tx_get_next_complete(struct hif_client_s *client, int qno, unsigned int *flags, int count)
+{
+	struct hif_client_tx_queue *queue = &client->tx_q[qno];
+	struct tx_queue_desc *desc = queue->base + queue->read_idx;
+
+	dbg_print_info("%s: qno : %d rd_indx: %d pending:%d\n",__func__, qno, queue->read_idx, queue->tx_pending);
+
+	if (!queue->tx_pending )
+		return NULL;
+
+	if (queue->nocpy_flag && !queue->done_tmu_tx_pkts) {
+		u32 tmu_tx_pkts = be32_to_cpu(pe_dmem_read(TMU0_ID + client->id, virt_to_tmu_dmem(&tx_trans[qno]), 4));
+
+		if (queue->prev_tmu_tx_pkts > tmu_tx_pkts)
+			queue->done_tmu_tx_pkts = UINT_MAX - queue->prev_tmu_tx_pkts + tmu_tx_pkts;
+		else
+			queue->done_tmu_tx_pkts = tmu_tx_pkts - queue->prev_tmu_tx_pkts;
+
+		queue->prev_tmu_tx_pkts  = tmu_tx_pkts;
+
+		if (!queue->done_tmu_tx_pkts) {
+			return NULL;
+		}
+	}
+
+	if (desc->ctrl & CL_DESC_OWN) {
+		hif_tx_done_process(&pfe->hif, count);
+
+		//Check again, if packets done in tx queue.
+		if (desc->ctrl & CL_DESC_OWN)
+			return NULL;
+	}
+
+	inc_cl_idx(queue->read_idx);
+	queue->tx_pending--;
+
+	*flags = CL_DESC_GET_FLAGS(desc->ctrl);
+
+	if (queue->done_tmu_tx_pkts && (*flags & HIF_LAST_BUFFER))
+		queue->done_tmu_tx_pkts--;
+
+
+	return desc->data;
+}
+
+//FIXME: TMU queues length mapping needs to be declared in shared PFE/PFE_CTRL header
+static void hif_lib_tmu_credit_init(struct pfe *pfe)
+{
+	int i, q;
+
+	for (i = 0; i < NUM_GEMAC_SUPPORT; i++)
+		for (q = 0; q < emac_txq_cnt; q++) {
+			pfe->tmu_credit.tx_credit_max[i][q] = (q == 0) ? DEFAULT_Q0_QDEPTH : DEFAULT_MAX_QDEPTH;
+			pfe->tmu_credit.tx_credit[i][q] = pfe->tmu_credit.tx_credit_max[i][q];
+		}
+}
+/** __hif_lib_update_credit
+ *
+ * @param[in] client	hif client context
+ * @param[in] queue	queue number in match with TMU
+ */
+void __hif_lib_update_credit(struct hif_client_s *client, unsigned int queue)
+{
+	unsigned int tmu_tx_packets, tmp;
+
+	if (tx_qos) {
+		tmu_tx_packets = be32_to_cpu(pe_dmem_read(TMU0_ID + client->id, virt_to_tmu_dmem(&tx_trans[queue]), 4));
+
+		// tx_packets counter overflowed
+		if (tmu_tx_packets > pfe->tmu_credit.tx_packets[client->id][queue]) {
+			tmp = UINT_MAX - tmu_tx_packets + pfe->tmu_credit.tx_packets[client->id][queue];
+			pfe->tmu_credit.tx_credit[client->id][queue] = pfe->tmu_credit.tx_credit_max[client->id][queue] - tmp;
+		}
+		// TMU tx <= pfe_eth tx, normal case or both OF since last time
+		else
+			pfe->tmu_credit.tx_credit[client->id][queue] = pfe->tmu_credit.tx_credit_max[client->id][queue] - (pfe->tmu_credit.tx_packets[client->id][queue] - tmu_tx_packets);
+	}
+}
+
+/** hif_lib_update_credit
+ *
+ * @param[in] client	hif client context
+ * @param[in] queue	queue number in match with TMU
+ */
+void hif_lib_update_credit(struct hif_client_s *client, unsigned int queue)
+{
+	spin_lock_bh(&pfe->hif.tx_lock);
+	__hif_lib_update_credit(client, queue);
+	spin_unlock_bh(&pfe->hif.tx_lock);
+}
+
+int pfe_hif_lib_init(struct pfe *pfe)
+{
+	int rc;
+
+	printk(KERN_INFO "%s\n", __func__);
+
+	if (lro_mode) {
+		page_mode = 1;
+		pfe_pkt_size = min(PAGE_SIZE, MAX_PFE_PKT_SIZE);
+		pfe_pkt_headroom = 0;
+	} else {
+		page_mode = 0;
+		pfe_pkt_size = PFE_PKT_SIZE;
+		pfe_pkt_headroom = PFE_PKT_HEADROOM;
+	}
+
+	if (tx_qos)
+		emac_txq_cnt = EMAC_TXQ_CNT / 2;
+	else
+		emac_txq_cnt = EMAC_TXQ_CNT;
+
+	hif_lib_tmu_credit_init(pfe);
+	pfe->hif.shm = &ghif_shm;
+	rc = pfe_hif_shm_init(pfe->hif.shm);
+
+	return rc;
+}
+
+
+void pfe_hif_lib_exit(struct pfe *pfe)
+{
+	printk(KERN_INFO "%s\n", __func__);
+
+	pfe_hif_shm_clean(pfe->hif.shm);
+}
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/pfe_hif_lib.h
@@ -0,0 +1,219 @@
+/*
+ *
+ *  Copyright (C) 2007 Freescale Semiconductor, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+
+#ifndef _PFE_HIF_LIB_H_
+#define _PFE_HIF_LIB_H_
+
+#include "pfe_hif.h"
+
+#ifdef HIF_LIB_DEBUG
+#define dbg_print_info( fmt, args...) \
+	printk(KERN_INFO fmt, ##args)
+#else
+#define dbg_print_info( fmt, args...) 
+#endif
+
+#define HIF_CL_REQ_TIMEOUT	10
+
+#if defined(CONFIG_COMCERTO_ZONE_DMA_NCNB)
+#define GFP_DMA_PFE (GFP_DMA_NCNB | __GFP_NOWARN)
+#else
+#define GFP_DMA_PFE 0
+#endif
+
+enum {
+	REQUEST_CL_REGISTER = 0,
+	REQUEST_CL_UNREGISTER,
+	HIF_REQUEST_MAX
+};
+
+enum {
+	EVENT_HIGH_RX_WM = 0,     /* Event to indicate that client rx queue is reached water mark level */
+	EVENT_RX_PKT_IND,	/* Event to indicate that, packet recieved for client */
+	EVENT_TXDONE_IND,	/* Event to indicate that, packet tx done for client */
+	HIF_EVENT_MAX
+};
+
+/*structure to store client queue info */
+
+/*structure to store client queue info */
+struct hif_client_rx_queue {
+	struct rx_queue_desc *base;
+	u32	size;
+	u32	read_idx;
+	u32	write_idx;
+};
+
+struct hif_client_tx_queue {
+	struct tx_queue_desc *base;
+	u32	size;
+	u32	read_idx;
+	u32	write_idx;
+	u32	tx_pending;
+	unsigned long jiffies_last_packet;
+	u32	nocpy_flag;
+	u32	prev_tmu_tx_pkts;
+	u32	done_tmu_tx_pkts;
+	u32	cur_tso_hdr_p;
+	int 	tso_buf_cnt;
+};
+
+struct hif_client_s
+{
+	int	id;
+	int	tx_qn;
+	int	rx_qn;
+	void	*rx_qbase;
+	void	*tx_qbase;
+	/* FIXME tx/rx_qsize fields  can be removed after per queue depth is supported*/
+	int	tx_qsize;
+	int	rx_qsize;
+	int	cpu_id;
+
+//	spinlock_t 	rx_lock;
+	struct hif_client_tx_queue tx_q[HIF_CLIENT_QUEUES_MAX];
+	struct hif_client_rx_queue rx_q[HIF_CLIENT_QUEUES_MAX];
+	int (*event_handler)(void *priv, int event, int data);
+	unsigned long queue_mask[HIF_EVENT_MAX];
+	struct pfe *pfe;
+	void *priv;
+};
+
+
+/* Client specific shared memory 
+ * It contains number of Rx/Tx queues, base addresses and queue sizes */
+struct hif_client_shm {
+	u32 ctrl; /*0-7: number of Rx queues, 8-15: number of tx queues */
+	unsigned long rx_qbase; /*Rx queue base address */
+	u32 rx_qsize; /*each Rx queue size, all Rx queues are of same size */
+	unsigned long tx_qbase; /* Tx queue base address */
+	u32 tx_qsize; /*each Tx queue size, all Tx queues are of same size */
+};
+
+/*Client shared memory ctrl bit description */
+#define CLIENT_CTRL_RX_Q_CNT_OFST	0
+#define CLIENT_CTRL_TX_Q_CNT_OFST	8
+#define CLIENT_CTRL_RX_Q_CNT(ctrl)	(((ctrl) >> CLIENT_CTRL_RX_Q_CNT_OFST) & 0xFF)
+#define CLIENT_CTRL_TX_Q_CNT(ctrl)	(((ctrl) >> CLIENT_CTRL_TX_Q_CNT_OFST) & 0xFF)
+
+
+
+/*Shared memory used to communicate between HIF driver and host/client drivers
+ * Before starting the hif driver rx_buf_pool ans rx_buf_pool_cnt should be 
+ * initialized with host buffers and buffers count in the pool. 
+ * rx_buf_pool_cnt should be >= HIF_RX_DESC_NT.
+ * 
+ */
+struct hif_shm {
+	u32 rx_buf_pool_cnt; /*Number of rx buffers available*/
+	void *rx_buf_pool[HIF_RX_DESC_NT];/*Rx buffers required to initialize HIF rx descriptors */
+	unsigned long gClient_status[2]; /*Global client status bit mask */
+	u32 hif_qfull; /*TODO Client-id that caused for the TMU3 queue stop */
+	u32 hif_qresume; /*TODO */
+	struct hif_client_shm client[HIF_CLIENTS_MAX]; /* Client specific shared memory */
+};
+
+
+#define CL_DESC_OWN			(1 << 31) /* This sets owner ship to HIF driver */
+#define CL_DESC_LAST		(1 << 30) /* This indicates last packet for multi buffers handling */
+#define CL_DESC_FIRST		(1 << 29) /* This indicates first packet for multi buffers handling */
+#define CL_DESC_BUF_LEN(x)		((x) & 0xFFFF)
+#define CL_DESC_FLAGS(x)		(((x) & 0xF) << 16)
+#define CL_DESC_GET_FLAGS(x)		(((x) >> 16) & 0xF)
+
+struct rx_queue_desc {
+	void *data;
+	u32	ctrl; /*0-15bit len, 16-20bit flags, 31bit owner*/
+	u32	client_ctrl;
+};
+
+struct tx_queue_desc {
+	void *data;
+	u32	ctrl; /*0-15bit len, 16-20bit flags, 31bit owner*/
+};
+
+/* HIF Rx is not working properly for 2-byte aligned buffers and   
+ * ip_header should be 4byte aligned for better iperformance.
+ * "ip_header = 64 + 6(hif_header) + 14 (MAC Header)" will be 4byte aligned. 
+ */
+#define PFE_PKT_HEADER_SZ	sizeof(struct hif_hdr)
+#define PFE_BUF_SIZE		2048	/* must be big enough for headroom, pkt size and skb shared info */
+#define PFE_PKT_HEADROOM	128
+#define SKB_SHARED_INFO_SIZE	256    /* At least sizeof(struct skb_shared_info) bytes */
+
+//#define PFE_PKT_SIZE		1544	/* maximum ethernet packet size */
+#define PFE_PKT_SIZE		(PFE_BUF_SIZE - PFE_PKT_HEADROOM - SKB_SHARED_INFO_SIZE)	/* maximum ethernet packet size after reassembly offload*/
+#define MAX_L2_HDR_SIZE		14	/* Not correct for VLAN/PPPoE */
+#define MAX_L3_HDR_SIZE		20	/* Not correct for IPv6 */
+#define MAX_L4_HDR_SIZE		60	/* TCP with maximum options */
+#define MAX_HDR_SIZE		(MAX_L2_HDR_SIZE + MAX_L3_HDR_SIZE + MAX_L4_HDR_SIZE)
+#define MAX_WIFI_HDR_SIZE 	(MAX_L2_HDR_SIZE + MAX_L3_HDR_SIZE + 6)
+#define MAX_PFE_PKT_SIZE	16380UL		/* Used in page mode to clamp packet size to the maximum supported by the hif hw interface (<16KiB) */
+
+extern unsigned int pfe_pkt_size;
+extern unsigned int pfe_pkt_headroom;
+extern unsigned int page_mode;
+extern unsigned int lro_mode;
+extern unsigned int tx_qos;
+extern unsigned int emac_txq_cnt;
+
+int pfe_hif_lib_init(struct pfe *pfe);
+void pfe_hif_lib_exit(struct pfe *pfe);
+int hif_lib_client_register(struct hif_client_s *client);
+int hif_lib_client_unregister(struct  hif_client_s *client);
+void __hif_lib_xmit_tso_hdr(struct hif_client_s *client, unsigned int qno, u32 client_ctrl, unsigned int ip_off, unsigned int ip_id, unsigned int ip_len, unsigned int tcp_off, unsigned int tcp_seq);
+void __hif_lib_xmit_pkt(struct hif_client_s *client, unsigned int qno, void *data, unsigned int len, u32 client_ctrl, unsigned int flags, void *client_data);
+int hif_lib_xmit_pkt(struct hif_client_s *client, unsigned int qno, void *data, unsigned int len, u32 client_ctrl, void *client_data);
+void hif_lib_indicate_client(int cl_id, int event, int data);
+int hif_lib_event_handler_start( struct hif_client_s *client, int event, int data );
+int hif_lib_tmu_queue_start( struct hif_client_s *client, int qno );
+int hif_lib_tmu_queue_stop( struct hif_client_s *client, int qno );
+void *hif_lib_tx_get_next_complete(struct hif_client_s *client, int qno, unsigned int *flags, int count);
+void *hif_lib_receive_pkt(struct hif_client_s *client, int qno, int *len, int *ofst, unsigned int *rx_ctrl, unsigned int *desc_ctrl, void **priv_data);
+void hif_lib_update_credit(struct hif_client_s *client, unsigned int qno);
+void __hif_lib_update_credit(struct hif_client_s *client, unsigned int queue);
+void hif_lib_set_rx_cpu_affinity(struct hif_client_s *client, int cpu_id);
+void hif_lib_set_tx_queue_nocpy(struct hif_client_s *client, int qno, int enable);
+static inline int hif_lib_tx_avail(struct hif_client_s *client, unsigned int qno)
+{
+	struct hif_client_tx_queue *queue = &client->tx_q[qno];
+
+	return (queue->size - queue->tx_pending);
+}
+
+static inline int hif_lib_get_tx_wrIndex(struct hif_client_s *client, unsigned int qno)
+{
+	struct hif_client_tx_queue *queue = &client->tx_q[qno];
+
+	return queue->write_idx;
+}
+
+
+static inline int hif_lib_tx_pending(struct hif_client_s *client, unsigned int qno)
+{
+	struct hif_client_tx_queue *queue = &client->tx_q[qno];
+
+	return queue->tx_pending;
+}
+
+#define hif_lib_tx_credit_avail(pfe, id, qno) pfe->tmu_credit.tx_credit[id][qno]
+#define hif_lib_tx_credit_max(pfe, id, qno) pfe->tmu_credit.tx_credit_max[id][qno]
+#define hif_lib_tx_credit_use(pfe, id, qno, credit) do {if (tx_qos) {pfe->tmu_credit.tx_credit[id][qno]-= credit; pfe->tmu_credit.tx_packets[id][qno]+=credit;}} while (0)
+
+#endif /* _PFE_HIF_LIB_H_ */
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/pfe_hw.c
@@ -0,0 +1,188 @@
+/*
+ *
+ *  Copyright (C) 2007 Freescale Semiconductor, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+
+#include "pfe_mod.h"
+#include "pfe_hw.h"
+
+/* Functions to handle most of pfe hw register initialization */
+
+int pfe_hw_init(struct pfe *pfe, int resume)
+{
+	CLASS_CFG class_cfg = {
+		.pe_sys_clk_ratio = PE_SYS_CLK_RATIO,
+		.route_table_baseaddr = pfe->ddr_phys_baseaddr + ROUTE_TABLE_BASEADDR,
+		.route_table_hash_bits = ROUTE_TABLE_HASH_BITS,
+	};
+
+	TMU_CFG tmu_cfg = {
+		.pe_sys_clk_ratio = PE_SYS_CLK_RATIO,
+		.llm_base_addr = pfe->ddr_phys_baseaddr + TMU_LLM_BASEADDR,
+		.llm_queue_len = TMU_LLM_QUEUE_LEN,
+	};
+
+#if !defined(CONFIG_UTIL_DISABLED)
+	UTIL_CFG util_cfg = {
+		.pe_sys_clk_ratio = PE_SYS_CLK_RATIO,
+	};
+#endif
+
+	BMU_CFG bmu1_cfg = {
+		.baseaddr = CBUS_VIRT_TO_PFE(LMEM_BASE_ADDR + BMU1_LMEM_BASEADDR),
+		.count = BMU1_BUF_COUNT,
+		.size = BMU1_BUF_SIZE,
+	};
+
+	BMU_CFG bmu2_cfg = {
+		.baseaddr = DDR_PHYS_TO_PFE(pfe->ddr_phys_baseaddr + BMU2_DDR_BASEADDR),
+		.count = BMU2_BUF_COUNT,
+		.size = BMU2_BUF_SIZE,
+	};
+
+	GPI_CFG egpi1_cfg = {
+		.lmem_rtry_cnt = EGPI1_LMEM_RTRY_CNT,
+		.tmlf_txthres = EGPI1_TMLF_TXTHRES,
+		.aseq_len = EGPI1_ASEQ_LEN,
+	};
+
+	GPI_CFG egpi2_cfg = {
+		.lmem_rtry_cnt = EGPI2_LMEM_RTRY_CNT,
+		.tmlf_txthres = EGPI2_TMLF_TXTHRES,
+		.aseq_len = EGPI2_ASEQ_LEN,
+	};
+
+#if defined(CONFIG_PLATFORM_C2000)
+	GPI_CFG egpi3_cfg = {
+		.lmem_rtry_cnt = EGPI3_LMEM_RTRY_CNT,
+		.tmlf_txthres = EGPI3_TMLF_TXTHRES,
+		.aseq_len = EGPI3_ASEQ_LEN,
+	};
+#endif
+
+	GPI_CFG hgpi_cfg = {
+		.lmem_rtry_cnt = HGPI_LMEM_RTRY_CNT,
+		.tmlf_txthres = HGPI_TMLF_TXTHRES,
+		.aseq_len = HGPI_ASEQ_LEN,
+	};
+
+	printk(KERN_INFO "%s\n", __func__);
+
+#if defined(CONFIG_PLATFORM_LS1012A) && !defined(LS1012A_PFE_RESET_WA)
+	/* LS1012A needs this to make PE work correctly */
+        writel(0x3,     CLASS_PE_SYS_CLK_RATIO);
+        writel(0x3,     TMU_PE_SYS_CLK_RATIO);
+        writel(0x3,     UTIL_PE_SYS_CLK_RATIO);
+        udelay(10);
+#endif
+
+	printk(KERN_INFO "CLASS version: %x\n", readl(CLASS_VERSION));
+	printk(KERN_INFO "TMU version: %x\n", readl(TMU_VERSION));
+
+	printk(KERN_INFO "BMU1 version: %x\n", readl(BMU1_BASE_ADDR + BMU_VERSION));
+	printk(KERN_INFO "BMU2 version: %x\n", readl(BMU2_BASE_ADDR + BMU_VERSION));
+#if defined(CONFIG_PLATFORM_C2000)
+	printk(KERN_INFO "EMAC1 network cfg: %x\n", readl(EMAC1_BASE_ADDR + EMAC_NETWORK_CONFIG));
+	printk(KERN_INFO "EMAC2 network cfg: %x\n", readl(EMAC2_BASE_ADDR + EMAC_NETWORK_CONFIG));
+#if !defined(CONFIG_PLATFORM_PCI)
+	printk(KERN_INFO "EMAC3 network cfg: %x\n", readl(EMAC3_BASE_ADDR + EMAC_NETWORK_CONFIG));
+#endif
+#else
+	//TODO print MTIP config
+#endif
+
+	printk(KERN_INFO "EGPI1 version: %x\n", readl(EGPI1_BASE_ADDR + GPI_VERSION));
+	printk(KERN_INFO "EGPI2 version: %x\n", readl(EGPI2_BASE_ADDR + GPI_VERSION));
+#if !defined(CONFIG_PLATFORM_PCI) && !defined(CONFIG_PLATFORM_LS1012A)
+	printk(KERN_INFO "EGPI3 version: %x\n", readl(EGPI3_BASE_ADDR + GPI_VERSION));
+#endif
+	printk(KERN_INFO "HGPI version: %x\n", readl(HGPI_BASE_ADDR + GPI_VERSION));
+
+#if !defined(CONFIG_PLATFORM_PCI)
+	printk(KERN_INFO "GPT version: %x\n", readl(CBUS_GPT_VERSION));
+#endif
+
+	printk(KERN_INFO "HIF version: %x\n", readl(HIF_VERSION));
+	printk(KERN_INFO "HIF NOPCY version: %x\n", readl(HIF_NOCPY_VERSION));
+
+#if !defined(CONFIG_UTIL_DISABLED)
+	printk(KERN_INFO "UTIL version: %x\n", readl(UTIL_VERSION));
+#endif
+	while(!(readl(TMU_CTRL) & ECC_MEM_INIT_DONE)) ;
+
+	hif_rx_disable();
+	hif_tx_disable();
+
+	bmu_init(BMU1_BASE_ADDR, &bmu1_cfg);
+
+	printk(KERN_INFO "bmu_init(1) done\n");
+
+	bmu_init(BMU2_BASE_ADDR, &bmu2_cfg);
+
+	printk(KERN_INFO "bmu_init(2) done\n");
+
+	class_cfg.resume = resume ? 1 : 0;
+
+	class_init(&class_cfg);
+
+	printk(KERN_INFO "class_init() done\n");
+
+	tmu_init(&tmu_cfg);
+
+	printk(KERN_INFO "tmu_init() done\n");
+#if !defined(CONFIG_UTIL_DISABLED)
+	util_init(&util_cfg);
+
+	printk(KERN_INFO "util_init() done\n");
+#endif
+	gpi_init(EGPI1_BASE_ADDR, &egpi1_cfg);
+
+	printk(KERN_INFO "gpi_init(1) done\n");
+
+	gpi_init(EGPI2_BASE_ADDR, &egpi2_cfg);
+
+	printk(KERN_INFO "gpi_init(2) done\n");
+#if !defined(CONFIG_PLATFORM_PCI) && !defined(CONFIG_PLATFORM_LS1012A)
+	gpi_init(EGPI3_BASE_ADDR, &egpi3_cfg);
+
+	printk(KERN_INFO "gpi_init(3) done\n");
+#endif
+	gpi_init(HGPI_BASE_ADDR, &hgpi_cfg);
+
+	printk(KERN_INFO "gpi_init(hif) done\n");
+
+	bmu_enable(BMU1_BASE_ADDR);
+
+	printk(KERN_INFO "bmu_enable(1) done\n");
+
+	bmu_enable(BMU2_BASE_ADDR);
+
+	printk(KERN_INFO "bmu_enable(2) done\n");
+
+	return 0;
+}
+
+void pfe_hw_exit(struct pfe *pfe)
+{
+	printk(KERN_INFO "%s\n", __func__);
+
+	bmu_disable(BMU1_BASE_ADDR);
+	bmu_reset(BMU1_BASE_ADDR);
+
+	bmu_disable(BMU2_BASE_ADDR);
+	bmu_reset(BMU2_BASE_ADDR);
+}
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/pfe_hw.h
@@ -0,0 +1,32 @@
+/*
+ *
+ *  Copyright (C) 2007 Freescale Semiconductor, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+
+#ifndef _PFE_HW_H_
+#define _PFE_HW_H_
+
+#if !defined(CONFIG_PLATFORM_PCI)
+#define PE_SYS_CLK_RATIO	1	/* SYS/AXI = 250MHz, HFE = 500MHz */
+#else
+#define PE_SYS_CLK_RATIO	0	/* SYS = 40MHz, HFE = 40MHz */
+#endif
+
+int pfe_hw_init(struct pfe *pfe, int resume);
+void pfe_hw_exit(struct pfe *pfe);
+
+#endif /* _PFE_HW_H_ */
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/pfe_ls1012a_platform.c
@@ -0,0 +1,341 @@
+/*
+ *
+ *  Copyright (C) 2007 Freescale Semiconductor, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+
+#include <linux/module.h>
+#include <linux/device.h>
+#include <linux/of_net.h>
+#include <linux/of_address.h>
+#include <linux/platform_device.h>
+#include <linux/slab.h>
+#include <linux/clk.h>
+#include <linux/mfd/syscon.h>
+#include <linux/regmap.h>
+
+
+#include "pfe_mod.h"
+
+struct comcerto_pfe_platform_data pfe_platform_data;
+
+
+
+static int pfe_get_gemac_if_proprties(struct device_node *parent, int port, int if_cnt,
+					struct comcerto_pfe_platform_data *pdata)
+{
+	struct device_node *gem = NULL, *phy = NULL;
+	int size;
+	int ii = 0, phy_id = 0;
+	const u32 *addr;
+	const void *mac_addr;
+
+	for (ii = 0; ii < if_cnt; ii++) {
+		gem = of_get_next_child(parent, gem);
+		if (!gem)
+			goto err;
+		addr = of_get_property(gem, "reg", &size);
+		if (addr && (be32_to_cpup(addr) == port))
+			break;
+	}
+
+	if (ii >= if_cnt) {
+		printk(KERN_ERR "%s:%d Failed to find interface = %d\n", __func__, __LINE__, if_cnt);
+		goto err;
+	}
+
+	pdata->comcerto_eth_pdata[port].gem_id = port;
+
+	mac_addr = of_get_mac_address(gem);
+
+	if (mac_addr) {
+		memcpy(pdata->comcerto_eth_pdata[port].mac_addr, mac_addr, ETH_ALEN);
+	}
+
+	if ((pdata->comcerto_eth_pdata[port].mii_config = of_get_phy_mode(gem)) < 0)
+		printk(KERN_ERR "%s:%d Incorrect Phy mode....\n", __func__, __LINE__);
+
+
+	addr = of_get_property(gem, "fsl,gemac-bus-id", &size);
+	if (!addr)
+		printk(KERN_ERR "%s:%d Invalid gemac-bus-id....\n", __func__, __LINE__);
+	else
+		pdata->comcerto_eth_pdata[port].bus_id = be32_to_cpup(addr);
+
+	addr = of_get_property(gem, "fsl,gemac-phy-id", &size);
+	if (!addr)
+		printk(KERN_ERR "%s:%d Invalid gemac-phy-id....\n", __func__, __LINE__);
+	else
+		phy_id = pdata->comcerto_eth_pdata[port].phy_id = be32_to_cpup(addr);
+
+	addr = of_get_property(gem, "fsl,mdio-mux-val", &size);
+	if (!addr)
+		printk(KERN_ERR "%s: Invalid mdio-mux-val....\n", __func__);
+	else
+		phy_id = pdata->comcerto_eth_pdata[port].mdio_muxval= be32_to_cpup(addr);
+
+
+	addr = of_get_property(gem, "fsl,pfe-phy-if-flags", &size);
+	if (!addr)
+		printk(KERN_ERR "%s:%d Invalid pfe-phy-if-flags....\n", __func__, __LINE__);
+	else
+		pdata->comcerto_eth_pdata[port].phy_flags = be32_to_cpup(addr);
+
+	addr = of_get_property(gem, "fsl,pfe-gemac-mode", &size);
+	if (!addr)
+		printk(KERN_ERR "%s:%d Invalid pfe-gemac-mode....\n", __func__, __LINE__);
+	else
+		pdata->comcerto_eth_pdata[port].gemac_mode = be32_to_cpup(addr);
+
+
+	/* If PHY is enabled, read mdio properties */
+	if (pdata->comcerto_eth_pdata[port].phy_flags & GEMAC_NO_PHY)
+		goto done;
+
+	phy = of_get_next_child(gem, NULL);
+
+	addr = of_get_property(phy, "reg", &size);
+        
+	if (!addr)
+		printk(KERN_ERR "%s:%d Invalid phy enable flag....\n", __func__, __LINE__);
+	else
+		pdata->comcerto_mdio_pdata[port].enabled = be32_to_cpup(addr);
+
+	addr = of_get_property (phy, "fsl,mdio-phy-mask", &size);
+	if (!addr)
+		printk(KERN_ERR "%s:%d Unable to read mdio-phy-mask....\n", __func__, __LINE__);
+	else
+		pdata->comcerto_mdio_pdata[port].phy_mask= be32_to_cpup(addr);
+	pdata->comcerto_mdio_pdata[port].irq[0] = PHY_POLL;
+
+done:
+
+	return 0;
+
+err:
+	return -1;
+}
+/**
+ * pfe_platform_probe -
+ *
+ *
+ */
+static int pfe_platform_probe(struct platform_device *pdev)
+{
+	struct resource res;
+	int ii, rc, interface_count = 0, size = 0;
+	const u32 *prop;
+	struct device_node  *np;
+
+	np = pdev->dev.of_node;
+
+	if (!np) {
+		printk(KERN_ERR "Invalid device node\n");
+		return -EINVAL;
+	}
+
+	pfe = kzalloc(sizeof(struct pfe), GFP_KERNEL);
+	if (!pfe) {
+		rc = -ENOMEM;
+		goto err_alloc;
+	}
+
+	platform_set_drvdata(pdev, pfe);
+
+	dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(32));
+
+	if (of_address_to_resource(np, 2, &res))
+	{
+		rc = -ENOMEM;
+		printk(KERN_ERR "failed to get ddr resource\n");
+		goto err_ddr;
+	}
+
+
+	pfe->ddr_phys_baseaddr = res.start;
+	pfe->ddr_size = resource_size(&res);
+
+	//pfe->ddr_baseaddr = ioremap(res.start, resource_size(&res));
+	pfe->ddr_baseaddr = phys_to_virt(res.start);
+	if (!pfe->ddr_baseaddr) {
+		printk(KERN_ERR "ioremap() ddr failed\n");
+		rc = -ENOMEM;
+		goto err_ddr;
+	}
+
+	/*printk("%s:%d : DDR Res : Phy addr:len = %x:%x Mapped addr : %x\n", __func__, __LINE__, 
+						pfe->ddr_phys_baseaddr, pfe->ddr_size, pfe->ddr_baseaddr);*/
+
+	pfe->scfg = syscon_regmap_lookup_by_phandle(pdev->dev.of_node,"fsl,pfe-scfg");
+	if (IS_ERR(pfe->scfg)) {
+		dev_err(&pdev->dev, "No syscfg phandle specified\n");
+		return PTR_ERR(pfe->scfg);
+	}
+	/*printk("%s scfg %p\n",__func__,pfe->scfg);*/
+
+
+#if 1
+	if (!(pfe->cbus_baseaddr = of_iomap(np, 1)))
+	{
+		rc = -ENOMEM;
+		printk(KERN_ERR "failed to get axi resource\n");
+		goto err_axi;
+	}
+
+	/*printk("%s:%d : AXI Mapped addr : %lx\n", __func__, __LINE__, pfe->cbus_baseaddr);
+	printk("%s:%d : AXI Mapped addr : phys %lx\n", __func__, __LINE__, virt_to_phys(pfe->cbus_baseaddr));*/
+#else
+
+	if (of_address_to_resource(np, 1, &res))
+	{
+		rc = -ENOMEM;
+		printk(KERN_ERR "failed to get AXI resource\n");
+		goto err_iram;
+	}
+	pfe->cbus_baseaddr = ioremap(res.start, resource_size(&res));
+	if (!pfe->cbus_baseaddr) {
+		printk(KERN_INFO "ioremap() AXI failed %lx %x\n", res.start, resource_size(&res));
+		rc = -ENOMEM;
+		goto err_iram;
+	}
+	printk("%s:%d : AXI Mapped addr : %x PHY addr = %x\n", __func__, __LINE__, pfe->cbus_baseaddr, res.start);
+#endif
+
+	pfe->hif_irq = platform_get_irq(pdev, 0);
+	if (pfe->hif_irq < 0) {
+		printk(KERN_ERR "platform_get_irq_byname(hif) failed\n");
+		rc = pfe->hif_irq;
+		goto err_hif_irq;
+	}
+	/*printk("hif_irq: %d \n", pfe->hif_irq);*/
+
+	/* Read interface count */
+	prop = of_get_property(np, "fsl,pfe-num-interfaces", &size);
+	if (!prop) {
+		printk(KERN_ERR "Failed to read number of interfaces\n");
+		rc = -ENXIO;
+		goto err_prop;
+	}
+
+	interface_count = be32_to_cpup(prop);
+	/*printk(KERN_INFO "%s:%d Number of interfaces : %d\n", __func__, __LINE__, interface_count);*/
+	if (interface_count <= 0) {
+		printk(KERN_ERR "No ethernet interface count : %d\n", interface_count);
+		rc = -ENXIO;
+		goto err_prop;
+	}
+
+	for (ii = 0; ii < interface_count; ii++) {
+		pfe_get_gemac_if_proprties(np, ii, interface_count, &pfe_platform_data);
+	}
+
+
+	pfe->dev = &pdev->dev;
+
+	pfe->dev->platform_data = &pfe_platform_data;
+
+	//FIXME get the correct clock from dts 
+	pfe->ctrl.sys_clk = 250000;  // save sys_clk value as KHz
+
+	rc = pfe_probe(pfe);
+	if (rc < 0)
+		goto err_probe;
+
+	return 0;
+
+err_probe:
+err_prop:
+	/*TODO complet the code */
+err_hif_irq:
+	iounmap(pfe->cbus_baseaddr);
+
+err_axi:
+	iounmap(pfe->ddr_baseaddr);
+
+err_ddr:
+	platform_set_drvdata(pdev, NULL);
+
+	kfree(pfe);
+
+err_alloc:
+	return rc;
+}
+
+
+/**
+ * pfe_platform_remove -
+ *
+ *
+ */
+static int pfe_platform_remove(struct platform_device *pdev)
+{
+	struct pfe *pfe = platform_get_drvdata(pdev);
+	int rc;
+	
+	printk(KERN_INFO "%s\n", __func__);
+
+	rc = pfe_remove(pfe);
+
+	iounmap(pfe->cbus_baseaddr);
+	iounmap(pfe->ddr_baseaddr);
+
+	platform_set_drvdata(pdev, NULL);
+
+	kfree(pfe);
+
+	return rc;
+}
+
+static struct of_device_id pfe_match[] = {
+	{
+		.compatible = "fsl,pfe",
+	},
+	{},
+};
+MODULE_DEVICE_TABLE(of, pfe_match);
+
+static struct platform_driver pfe_platform_driver = {
+	.probe = pfe_platform_probe,
+	.remove = pfe_platform_remove,
+	.driver = {
+		.name = "pfe",
+		.of_match_table = pfe_match,
+	},
+};
+
+#if 0
+static int __init pfe_module_init(void)
+{
+	printk(KERN_INFO "%s\n", __func__);
+
+	return platform_driver_register(&pfe_platform_driver);
+}
+
+
+static void __exit pfe_module_exit(void)
+{
+	platform_driver_unregister(&pfe_platform_driver);
+
+	printk(KERN_INFO "%s\n", __func__);
+}
+module_init(pfe_module_init);
+module_exit(pfe_module_exit);
+#endif
+
+module_platform_driver(pfe_platform_driver);
+MODULE_LICENSE("GPL");
+MODULE_DESCRIPTION("PFE Ethernet driver");
+MODULE_AUTHOR("NXP DNCPE");
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/pfe_mod.c
@@ -0,0 +1,140 @@
+/*
+ *
+ *  Copyright (C) 2007 Freescale Semiconductor, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+
+#include <linux/dma-mapping.h>
+#include "pfe_mod.h"
+
+struct pfe *pfe;
+
+/**
+ * pfe_probe - 
+ *
+ *
+ */
+int pfe_probe(struct pfe *pfe)
+{
+	int rc;
+
+
+	if (DDR_MAX_SIZE > pfe->ddr_size) {
+		printk(KERN_ERR "%s: required DDR memory (%x) above platform ddr memory (%x)\n", __func__, DDR_MAX_SIZE, pfe->ddr_size);
+		rc = -ENOMEM;
+		goto err_hw;
+	}
+
+	if (((int) (pfe->ddr_phys_baseaddr + BMU2_DDR_BASEADDR) & (8*SZ_1M - 1)) != 0) {
+			printk(KERN_ERR "%s: BMU2 base address (0x%x) must be aligned on 8MB boundary\n", __func__, (int) pfe->ddr_phys_baseaddr + BMU2_DDR_BASEADDR);
+			rc = -ENOMEM;
+			goto err_hw;
+	}
+
+
+	printk(KERN_INFO "cbus_baseaddr: %lx, ddr_baseaddr: %lx, ddr_phys_baseaddr: %lx, ddr_size: %x\n",
+			(unsigned long)pfe->cbus_baseaddr, (unsigned long)pfe->ddr_baseaddr,
+			pfe->ddr_phys_baseaddr, pfe->ddr_size);
+
+	pfe_lib_init(pfe->cbus_baseaddr, pfe->ddr_baseaddr, pfe->ddr_phys_baseaddr, pfe->ddr_size);
+
+	rc = pfe_hw_init(pfe, 0);
+	if (rc < 0)
+		goto err_hw;
+
+	rc = pfe_hif_lib_init(pfe);
+	if (rc < 0)
+		goto err_hif_lib;
+
+	rc = pfe_hif_init(pfe);
+	if (rc < 0)
+		goto err_hif;
+
+	rc = pfe_firmware_init(pfe);
+	if (rc < 0)
+		goto err_firmware;
+
+	rc = pfe_ctrl_init(pfe);
+	if (rc < 0)
+		goto err_ctrl;
+
+	rc = pfe_eth_init(pfe);
+	if (rc < 0)
+		goto err_eth;
+
+	rc = pfe_sysfs_init(pfe);
+	if(rc < 0)
+		goto err_sysfs;
+
+	rc = pfe_debugfs_init(pfe);
+	if (rc < 0)
+		goto err_debugfs;
+
+	return 0;
+
+err_debugfs:
+	pfe_sysfs_exit(pfe);
+
+err_sysfs:
+	pfe_eth_exit(pfe);
+
+err_eth:
+	pfe_ctrl_exit(pfe);
+
+err_ctrl:
+	pfe_firmware_exit(pfe);
+
+err_firmware:
+	pfe_hif_exit(pfe);
+
+err_hif:
+	pfe_hif_lib_exit(pfe);
+
+err_hif_lib:
+	pfe_hw_exit(pfe);
+
+err_hw:
+	return rc;
+}
+
+
+/**
+ * pfe_remove - 
+ *
+ *
+ */
+int pfe_remove(struct pfe *pfe)
+{
+	printk(KERN_INFO "%s\n", __func__);
+
+	pfe_debugfs_exit(pfe);
+
+	pfe_sysfs_exit(pfe);
+
+	pfe_eth_exit(pfe);
+
+	pfe_ctrl_exit(pfe);
+
+	pfe_firmware_exit(pfe);
+
+	pfe_hif_exit(pfe);
+
+	pfe_hif_lib_exit(pfe);
+
+	pfe_hw_exit(pfe);
+
+	return 0;
+}
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/pfe_mod.h
@@ -0,0 +1,163 @@
+/*
+ *
+ *  Copyright (C) 2007 Freescale Semiconductor, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+
+#ifndef _PFE_MOD_H_
+#define _PFE_MOD_H_
+
+#include <linux/device.h>
+#include <linux/elf.h>
+
+struct pfe;
+
+#include "config.h"
+#include "pfe_hw.h"
+#include "pfe_firmware.h"
+#include "pfe_ctrl.h"
+#include "pfe_hif.h"
+#include "pfe_hif_lib.h"
+#include "pfe_eth.h"
+#include "pfe_sysfs.h"
+#include "pfe_perfmon.h"
+#include "pfe_debugfs.h"
+
+struct pfe_tmu_credit {
+	/* Number of allowed TX packet in-flight, matches TMU queue size */
+	unsigned int tx_credit[NUM_GEMAC_SUPPORT][EMAC_TXQ_CNT];
+	unsigned int tx_credit_max[NUM_GEMAC_SUPPORT][EMAC_TXQ_CNT];
+	unsigned int tx_packets[NUM_GEMAC_SUPPORT][EMAC_TXQ_CNT];
+};
+
+struct pfe {
+	struct regmap	*scfg;
+	unsigned long ddr_phys_baseaddr;
+	void *ddr_baseaddr;
+	unsigned int ddr_size;
+	void *cbus_baseaddr;
+	void *apb_baseaddr;
+	unsigned long iram_phys_baseaddr;
+	void *iram_baseaddr;
+        unsigned long ipsec_phys_baseaddr;
+        void *ipsec_baseaddr;
+	int hif_irq;
+	int hif_client_irq;
+	struct device *dev;
+	struct dentry *dentry;
+	struct pfe_ctrl ctrl;
+	struct pfe_hif hif;
+	struct pfe_eth eth;
+	struct hif_client_s *hif_client[HIF_CLIENTS_MAX];
+#if defined(CFG_DIAGS)
+	struct pfe_diags diags;
+#endif
+	struct pfe_tmu_credit tmu_credit;
+	struct pfe_cpumon cpumon;
+	struct pfe_memmon memmon;
+	int wake;
+	struct clk * hfe_clock;
+};
+
+extern struct pfe *pfe;
+
+int pfe_probe(struct pfe *pfe);
+int pfe_remove(struct pfe *pfe);
+
+#ifndef SZ_1K
+#define SZ_1K 1024
+#endif
+
+#ifndef SZ_1M
+#define SZ_1M (1024 * 1024)
+#endif
+
+/* DDR Mapping */
+#if !defined(CONFIG_PLATFORM_PCI)
+#define ROUTE_TABLE_BASEADDR	0
+#define ROUTE_TABLE_HASH_BITS	15	/**< 32K entries */
+#define ROUTE_TABLE_SIZE	((1 << ROUTE_TABLE_HASH_BITS) * CLASS_ROUTE_SIZE)
+#define BMU2_DDR_BASEADDR	(ROUTE_TABLE_BASEADDR + ROUTE_TABLE_SIZE)
+#define BMU2_BUF_COUNT		(4096 - 256)			/**< This is to get a total DDR size of 12MiB */
+#define BMU2_DDR_SIZE		(DDR_BUF_SIZE * BMU2_BUF_COUNT)
+#define UTIL_CODE_BASEADDR	(BMU2_DDR_BASEADDR + BMU2_DDR_SIZE)
+#define UTIL_CODE_SIZE		(128 * SZ_1K)
+#define UTIL_DDR_DATA_BASEADDR	(UTIL_CODE_BASEADDR + UTIL_CODE_SIZE)
+#define UTIL_DDR_DATA_SIZE	(64 * SZ_1K)
+#define CLASS_DDR_DATA_BASEADDR	(UTIL_DDR_DATA_BASEADDR + UTIL_DDR_DATA_SIZE)
+#define CLASS_DDR_DATA_SIZE	(32 * SZ_1K)
+#define TMU_DDR_DATA_BASEADDR	(CLASS_DDR_DATA_BASEADDR + CLASS_DDR_DATA_SIZE)
+#define TMU_DDR_DATA_SIZE	(32 * SZ_1K)
+#define TMU_LLM_BASEADDR	(TMU_DDR_DATA_BASEADDR + TMU_DDR_DATA_SIZE)
+#define TMU_LLM_QUEUE_LEN	(8 * 512)			/**< Must be power of two and at least 16 * 8 = 128 bytes */
+#define TMU_LLM_SIZE		(4 * 16 * TMU_LLM_QUEUE_LEN)	/**< (4 TMU's x 16 queues x queue_len) */
+
+#define DDR_MAX_SIZE		(TMU_LLM_BASEADDR + TMU_LLM_SIZE)
+
+#else
+
+#define UTIL_CODE_BASEADDR	0
+#if defined(CONFIG_UTIL_DISABLED)
+#define UTIL_CODE_SIZE		(0 * SZ_1K)
+#else
+#define UTIL_CODE_SIZE		(8 * SZ_1K)
+#endif
+#define UTIL_DDR_DATA_BASEADDR	(UTIL_CODE_BASEADDR + UTIL_CODE_SIZE)
+#define UTIL_DDR_DATA_SIZE	(0 * SZ_1K)
+#define CLASS_DDR_DATA_BASEADDR	(UTIL_DDR_DATA_BASEADDR + UTIL_DDR_DATA_SIZE)
+#define CLASS_DDR_DATA_SIZE	(0 * SZ_1K)
+#define TMU_DDR_DATA_BASEADDR	(CLASS_DDR_DATA_BASEADDR + CLASS_DDR_DATA_SIZE)
+#define TMU_DDR_DATA_SIZE	(0 * SZ_1K)
+#define ROUTE_TABLE_BASEADDR	(TMU_DDR_DATA_BASEADDR + TMU_DDR_DATA_SIZE)
+#define ROUTE_TABLE_HASH_BITS	5	/**< 32 entries */
+#define ROUTE_TABLE_SIZE	((1 << ROUTE_TABLE_HASH_BITS) * CLASS_ROUTE_SIZE)
+#define BMU2_DDR_BASEADDR	(ROUTE_TABLE_BASEADDR + ROUTE_TABLE_SIZE)
+#define BMU2_BUF_COUNT		16
+#define BMU2_DDR_SIZE		(DDR_BUF_SIZE * BMU2_BUF_COUNT)
+#define TMU_LLM_BASEADDR	(BMU2_DDR_BASEADDR + BMU2_DDR_SIZE)
+#define TMU_LLM_QUEUE_LEN	(16 * 8)			/**< Must be power of two and at least 16 * 8 = 128 bytes */
+#define TMU_LLM_SIZE		(4 * 16 * TMU_LLM_QUEUE_LEN)	/**< (4 TMU's x 16 queues x queue_len) */
+#define HIF_DESC_BASEADDR	(TMU_LLM_BASEADDR + TMU_LLM_SIZE)
+#define HIF_RX_DESC_SIZE	(16*HIF_RX_DESC_NT)
+#define HIF_TX_DESC_SIZE	(16*HIF_TX_DESC_NT)
+#define HIF_DESC_SIZE		(HIF_RX_DESC_SIZE + HIF_TX_DESC_SIZE)
+#define HIF_RX_PKT_DDR_BASEADDR	(HIF_DESC_BASEADDR + HIF_DESC_SIZE)
+#define HIF_RX_PKT_DDR_SIZE	(HIF_RX_DESC_NT * DDR_BUF_SIZE)
+#define HIF_TX_PKT_DDR_BASEADDR	(HIF_RX_PKT_DDR_BASEADDR + HIF_RX_PKT_DDR_SIZE)
+#define HIF_TX_PKT_DDR_SIZE	(HIF_TX_DESC_NT * DDR_BUF_SIZE)
+#define ROUTE_BASEADDR		(HIF_TX_PKT_DDR_BASEADDR + HIF_TX_PKT_DDR_SIZE)
+#define ROUTE_SIZE		(2 * CLASS_ROUTE_SIZE)
+
+#define DDR_MAX_SIZE		(ROUTE_BASEADDR + ROUTE_SIZE)
+
+#define PFE_HOST_TO_PCI(addr)	(((u32)addr)- ((u32)DDR_BASE_ADDR))
+#define PFE_PCI_TO_HOST(addr)	(((u32)addr)+ ((u32)DDR_BASE_ADDR))
+#endif
+
+/* IRAM Mapping */
+#define IPSEC_IRAM_BASEADDR	0
+#define IPSEC_IRAM_SIZE		0x2000
+
+/* LMEM Mapping */
+#define BMU1_LMEM_BASEADDR	0
+#define BMU1_BUF_COUNT		256
+#define BMU1_LMEM_SIZE		(LMEM_BUF_SIZE * BMU1_BUF_COUNT)
+#define IPSEC_LMEM_BASEADDR	(BMU1_LMEM_BASEADDR + BMU1_LMEM_SIZE)	
+#define IPSEC_LMEM_SIZE		(30 * 1024)
+
+
+
+#endif /* _PFE_MOD_H */
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/pfe_perfmon.c
@@ -0,0 +1,175 @@
+/*
+ *
+ *  Copyright (C) 2007 Freescale Semiconductor, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+
+/* PFE performance monitoring functions */
+
+#include "pfe_ctrl_hal.h"
+#include "pfe_perfmon.h"
+
+static TIMER_ENTRY cpumon_timer;
+
+u32 CLASS_DMEM_SH2(cpu_ticks[2]);
+u32 TMU_DMEM_SH2(cpu_ticks[2]);
+#if !defined(CONFIG_UTIL_DISABLED)
+u32 UTIL_DMEM_SH2(cpu_ticks[2]);
+#endif
+
+#define compute_active_pct(total_ticks, active_ticks) ((active_ticks * 100 + (total_ticks >> 1)) / total_ticks)
+
+static void cpumon_timer_handler(void)
+{
+	int id;
+	u32 dmem_addr;
+	u32 ticks[2];
+	u32 total, active;
+	struct pfe_ctrl *ctrl = &pfe->ctrl;
+	struct pfe_cpumon *cpumon = &pfe->cpumon;
+
+	// Process class PE's
+	total = active = 0;
+	dmem_addr = virt_to_class_dmem(&class_cpu_ticks[0]);
+	for (id = CLASS0_ID; id <= CLASS_MAX_ID; id++)
+	{
+		cpumon->cpu_usage_pct[id] = 0;
+		if (pe_sync_stop(ctrl, (1 << id)) < 0)
+			continue;
+		ticks[0] = be32_to_cpu(pe_dmem_read(id, dmem_addr, 4));
+		ticks[1] = be32_to_cpu(pe_dmem_read(id, dmem_addr + 4, 4));
+		pe_dmem_write(id, 0, dmem_addr, 4);
+		pe_dmem_write(id, 0, dmem_addr + 4, 4);
+		pe_start(ctrl, (1 << id));
+		ticks[0] >>= 8;	// divide both values by 256, so multiply by 100 won't overflow
+		ticks[1] >>= 8;
+		total += ticks[0];
+		active += ticks[1];
+		if (ticks[0] != 0)
+			cpumon->cpu_usage_pct[id] = compute_active_pct(ticks[0], ticks[1]);
+	}
+	if (total != 0)
+		cpumon->class_usage_pct = compute_active_pct(total, active);
+	else
+		cpumon->class_usage_pct = 0;
+
+	// Process TMU PE's
+	total = active = 0;
+	dmem_addr = virt_to_tmu_dmem(&tmu_cpu_ticks[0]);
+	for (id = TMU0_ID; id <= TMU_MAX_ID; id++)
+	{
+#if defined(CONFIG_PLATFORM_LS1012A)
+		if(id == TMU2_ID) continue;
+#endif
+		cpumon->cpu_usage_pct[id] = 0;
+		if (pe_sync_stop(ctrl, (1 << id)) < 0)
+			continue;
+		ticks[0] = be32_to_cpu(pe_dmem_read(id, dmem_addr, 4));
+		ticks[1] = be32_to_cpu(pe_dmem_read(id, dmem_addr + 4, 4));
+		pe_dmem_write(id, 0, dmem_addr, 4);
+		pe_dmem_write(id, 0, dmem_addr + 4, 4);
+		pe_start(ctrl, (1 << id));
+		ticks[0] >>= 8;	// divide both values by 256, so multiply by 100 won't overflow
+		ticks[1] >>= 8;
+		if (ticks[0] != 0)
+			cpumon->cpu_usage_pct[id] = compute_active_pct(ticks[0], ticks[1]);
+	}
+#if !defined(CONFIG_UTIL_DISABLED)
+	// Process Util PE
+	dmem_addr = virt_to_util_dmem(&util_cpu_ticks[0]);
+	cpumon->cpu_usage_pct[UTIL_ID] = 0;
+	if (pe_sync_stop(ctrl, (1 << UTIL_ID)) < 0)
+		return;
+	ticks[0] = be32_to_cpu(pe_dmem_read(UTIL_ID, dmem_addr, 4));
+	ticks[1] = be32_to_cpu(pe_dmem_read(UTIL_ID, dmem_addr + 4, 4));
+	pe_dmem_write(UTIL_ID, 0, dmem_addr, 4);
+	pe_dmem_write(UTIL_ID, 0, dmem_addr + 4, 4);
+	pe_start(ctrl, (1 << UTIL_ID));
+	ticks[0] >>= 8;	// divide both values by 256, so multiply by 100 won't overflow
+	ticks[1] >>= 8;
+	if (ticks[0] != 0)
+		cpumon->cpu_usage_pct[UTIL_ID] = compute_active_pct(ticks[0], ticks[1]);
+#endif
+}
+
+static int pfe_cpumon_init(struct pfe *pfe)
+{
+	timer_init(&cpumon_timer, cpumon_timer_handler);
+	timer_add(&cpumon_timer, CT_CPUMON_INTERVAL);
+	return 0;
+}
+
+static void pfe_cpumon_exit(struct pfe *pfe)
+{
+	timer_del(&cpumon_timer);
+}
+
+
+/*********************************************************************************/
+
+// Memory monitor functions
+
+void * pfe_kmalloc(size_t size, int flags)
+{
+	struct pfe_memmon *memmon = &pfe->memmon;
+	void *ptr;
+	ptr = kmalloc(size, flags);
+	if (ptr)
+		memmon->kernel_memory_allocated += ksize(ptr);
+	return ptr;
+}
+
+void * pfe_kzalloc(size_t size, int flags)
+{
+	struct pfe_memmon *memmon = &pfe->memmon;
+	void *ptr;
+	ptr = kzalloc(size, flags);
+	if (ptr)
+		memmon->kernel_memory_allocated += ksize(ptr);
+	return ptr;
+}
+
+void pfe_kfree(void *ptr)
+{
+	struct pfe_memmon *memmon = &pfe->memmon;
+	memmon->kernel_memory_allocated -= ksize(ptr);
+	kfree(ptr);
+}
+
+static int pfe_memmon_init(struct pfe *pfe)
+{
+	return 0;
+}
+
+static void pfe_memmon_exit(struct pfe *pfe)
+{
+}
+
+/*********************************************************************************/
+
+
+int pfe_perfmon_init(struct pfe *pfe)
+{
+	pfe_cpumon_init(pfe);
+	pfe_memmon_init(pfe);
+	return 0;
+}
+
+void pfe_perfmon_exit(struct pfe *pfe)
+{
+	pfe_cpumon_exit(pfe);
+	pfe_memmon_exit(pfe);
+}
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/pfe_perfmon.h
@@ -0,0 +1,41 @@
+/*
+ *
+ *  Copyright (C) 2007 Freescale Semiconductor, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+
+#ifndef _PFE_PERFMON_H_
+#define _PFE_PERFMON_H_
+
+#define	CT_CPUMON_INTERVAL	(1 * TIMER_TICKS_PER_SEC)
+
+struct pfe_cpumon {
+	u32 cpu_usage_pct[MAX_PE];
+	u32 class_usage_pct;
+};
+
+struct pfe_memmon {
+	u32 kernel_memory_allocated;
+};
+
+void * pfe_kmalloc(size_t size, int flags);
+void * pfe_kzalloc(size_t size, int flags);
+void pfe_kfree(void *ptr);
+
+int pfe_perfmon_init(struct pfe *pfe);
+void pfe_perfmon_exit(struct pfe *pfe);
+
+#endif /* _PFE_PERFMON_H_ */
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/pfe_platform.c
@@ -0,0 +1,358 @@
+/*
+ *
+ *  Copyright (C) 2007 Freescale Semiconductor, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+
+#include <linux/module.h>
+#include <linux/platform_device.h>
+#include <linux/slab.h>
+#include <linux/clk.h>
+
+#include "pfe_mod.h"
+
+/**
+ * pfe_platform_probe -
+ *
+ *
+ */
+static int pfe_platform_probe(struct platform_device *pdev)
+{
+	struct resource *r;
+	int rc;
+	struct clk *clk_axi;
+
+	printk(KERN_INFO "%s\n", __func__);
+
+	pfe = kzalloc(sizeof(struct pfe), GFP_KERNEL);
+	if (!pfe) {
+		rc = -ENOMEM;
+		goto err_alloc;
+	}
+
+	platform_set_drvdata(pdev, pfe);
+
+	r = platform_get_resource_byname(pdev, IORESOURCE_MEM, "ddr");
+	if (!r) {
+		printk(KERN_INFO "platform_get_resource_byname(ddr) failed\n");
+		rc = -ENXIO;
+		goto err_ddr;
+	}
+	
+	pfe->ddr_phys_baseaddr = r->start;
+	pfe->ddr_size = resource_size(r);
+
+	pfe->ddr_baseaddr = ioremap(r->start, resource_size(r));
+	if (!pfe->ddr_baseaddr) {
+		printk(KERN_INFO "ioremap() ddr failed\n");
+		rc = -ENOMEM;
+		goto err_ddr;
+	}
+	
+	r = platform_get_resource_byname(pdev, IORESOURCE_MEM, "axi");
+	if (!r) {
+		printk(KERN_INFO "platform_get_resource_byname(axi) failed\n");
+		rc = -ENXIO;
+		goto err_axi;
+	}
+
+	pfe->cbus_baseaddr = ioremap(r->start, resource_size(r));
+	if (!pfe->cbus_baseaddr) {
+		printk(KERN_INFO "ioremap() axi failed\n");
+		rc = -ENOMEM;
+		goto err_axi;
+	}
+
+	r = platform_get_resource_byname(pdev, IORESOURCE_MEM, "apb");
+	if (!r) {
+		printk(KERN_INFO "platform_get_resource_byname(apb) failed\n");
+		rc = -ENXIO;
+		goto err_apb;
+	}
+
+	pfe->apb_baseaddr = ioremap(r->start, resource_size(r));
+	if (!pfe->apb_baseaddr) {
+		printk(KERN_INFO "ioremap() apb failed\n");
+		rc = -ENOMEM;
+		goto err_apb;
+	}
+
+	r = platform_get_resource_byname(pdev, IORESOURCE_MEM, "iram");
+	if (!r) {
+		printk(KERN_INFO "platform_get_resource_byname(iram) failed\n");
+		rc = -ENXIO;
+		goto err_iram;
+	}
+
+	pfe->iram_phys_baseaddr = r->start;
+	pfe->iram_baseaddr = ioremap(r->start, resource_size(r));
+	if (!pfe->iram_baseaddr) {
+		printk(KERN_INFO "ioremap() iram failed\n");
+		rc = -ENOMEM;
+		goto err_iram;
+	}
+
+        r = platform_get_resource_byname(pdev, IORESOURCE_MEM, "ipsec");
+        if (!r) {
+                printk(KERN_INFO "platform_get_resource_byname(ipsec) failed\n");
+                rc = -ENXIO;
+                goto err_ipsec;
+        }
+
+        pfe->ipsec_phys_baseaddr = r->start;
+	/* Just map only initial 1MB , as its enough to access espah engine
+	*/
+        //pfe->ipsec_baseaddr = ioremap(r->start, resource_size(r));
+        pfe->ipsec_baseaddr = ioremap(r->start, 1*1024*1024);
+        if (!pfe->ipsec_baseaddr) {
+                printk(KERN_INFO "ioremap() ipsec failed\n");
+                rc = -ENOMEM;
+                goto err_ipsec;
+        }
+
+        printk(KERN_INFO "ipsec: baseaddr :%x --- %x\n",  (u32)pfe->ipsec_phys_baseaddr,  (u32)pfe->ipsec_baseaddr);
+
+	pfe->hif_irq = platform_get_irq_byname(pdev, "hif");
+	if (pfe->hif_irq < 0) {
+		printk(KERN_INFO "platform_get_irq_byname(hif) failed\n");
+		rc = pfe->hif_irq;
+		goto err_hif_irq;
+	}
+
+#if 0
+	pfe->hif_client_irq = platform_get_irq_byname(pdev, "hif_client");
+	if (pfe->hif_client_irq < 0) {
+		printk(KERN_INFO "platform_get_irq_byname(hif_client) failed\n");
+		rc = pfe->hif_client_irq;
+		goto err_hif_irq;
+	}
+#endif
+
+	pfe->dev = &pdev->dev;
+
+
+	/* Get the system clock */
+	clk_axi = clk_get(NULL,"axi");
+	if (IS_ERR(clk_axi)) {
+		printk(KERN_INFO "clk_get call failed\n");
+		rc = -ENXIO;
+		goto err_clk;
+	}
+
+	/* HFE core clock */
+	pfe->hfe_clock = clk_get(NULL, "hfe_core");
+	if (IS_ERR(pfe->hfe_clock)) {
+		printk(KERN_INFO "clk_get call failed\n");
+		rc = -ENXIO;
+		goto err_hfe_clock;
+	}
+
+	clk_disable(pfe->hfe_clock);
+	c2000_block_reset(COMPONENT_PFE_SYS, 1);
+	mdelay(1);
+	c2000_block_reset(COMPONENT_PFE_SYS, 0);
+	clk_enable(pfe->hfe_clock);
+
+	pfe->ctrl.clk_axi = clk_axi;
+	pfe->ctrl.sys_clk = clk_get_rate(clk_axi) / 1000;  // save sys_clk value as KHz
+
+	rc = pfe_probe(pfe);
+	if (rc < 0)
+		goto err_probe;
+
+	return 0;
+
+err_probe:
+	clk_put(pfe->hfe_clock);
+err_hfe_clock:
+	clk_put(clk_axi);
+err_clk:
+err_hif_irq:
+        iounmap(pfe->ipsec_baseaddr);
+err_ipsec:
+	iounmap(pfe->iram_baseaddr);
+err_iram:
+	iounmap(pfe->apb_baseaddr);
+
+err_apb:
+	iounmap(pfe->cbus_baseaddr);
+
+err_axi:
+	iounmap(pfe->ddr_baseaddr);
+
+err_ddr:
+	platform_set_drvdata(pdev, NULL);
+
+	kfree(pfe);
+
+err_alloc:
+	return rc;
+}
+
+
+/**
+ * pfe_platform_remove -
+ *
+ *
+ */
+static int pfe_platform_remove(struct platform_device *pdev)
+{
+	struct pfe *pfe = platform_get_drvdata(pdev);
+	int rc;
+	
+	printk(KERN_INFO "%s\n", __func__);
+
+	rc = pfe_remove(pfe);
+
+	c2000_block_reset(COMPONENT_PFE_SYS, 1);
+	clk_disable(pfe->hfe_clock);
+	clk_put(pfe->hfe_clock);
+	clk_put(pfe->ctrl.clk_axi);
+	iounmap(pfe->ipsec_baseaddr);
+	iounmap(pfe->iram_baseaddr);
+	iounmap(pfe->apb_baseaddr);
+	iounmap(pfe->cbus_baseaddr);
+	iounmap(pfe->ddr_baseaddr);
+
+	platform_set_drvdata(pdev, NULL);
+
+	kfree(pfe);
+
+	return rc;
+}
+
+#ifdef CONFIG_PM
+
+#ifdef CONFIG_PM_SLEEP
+static int pfe_platform_suspend(struct device *dev)
+{
+	struct pfe *pfe = platform_get_drvdata(to_platform_device(dev));
+	struct net_device *netdev;
+	int i;
+
+	printk(KERN_INFO "%s\n", __func__);
+
+	pfe->wake = 0;
+
+	for (i = 0; i < (NUM_GEMAC_SUPPORT - 1); i++ ) {
+		netdev = pfe->eth.eth_priv[i]->dev;
+
+		netif_device_detach(netdev);
+
+		if (netif_running(netdev))
+			if(pfe_eth_suspend(netdev))
+				pfe->wake =1;
+	}
+
+	/* Shutdown PFE only if we're not waking up the system */
+	if (!pfe->wake) {
+		pfe_ctrl_suspend(&pfe->ctrl);
+		pfe_hif_exit(pfe);
+		pfe_hif_lib_exit(pfe);
+
+		class_disable();
+		tmu_disable(0xf);
+#if !defined(CONFIG_UTIL_DISABLED)
+		util_disable();
+#endif
+		pfe_hw_exit(pfe);
+		c2000_block_reset(COMPONENT_PFE_SYS, 1);
+		clk_disable(pfe->hfe_clock);
+	}
+
+	return 0;
+}
+
+static int pfe_platform_resume(struct device *dev)
+{
+	struct pfe *pfe = platform_get_drvdata(to_platform_device(dev));
+	struct net_device *netdev;
+	int i;
+
+	printk(KERN_INFO "%s\n", __func__);
+
+	if (!pfe->wake) {
+		/* Sequence follows VLSI recommendation (bug 71927) */
+		c2000_block_reset(COMPONENT_PFE_SYS, 1);
+		mdelay(1);
+		c2000_block_reset(COMPONENT_PFE_SYS, 0);
+		clk_enable(pfe->hfe_clock);
+
+		pfe_hw_init(pfe, 1);
+		pfe_hif_lib_init(pfe);
+		pfe_hif_init(pfe);
+#if !defined(CONFIG_UTIL_DISABLED)
+		util_enable();
+#endif
+		tmu_enable(0xf);
+		class_enable();
+		pfe_ctrl_resume(&pfe->ctrl);
+	}
+
+	for(i = 0; i < (NUM_GEMAC_SUPPORT - 1); i++) {
+		netdev = pfe->eth.eth_priv[i]->dev;
+
+		if (pfe->eth.eth_priv[i]->mii_bus)
+			pfe_eth_mdio_reset(pfe->eth.eth_priv[i]->mii_bus);
+
+		if (netif_running(netdev))
+			pfe_eth_resume(netdev);
+
+		netif_device_attach(netdev);
+	}
+	return 0;
+}
+#else
+#define pfe_platform_suspend NULL
+#define pfe_platform_resume NULL
+#endif
+
+static const struct dev_pm_ops pfe_platform_pm_ops = {
+	SET_SYSTEM_SLEEP_PM_OPS(pfe_platform_suspend, pfe_platform_resume)
+};
+
+#endif
+
+static struct platform_driver pfe_platform_driver = {
+	.probe = pfe_platform_probe,
+	.remove = pfe_platform_remove,
+	.driver = {
+		.name = "pfe",
+#ifdef CONFIG_PM
+		.pm = &pfe_platform_pm_ops,
+#endif
+	},
+};
+
+
+static int __init pfe_module_init(void)
+{
+	printk(KERN_INFO "%s\n", __func__);
+
+	return platform_driver_register(&pfe_platform_driver);
+}
+
+
+static void __exit pfe_module_exit(void)
+{
+	platform_driver_unregister(&pfe_platform_driver);
+
+	printk(KERN_INFO "%s\n", __func__);
+}
+
+MODULE_LICENSE("GPL");
+module_init(pfe_module_init);
+module_exit(pfe_module_exit);
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/pfe_sysfs.c
@@ -0,0 +1,855 @@
+/*
+ *  (C) Copyright 2011
+ *  Author : Freescale Semiconductor, Inc.
+ *
+ *  See file CREDITS for list of people who contributed to this
+ *  project.
+ *
+ *  This program is free software; you can redistribute it and/or
+ *  modify it under the terms of the GNU General Public License as
+ *  published by the Free Software Foundation; either version 2 of
+ *  the License, or (at your option) any later version.
+ *
+ *  This program is distributed in the hope that it will be useful,
+ *  but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *  GNU General Public License for more details.
+ *
+ *  You should have received a copy of the GNU General Public License
+ *  along with this program; if not, write to the Free Software
+ *  Foundation, Inc., 59 Temple Place, Suite 330, Boston,
+ *  MA 02111-1307 USA
+ * */
+
+#include <linux/module.h>
+#include <linux/platform_device.h>
+
+#include "pfe_mod.h"
+#include "pfe_ctrl_hal.h"
+
+#define PE_EXCEPTION_DUMP_ADDRESS 0x1fa8
+#define NUM_QUEUES		16
+
+static char register_name[20][5] = {
+	"EPC", "ECAS", "EID", "ED",
+	"r0", "r1", "r2", "r3",
+	"r4", "r5", "r6", "r7",
+	"r8", "r9", "r10", "r11",
+	"r12", "r13", "r14", "r15",
+};
+
+static char exception_name[14][20] = {
+	"Reset",
+	"HardwareFailure",
+	"NMI",
+	"InstBreakpoint",
+	"DataBreakpoint",
+	"Unsupported",
+	"PrivilegeViolation",
+	"InstBusError",
+	"DataBusError",
+	"AlignmentError",
+	"ArithmeticError",
+	"SystemCall",
+	"MemoryManagement",
+	"Interrupt",
+};
+
+static unsigned long class_do_clear = 0;
+static unsigned long tmu_do_clear = 0;
+#if !defined(CONFIG_UTIL_DISABLED)
+static unsigned long util_do_clear = 0;
+#endif
+
+u32 qm_read_drop_stat(u32 tmu, u32 queue, u32 *total_drops, int do_reset);
+
+static ssize_t display_pe_status(char *buf, int id, u32 dmem_addr, unsigned long do_clear)
+{
+	ssize_t len = 0;
+	u32 val;
+	char statebuf[5];
+	struct pfe_cpumon *cpumon = &pfe->cpumon;
+	u32 debug_indicator;
+	u32 debug[20];
+
+	*(u32 *)statebuf = pe_dmem_read(id, dmem_addr, 4);
+	dmem_addr += 4;
+
+	statebuf[4] = '\0';
+	len += sprintf(buf + len, "state=%4s ", statebuf);
+
+	val = pe_dmem_read(id, dmem_addr, 4);
+	dmem_addr += 4;
+	len += sprintf(buf + len, "ctr=%08x ", cpu_to_be32(val));
+
+	val = pe_dmem_read(id, dmem_addr, 4);
+	if (do_clear && val)
+		pe_dmem_write(id, 0, dmem_addr, 4);
+	dmem_addr += 4;
+	len += sprintf(buf + len, "rx=%u ", cpu_to_be32(val));
+
+	val = pe_dmem_read(id, dmem_addr, 4);
+	if (do_clear && val)
+		pe_dmem_write(id, 0, dmem_addr, 4);
+	dmem_addr += 4;
+	if (id >= TMU0_ID && id <= TMU_MAX_ID)
+		len += sprintf(buf + len, "qstatus=%x", cpu_to_be32(val));
+	else
+		len += sprintf(buf + len, "tx=%u", cpu_to_be32(val));
+
+	val = pe_dmem_read(id, dmem_addr, 4);
+	if (do_clear && val)
+		pe_dmem_write(id, 0, dmem_addr, 4);
+	dmem_addr += 4;
+	if (val)
+		len += sprintf(buf + len, " drop=%u", cpu_to_be32(val));
+
+	len += sprintf(buf + len, " load=%d%%", cpumon->cpu_usage_pct[id]);
+
+	len += sprintf(buf + len, "\n");
+
+	debug_indicator = pe_dmem_read(id, dmem_addr, 4);
+	dmem_addr += 4;
+	if (!strncmp((char *)&debug_indicator, "DBUG", 4))
+	{
+		int j, last = 0;
+		for (j = 0; j < 16; j++)
+		{
+			debug[j] = pe_dmem_read(id, dmem_addr, 4);
+			if (debug[j])
+			{
+				if (do_clear)
+					pe_dmem_write(id, 0, dmem_addr, 4);
+				last = j + 1;
+			}
+			dmem_addr += 4;
+		}
+		for (j = 0; j < last; j++)
+		{
+			len += sprintf(buf + len, "%08x%s", cpu_to_be32(debug[j]),
+							(j & 0x7) == 0x7 || j == last - 1 ? "\n" : " ");
+		}
+	}
+
+	if (!strncmp(statebuf, "DEAD", 4))
+	{
+		u32 i, dump = PE_EXCEPTION_DUMP_ADDRESS;
+
+		len += sprintf(buf + len, "Exception details:\n");
+		for (i = 0; i < 20; i++) {
+			debug[i] = pe_dmem_read(id, dump, 4);
+			dump +=4;
+			if (i == 2)
+				len += sprintf(buf + len, "%4s = %08x (=%s) ", register_name[i], cpu_to_be32(debug[i]), exception_name[min((u32) cpu_to_be32(debug[i]), (u32)13)]);
+			else
+				len += sprintf(buf + len, "%4s = %08x%s", register_name[i], cpu_to_be32(debug[i]),
+							(i & 0x3) == 0x3 || i == 19 ? "\n" : " ");
+		}
+	}
+
+	return len;
+}
+
+static ssize_t class_phy_stats(char *buf, int phy)
+{
+	ssize_t len = 0;
+	int off1 = phy * 0x28;
+	int off2 = phy * 0x10;
+
+	if (phy == 3)
+		off1 = CLASS_PHY4_RX_PKTS - CLASS_PHY1_RX_PKTS;
+
+	len += sprintf(buf + len, "phy: %d\n", phy);
+	len += sprintf(buf + len, "  rx:   %10u, tx:   %10u, intf:  %10u, ipv4:    %10u, ipv6: %10u\n",
+			readl(CLASS_PHY1_RX_PKTS + off1), readl(CLASS_PHY1_TX_PKTS + off1),
+			readl(CLASS_PHY1_INTF_MATCH_PKTS + off1), readl(CLASS_PHY1_V4_PKTS + off1),
+			readl(CLASS_PHY1_V6_PKTS + off1));
+
+	len += sprintf(buf + len, "  icmp: %10u, igmp: %10u, tcp:   %10u, udp:     %10u\n",
+			readl(CLASS_PHY1_ICMP_PKTS + off2), readl(CLASS_PHY1_IGMP_PKTS + off2),
+			readl(CLASS_PHY1_TCP_PKTS + off2), readl(CLASS_PHY1_UDP_PKTS + off2));
+
+	len += sprintf(buf + len, "  err\n");
+	len += sprintf(buf + len, "  lp:   %10u, intf: %10u, l3:    %10u, chcksum: %10u, ttl:  %10u\n",
+			readl(CLASS_PHY1_LP_FAIL_PKTS + off1), readl(CLASS_PHY1_INTF_FAIL_PKTS + off1),
+			readl(CLASS_PHY1_L3_FAIL_PKTS + off1), readl(CLASS_PHY1_CHKSUM_ERR_PKTS + off1),
+			readl(CLASS_PHY1_TTL_ERR_PKTS + off1));
+
+	return len;
+}
+
+/** qm_read_drop_stat
+ * This function is used to read the drop statistics from the TMU
+ * hw drop counter.  Since the hw counter is always cleared afer
+ * reading, this function maintains the previous drop count, and
+ * adds the new value to it.  That value can be retrieved by
+ * passing a pointer to it with the total_drops arg.
+ *
+ * @param tmu		TMU number (0 - 3)
+ * @param queue		queue number (0 - 15)
+ * @param total_drops	pointer to location to store total drops (or NULL)
+ * @param do_reset	if TRUE, clear total drops after updating
+ *
+ */
+
+u32 qm_read_drop_stat(u32 tmu, u32 queue, u32 *total_drops, int do_reset)
+{
+	static u32 qtotal[TMU_MAX_ID + 1][NUM_QUEUES];
+	u32 val;
+	writel((tmu << 8) | queue, TMU_TEQ_CTRL);
+	writel((tmu << 8) | queue, TMU_LLM_CTRL);
+	val = readl(TMU_TEQ_DROP_STAT);
+	qtotal[tmu][queue] += val;
+	if (total_drops)
+		*total_drops = qtotal[tmu][queue];
+	if (do_reset)
+		qtotal[tmu][queue] = 0;
+	return val;
+}
+
+static ssize_t tmu_queue_stats(char *buf, int tmu, int queue)
+{
+	ssize_t len = 0;
+	u32 drops;
+
+	len += sprintf(buf + len, "%d-%02d, ", tmu, queue);
+
+	drops = qm_read_drop_stat(tmu, queue, NULL, 0);
+
+	/* Select queue */
+	writel((tmu << 8) | queue, TMU_TEQ_CTRL);
+	writel((tmu << 8) | queue, TMU_LLM_CTRL);
+
+	len += sprintf(buf + len, "(teq) drop: %10u, tx: %10u (llm) head: %08x, tail: %08x, drop: %10u\n",
+		drops, readl(TMU_TEQ_TRANS_STAT),
+		readl(TMU_LLM_QUE_HEADPTR), readl(TMU_LLM_QUE_TAILPTR),
+		readl(TMU_LLM_QUE_DROPCNT));
+
+	return len;
+}
+
+
+static ssize_t tmu_queues(char *buf, int tmu)
+{
+	ssize_t len = 0;
+	int queue;
+
+	for (queue = 0; queue < 16; queue++)
+		len += tmu_queue_stats(buf + len, tmu, queue);
+
+	return len;
+}
+
+static ssize_t tmu_ctx(char *buf, int tmu)
+{
+	ssize_t len = 0;
+	int i;
+	u32 val, tmu_context_addr = TMU_CONTEXT_ADDR;
+
+	len += sprintf(buf+len, " TMU %d \n", TMU0_ID+tmu);
+	for (i = 1; i <= 160 ; i++, tmu_context_addr += 4)
+	{
+		val = pe_dmem_read(TMU0_ID+tmu, tmu_context_addr , 4);
+		if (i == 5)
+			len += sprintf(buf+len, "\nShapers: Each shaper structure is 8 bytes and there are 10 shapers\n");
+
+		if (i == 25)
+			len += sprintf(buf+len, "\nScheduler: Each scheduler structure is 48 bytes and there are 8 schedulers\n");
+		if (i == 121)
+			len += sprintf(buf+len, "\nQueue: Each queue structure is 2 bytes and there are 16 queues\n");
+
+		if (i == 129)
+			len += sprintf(buf+len, "\nqlenmasks array for  16 queues\n");
+		if (i == 145)
+			len += sprintf(buf+len, "\nqresultmap array for  16 queues\n");
+		if (i%8 == 0)
+			len += sprintf(buf+len, "%08x \n",  cpu_to_be32(val));
+		else
+			len += sprintf(buf+len, "%08x ",  cpu_to_be32(val));
+	}
+	
+	len += sprintf(buf+len, "\n");
+		
+	return len;
+}
+
+static ssize_t block_version(char *buf, void *addr)
+{
+	ssize_t len = 0;
+	u32 val;
+
+	val = readl(addr);
+	len += sprintf(buf + len, "revision: %x, version: %x, id: %x\n", (val >> 24) & 0xff, (val >> 16) & 0xff, val & 0xffff);
+
+	return len;
+}
+
+static ssize_t bmu(char *buf, int id, void *base)
+{
+	ssize_t len = 0;
+
+	len += sprintf(buf + len, "bmu: %d\n  ", id);
+
+	len += block_version(buf + len, base + BMU_VERSION);
+
+	len += sprintf(buf + len, "  buf size:  %x\n", (1 << readl(base + BMU_BUF_SIZE)));
+	len += sprintf(buf + len, "  buf count: %x\n", readl(base + BMU_BUF_CNT));
+	len += sprintf(buf + len, "  buf rem:   %x\n", readl(base + BMU_REM_BUF_CNT));
+	len += sprintf(buf + len, "  buf curr:  %x\n", readl(base + BMU_CURR_BUF_CNT));
+	len += sprintf(buf + len, "  free err:  %x\n", readl(base + BMU_FREE_ERR_ADDR));
+
+	return len;
+}
+
+static ssize_t gpi(char *buf, int id, void *base)
+{
+	ssize_t len = 0;
+	u32 val;
+
+	len += sprintf(buf + len, "gpi%d:\n  ", id);
+	len += block_version(buf + len, base + GPI_VERSION);
+
+	len += sprintf(buf + len, "  tx under stick: %x\n", readl(base + GPI_FIFO_STATUS));
+	val = readl(base + GPI_FIFO_DEBUG);
+	len += sprintf(buf + len, "  tx pkts:        %x\n", (val >> 23) & 0x3f);
+	len += sprintf(buf + len, "  rx pkts:        %x\n", (val >> 18) & 0x3f);
+	len += sprintf(buf + len, "  tx bytes:       %x\n", (val >> 9) & 0x1ff);
+	len += sprintf(buf + len, "  rx bytes:       %x\n", (val >> 0) & 0x1ff);
+	len += sprintf(buf + len, "  overrun:        %x\n", readl(base + GPI_OVERRUN_DROPCNT));
+
+	return len;
+}
+
+static ssize_t pfe_set_class(struct device *dev, struct device_attribute *attr, const char *buf, size_t count)
+{
+	class_do_clear = simple_strtoul(buf, NULL, 0);
+	return count;
+}
+
+static ssize_t pfe_show_class(struct device *dev, struct device_attribute *attr, char *buf)
+{
+	ssize_t len = 0;
+	int id;
+	u32 val;
+	struct pfe_cpumon *cpumon = &pfe->cpumon;
+
+	len += block_version(buf + len, CLASS_VERSION);
+
+	for (id = CLASS0_ID; id <= CLASS_MAX_ID; id++)
+	{
+		len += sprintf(buf + len, "%d: ", id - CLASS0_ID);
+
+		val = readl(CLASS_PE0_DEBUG + id * 4);
+		len += sprintf(buf + len, "pc=1%04x ", val & 0xffff);
+
+		len += display_pe_status(buf + len, id, PESTATUS_ADDR_CLASS, class_do_clear);
+	}
+	len += sprintf(buf + len, "aggregate load=%d%%\n\n", cpumon->class_usage_pct);
+
+	len += sprintf(buf + len, "pe status:   0x%x\n", readl(CLASS_PE_STATUS));
+	len += sprintf(buf + len, "max buf cnt: 0x%x   afull thres: 0x%x\n", readl(CLASS_MAX_BUF_CNT), readl(CLASS_AFULL_THRES));
+	len += sprintf(buf + len, "tsq max cnt: 0x%x   tsq fifo thres: 0x%x\n", readl(CLASS_TSQ_MAX_CNT), readl(CLASS_TSQ_FIFO_THRES));
+	len += sprintf(buf + len, "state:       0x%x\n", readl(CLASS_STATE));
+
+	len += class_phy_stats(buf + len, 0);
+	len += class_phy_stats(buf + len, 1);
+	len += class_phy_stats(buf + len, 2);
+	len += class_phy_stats(buf + len, 3);
+
+	return len;
+}
+
+static ssize_t pfe_set_tmu(struct device *dev, struct device_attribute *attr, const char *buf, size_t count)
+{
+	tmu_do_clear = simple_strtoul(buf, NULL, 0);
+	return count;
+}
+
+static ssize_t pfe_show_tmu(struct device *dev, struct device_attribute *attr, char *buf)
+{
+	ssize_t len = 0;
+	int id;
+	u32 val;
+
+	len += block_version(buf + len, TMU_VERSION);
+
+	for (id = TMU0_ID; id <= TMU_MAX_ID; id++)
+	{
+#if defined(CONFIG_PLATFORM_LS1012A)
+		if(id == TMU2_ID) continue;
+#endif
+		len += sprintf(buf + len, "%d: ", id - TMU0_ID);
+
+		len += display_pe_status(buf + len, id, PESTATUS_ADDR_TMU, tmu_do_clear);
+	}
+
+	len += sprintf(buf + len, "pe status:    %x\n", readl(TMU_PE_STATUS));
+	len += sprintf(buf + len, "inq fifo cnt: %x\n", readl(TMU_PHY_INQ_FIFO_CNT));
+	val = readl(TMU_INQ_STAT);
+	len += sprintf(buf + len, "inq wr ptr:     %x\n", val & 0x3ff);
+	len += sprintf(buf + len, "inq rd ptr:     %x\n", val >> 10);
+
+
+	return len;
+}
+
+
+static unsigned long drops_do_clear = 0;
+static u32 CLASS_DMEM_SH2(drop_counter)[CLASS_NUM_DROP_COUNTERS];
+#if !defined(CONFIG_UTIL_DISABLED)
+static u32 UTIL_DMEM_SH2(drop_counter)[UTIL_NUM_DROP_COUNTERS];
+#endif
+
+char *class_drop_description[CLASS_NUM_DROP_COUNTERS] = {
+	"ICC",
+	"Host Pkt Error",
+	"Rx Error",
+	"IPsec Outbound",
+	"IPsec Inbound",
+	"EXPT IPsec Error",
+	"Reassembly",
+	"Fragmenter",
+	"NAT-T",
+	"Socket",
+	"Multicast",
+	"NAT-PT",
+	"Tx Disabled",
+};
+
+#if !defined(CONFIG_UTIL_DISABLED)
+char *util_drop_description[UTIL_NUM_DROP_COUNTERS] = {
+	"IPsec Outbound",
+	"IPsec Inbound",
+	"IPsec Rate Limiter",
+	"Fragmenter",
+	"Socket",
+	"Tx Disabled",
+	"Rx Error",
+};
+#endif
+
+static ssize_t pfe_set_drops(struct device *dev, struct device_attribute *attr, const char *buf, size_t count)
+{
+	drops_do_clear = simple_strtoul(buf, NULL, 0);
+	return count;
+}
+
+static u32 tmu_drops[4][16];
+static ssize_t pfe_show_drops(struct device *dev, struct device_attribute *attr, char *buf)
+{
+	ssize_t len = 0;
+	int id, dropnum;
+	int tmu, queue;
+	u32 val;
+	u32 dmem_addr;
+	int num_class_drops = 0, num_tmu_drops = 0, num_util_drops = 0;
+	struct pfe_ctrl *ctrl = &pfe->ctrl;
+
+	memset(class_drop_counter, 0, sizeof(class_drop_counter));
+	for (id = CLASS0_ID; id <= CLASS_MAX_ID; id++)
+	{
+		if (drops_do_clear)
+			pe_sync_stop(ctrl, (1 << id));
+		for (dropnum = 0; dropnum < CLASS_NUM_DROP_COUNTERS; dropnum++)
+		{
+			dmem_addr = virt_to_class_dmem(&class_drop_counter[dropnum]);
+			val = be32_to_cpu(pe_dmem_read(id, dmem_addr, 4));
+			class_drop_counter[dropnum] += val;
+			num_class_drops += val;
+			if (drops_do_clear)
+				pe_dmem_write(id, 0, dmem_addr, 4);
+		}
+		if (drops_do_clear)
+			pe_start(ctrl, (1 << id));
+	}
+
+#if !defined(CONFIG_UTIL_DISABLED)
+	if (drops_do_clear)
+		pe_sync_stop(ctrl, (1 << UTIL_ID));
+	for (dropnum = 0; dropnum < UTIL_NUM_DROP_COUNTERS; dropnum++)
+	{
+		dmem_addr = virt_to_util_dmem(&util_drop_counter[dropnum]);
+		val = be32_to_cpu(pe_dmem_read(UTIL_ID, dmem_addr, 4));
+		util_drop_counter[dropnum] = val;
+		num_util_drops += val;
+		if (drops_do_clear)
+			pe_dmem_write(UTIL_ID, 0, dmem_addr, 4);
+	}
+	if (drops_do_clear)
+		pe_start(ctrl, (1 << UTIL_ID));
+#endif
+	for (tmu = 0; tmu < 4; tmu++)
+	{
+		for (queue = 0; queue < 16; queue++)
+		{
+			qm_read_drop_stat(tmu, queue, &tmu_drops[tmu][queue], drops_do_clear);
+			num_tmu_drops += tmu_drops[tmu][queue];
+		}
+	}
+
+	if (num_class_drops == 0 && num_util_drops == 0 && num_tmu_drops == 0)
+		len += sprintf(buf + len, "No PE drops\n\n");
+
+	if (num_class_drops > 0)
+	{
+		len += sprintf(buf + len, "Class PE drops --\n");
+		for (dropnum = 0; dropnum < CLASS_NUM_DROP_COUNTERS; dropnum++)
+		{
+			if (class_drop_counter[dropnum] > 0)
+				len += sprintf(buf + len, "  %s: %d\n", class_drop_description[dropnum], class_drop_counter[dropnum]);
+		}
+		len += sprintf(buf + len, "\n");
+	}
+
+#if !defined(CONFIG_UTIL_DISABLED)
+	if (num_util_drops > 0)
+	{
+		len += sprintf(buf + len, "Util PE drops --\n");
+		for (dropnum = 0; dropnum < UTIL_NUM_DROP_COUNTERS; dropnum++)
+		{
+			if (util_drop_counter[dropnum] > 0)
+				len += sprintf(buf + len, "  %s: %d\n", util_drop_description[dropnum], util_drop_counter[dropnum]);
+		}
+		len += sprintf(buf + len, "\n");
+	}
+#endif
+	if (num_tmu_drops > 0)
+	{
+		len += sprintf(buf + len, "TMU drops --\n");
+		for (tmu = 0; tmu < 4; tmu++)
+		{
+			for (queue = 0; queue < 16; queue++)
+			{
+				if (tmu_drops[tmu][queue] > 0)
+					len += sprintf(buf + len, "  TMU%d-Q%d: %d\n", tmu, queue, tmu_drops[tmu][queue]);
+			}
+		}
+		len += sprintf(buf + len, "\n");
+	}
+
+	return len;
+}
+
+static ssize_t pfe_show_tmu0_queues(struct device *dev, struct device_attribute *attr, char *buf)
+{
+	return tmu_queues(buf, 0);
+}
+
+static ssize_t pfe_show_tmu1_queues(struct device *dev, struct device_attribute *attr, char *buf)
+{
+	return tmu_queues(buf, 1);
+}
+
+static ssize_t pfe_show_tmu2_queues(struct device *dev, struct device_attribute *attr, char *buf)
+{
+	return tmu_queues(buf, 2);
+}
+
+static ssize_t pfe_show_tmu3_queues(struct device *dev, struct device_attribute *attr, char *buf)
+{
+	return tmu_queues(buf, 3);
+}
+
+static ssize_t pfe_show_tmu0_ctx(struct device *dev, struct device_attribute *attr, char *buf)
+{
+        return tmu_ctx(buf, 0);
+}
+static ssize_t pfe_show_tmu1_ctx(struct device *dev, struct device_attribute *attr, char *buf)
+{
+        return tmu_ctx(buf, 1);
+}
+static ssize_t pfe_show_tmu2_ctx(struct device *dev, struct device_attribute *attr, char *buf)
+{
+        return tmu_ctx(buf, 2);
+}
+
+static ssize_t pfe_show_tmu3_ctx(struct device *dev, struct device_attribute *attr, char *buf)
+{
+        return tmu_ctx(buf, 3);
+}
+
+
+#if !defined(CONFIG_UTIL_DISABLED)
+static ssize_t pfe_set_util(struct device *dev, struct device_attribute *attr, const char *buf, size_t count)
+{
+	util_do_clear = simple_strtoul(buf, NULL, 0);
+	return count;
+}
+
+static ssize_t pfe_show_util(struct device *dev, struct device_attribute *attr, char *buf)
+{
+	ssize_t len = 0;
+	struct pfe_ctrl *ctrl = &pfe->ctrl;
+
+
+	len += block_version(buf + len, UTIL_VERSION);
+
+	pe_sync_stop(ctrl, (1 << UTIL_ID));
+	len += display_pe_status(buf + len, UTIL_ID, PESTATUS_ADDR_UTIL, util_do_clear);
+	pe_start(ctrl, (1 << UTIL_ID));
+
+	len += sprintf(buf + len, "pe status:   %x\n", readl(UTIL_PE_STATUS));
+	len += sprintf(buf + len, "max buf cnt: %x\n", readl(UTIL_MAX_BUF_CNT));
+	len += sprintf(buf + len, "tsq max cnt: %x\n", readl(UTIL_TSQ_MAX_CNT));
+
+	return len;
+}
+#endif
+
+static ssize_t pfe_show_bmu(struct device *dev, struct device_attribute *attr, char *buf)
+{
+	ssize_t len = 0;
+
+	len += bmu(buf + len, 1, BMU1_BASE_ADDR);
+	len += bmu(buf + len, 2, BMU2_BASE_ADDR);
+
+	return len;
+}
+
+static ssize_t pfe_show_hif(struct device *dev, struct device_attribute *attr, char *buf)
+{
+	ssize_t len = 0;
+
+	len += sprintf(buf + len, "hif:\n  ");
+	len += block_version(buf + len, HIF_VERSION);
+
+	len += sprintf(buf + len, "  tx curr bd:    %x\n", readl(HIF_TX_CURR_BD_ADDR));
+	len += sprintf(buf + len, "  tx status:     %x\n", readl(HIF_TX_STATUS));
+	len += sprintf(buf + len, "  tx dma status: %x\n", readl(HIF_TX_DMA_STATUS));
+
+	len += sprintf(buf + len, "  rx curr bd:    %x\n", readl(HIF_RX_CURR_BD_ADDR));
+	len += sprintf(buf + len, "  rx status:     %x\n", readl(HIF_RX_STATUS));
+	len += sprintf(buf + len, "  rx dma status: %x\n", readl(HIF_RX_DMA_STATUS));
+
+	len += sprintf(buf + len, "hif nocopy:\n  ");
+	len += block_version(buf + len, HIF_NOCPY_VERSION);
+
+	len += sprintf(buf + len, "  tx curr bd:    %x\n", readl(HIF_NOCPY_TX_CURR_BD_ADDR));
+	len += sprintf(buf + len, "  tx status:     %x\n", readl(HIF_NOCPY_TX_STATUS));
+	len += sprintf(buf + len, "  tx dma status: %x\n", readl(HIF_NOCPY_TX_DMA_STATUS));
+
+	len += sprintf(buf + len, "  rx curr bd:    %x\n", readl(HIF_NOCPY_RX_CURR_BD_ADDR));
+	len += sprintf(buf + len, "  rx status:     %x\n", readl(HIF_NOCPY_RX_STATUS));
+	len += sprintf(buf + len, "  rx dma status: %x\n", readl(HIF_NOCPY_RX_DMA_STATUS));
+
+	return len;
+}
+
+
+static ssize_t pfe_show_gpi(struct device *dev, struct device_attribute *attr, char *buf)
+{
+	ssize_t len = 0;
+
+	len += gpi(buf + len, 0, EGPI1_BASE_ADDR);
+	len += gpi(buf + len, 1, EGPI2_BASE_ADDR);
+#if !defined(CONFIG_PLATFORM_LS1012A)
+	len += gpi(buf + len, 2, EGPI3_BASE_ADDR);
+#endif
+	len += gpi(buf + len, 3, HGPI_BASE_ADDR);
+
+	return len;
+}
+
+static ssize_t pfe_show_pfemem(struct device *dev, struct device_attribute *attr, char *buf)
+{
+	ssize_t len = 0;
+	struct pfe_memmon *memmon = &pfe->memmon;
+
+	len += sprintf(buf + len, "Kernel Memory: %d Bytes (%d KB)\n", memmon->kernel_memory_allocated, (memmon->kernel_memory_allocated + 1023) / 1024);
+
+	return len;
+}
+
+#ifdef HIF_NAPI_STATS
+static ssize_t pfe_show_hif_napi_stats(struct device *dev, struct device_attribute *attr, char *buf)
+{
+	struct platform_device *pdev = to_platform_device(dev);
+	struct pfe *pfe = platform_get_drvdata(pdev);
+	ssize_t len = 0;
+
+	len += sprintf(buf + len, "sched:  %u\n", pfe->hif.napi_counters[NAPI_SCHED_COUNT]);
+	len += sprintf(buf + len, "poll:   %u\n", pfe->hif.napi_counters[NAPI_POLL_COUNT]);
+	len += sprintf(buf + len, "packet: %u\n", pfe->hif.napi_counters[NAPI_PACKET_COUNT]);
+	len += sprintf(buf + len, "budget: %u\n", pfe->hif.napi_counters[NAPI_FULL_BUDGET_COUNT]);
+	len += sprintf(buf + len, "desc:   %u\n", pfe->hif.napi_counters[NAPI_DESC_COUNT]);
+	len += sprintf(buf + len, "full:   %u\n", pfe->hif.napi_counters[NAPI_CLIENT_FULL_COUNT]);
+
+	return len;
+}
+
+static ssize_t pfe_set_hif_napi_stats(struct device *dev, struct device_attribute *attr, const char *buf, size_t count)
+{
+	struct platform_device *pdev = to_platform_device(dev);
+	struct pfe *pfe = platform_get_drvdata(pdev);
+
+	memset(pfe->hif.napi_counters, 0, sizeof(pfe->hif.napi_counters));
+
+	return count;
+}
+
+static DEVICE_ATTR(hif_napi_stats, 0644, pfe_show_hif_napi_stats, pfe_set_hif_napi_stats);
+#endif
+
+
+static DEVICE_ATTR(class, 0644, pfe_show_class, pfe_set_class);
+static DEVICE_ATTR(tmu, 0644, pfe_show_tmu, pfe_set_tmu);
+#if !defined(CONFIG_UTIL_DISABLED)
+static DEVICE_ATTR(util, 0644, pfe_show_util, pfe_set_util);
+#endif
+static DEVICE_ATTR(bmu, 0444, pfe_show_bmu, NULL);
+static DEVICE_ATTR(hif, 0444, pfe_show_hif, NULL);
+static DEVICE_ATTR(gpi, 0444, pfe_show_gpi, NULL);
+static DEVICE_ATTR(drops, 0644, pfe_show_drops, pfe_set_drops);
+static DEVICE_ATTR(tmu0_queues, 0444, pfe_show_tmu0_queues, NULL);
+static DEVICE_ATTR(tmu1_queues, 0444, pfe_show_tmu1_queues, NULL);
+static DEVICE_ATTR(tmu2_queues, 0444, pfe_show_tmu2_queues, NULL);
+static DEVICE_ATTR(tmu3_queues, 0444, pfe_show_tmu3_queues, NULL);
+static DEVICE_ATTR(tmu0_ctx, 0444, pfe_show_tmu0_ctx, NULL);
+static DEVICE_ATTR(tmu1_ctx, 0444, pfe_show_tmu1_ctx, NULL);
+static DEVICE_ATTR(tmu2_ctx, 0444, pfe_show_tmu2_ctx, NULL);
+static DEVICE_ATTR(tmu3_ctx, 0444, pfe_show_tmu3_ctx, NULL);
+static DEVICE_ATTR(pfemem, 0444, pfe_show_pfemem, NULL);
+
+
+int pfe_sysfs_init(struct pfe *pfe)
+{
+	if (device_create_file(pfe->dev, &dev_attr_class))
+		goto err_class;
+
+	if (device_create_file(pfe->dev, &dev_attr_tmu))
+		goto err_tmu;
+
+#if !defined(CONFIG_UTIL_DISABLED)
+	if (device_create_file(pfe->dev, &dev_attr_util))
+		goto err_util;
+#endif
+
+	if (device_create_file(pfe->dev, &dev_attr_bmu))
+		goto err_bmu;
+
+	if (device_create_file(pfe->dev, &dev_attr_hif))
+		goto err_hif;
+
+	if (device_create_file(pfe->dev, &dev_attr_gpi))
+		goto err_gpi;
+
+	if (device_create_file(pfe->dev, &dev_attr_drops))
+		goto err_drops;
+
+	if (device_create_file(pfe->dev, &dev_attr_tmu0_queues))
+		goto err_tmu0_queues;
+
+	if (device_create_file(pfe->dev, &dev_attr_tmu1_queues))
+		goto err_tmu1_queues;
+
+	if (device_create_file(pfe->dev, &dev_attr_tmu2_queues))
+		goto err_tmu2_queues;
+
+	if (device_create_file(pfe->dev, &dev_attr_tmu3_queues))
+		goto err_tmu3_queues;
+
+	if (device_create_file(pfe->dev, &dev_attr_tmu0_ctx))
+		goto err_tmu0_ctx;
+
+	if (device_create_file(pfe->dev, &dev_attr_tmu1_ctx))
+		goto err_tmu1_ctx;
+
+	if (device_create_file(pfe->dev, &dev_attr_tmu2_ctx))
+		goto err_tmu2_ctx;
+
+	if (device_create_file(pfe->dev, &dev_attr_tmu3_ctx))
+		goto err_tmu3_ctx;
+
+	if (device_create_file(pfe->dev, &dev_attr_pfemem))
+		goto err_pfemem;
+
+#ifdef HIF_NAPI_STATS
+	if (device_create_file(pfe->dev, &dev_attr_hif_napi_stats))
+		goto err_hif_napi_stats;
+#endif
+
+	return 0;
+
+#ifdef HIF_NAPI_STATS
+err_hif_napi_stats:
+	device_remove_file(pfe->dev, &dev_attr_pfemem);
+#endif
+
+err_pfemem:
+	device_remove_file(pfe->dev, &dev_attr_tmu3_ctx);
+
+err_tmu3_ctx:
+	device_remove_file(pfe->dev, &dev_attr_tmu2_ctx);
+
+err_tmu2_ctx:
+	device_remove_file(pfe->dev, &dev_attr_tmu1_ctx);
+
+err_tmu1_ctx:
+	device_remove_file(pfe->dev, &dev_attr_tmu0_ctx);
+
+err_tmu0_ctx:
+	device_remove_file(pfe->dev, &dev_attr_tmu3_queues);
+
+err_tmu3_queues:
+	device_remove_file(pfe->dev, &dev_attr_tmu2_queues);
+
+err_tmu2_queues:
+	device_remove_file(pfe->dev, &dev_attr_tmu1_queues);
+
+err_tmu1_queues:
+	device_remove_file(pfe->dev, &dev_attr_tmu0_queues);
+
+err_tmu0_queues:
+	device_remove_file(pfe->dev, &dev_attr_drops);
+
+err_drops:
+	device_remove_file(pfe->dev, &dev_attr_gpi);
+
+err_gpi:
+	device_remove_file(pfe->dev, &dev_attr_hif);
+
+err_hif:
+	device_remove_file(pfe->dev, &dev_attr_bmu);
+
+err_bmu:
+#if !defined(CONFIG_UTIL_DISABLED)
+	device_remove_file(pfe->dev, &dev_attr_util);
+
+err_util:
+#endif
+	device_remove_file(pfe->dev, &dev_attr_tmu);
+
+err_tmu:
+	device_remove_file(pfe->dev, &dev_attr_class);
+
+err_class:
+	return -1;
+}
+
+
+void pfe_sysfs_exit(struct pfe *pfe)
+{
+#ifdef HIF_NAPI_STATS
+	device_remove_file(pfe->dev, &dev_attr_hif_napi_stats);
+#endif
+
+	device_remove_file(pfe->dev, &dev_attr_pfemem);
+	device_remove_file(pfe->dev, &dev_attr_tmu3_ctx);
+	device_remove_file(pfe->dev, &dev_attr_tmu2_ctx);
+	device_remove_file(pfe->dev, &dev_attr_tmu1_ctx);
+	device_remove_file(pfe->dev, &dev_attr_tmu0_ctx);
+	device_remove_file(pfe->dev, &dev_attr_tmu3_queues);
+	device_remove_file(pfe->dev, &dev_attr_tmu2_queues);
+	device_remove_file(pfe->dev, &dev_attr_tmu1_queues);
+	device_remove_file(pfe->dev, &dev_attr_tmu0_queues);
+	device_remove_file(pfe->dev, &dev_attr_drops);
+	device_remove_file(pfe->dev, &dev_attr_gpi);
+	device_remove_file(pfe->dev, &dev_attr_hif);
+	device_remove_file(pfe->dev, &dev_attr_bmu);
+#if !defined(CONFIG_UTIL_DISABLED)
+	device_remove_file(pfe->dev, &dev_attr_util);
+#endif
+	device_remove_file(pfe->dev, &dev_attr_tmu);
+	device_remove_file(pfe->dev, &dev_attr_class);
+}
+
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/pfe_sysfs.h
@@ -0,0 +1,34 @@
+/*
+ *
+ *  Copyright (C) 2007 Freescale Semiconductor, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+
+#ifndef _PFE_SYSFS_H_
+#define _PFE_SYSFS_H_
+
+#include <linux/proc_fs.h>
+
+#define	PESTATUS_ADDR_CLASS	0x800
+#define	PESTATUS_ADDR_TMU	0x80
+#define	PESTATUS_ADDR_UTIL	0x0
+
+#define TMU_CONTEXT_ADDR 	0x3c8
+#define IPSEC_CNTRS_ADDR 	0x840
+
+int pfe_sysfs_init(struct pfe *pfe);
+void pfe_sysfs_exit(struct pfe *pfe);
+#endif /* _PFE_SYSFS_H_ */
--- /dev/null
+++ b/drivers/staging/fsl_ppfe/platform.h
@@ -0,0 +1,25 @@
+/*
+ *
+ *  Copyright (C) 2007 Freescale Semiconductor, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+
+#ifndef _PLATFORM_H_
+#define _PLATFORM_H_
+
+#define virt_to_phys(virt)	((unsigned long)virt)
+
+#endif /* _PLATFORM_H_ */
--- a/include/linux/skbuff.h
+++ b/include/linux/skbuff.h
@@ -858,6 +858,17 @@ static inline struct sk_buff *alloc_skb_
 	return __alloc_skb(size, priority, SKB_ALLOC_FCLONE, NUMA_NO_NODE);
 }
 
+extern struct sk_buff *__alloc_skb_header(unsigned int size, void *data,
+		gfp_t gfp_mask,
+		int fclone,
+		int node);
+static inline struct sk_buff *alloc_skb_header(unsigned int size,
+		u8 *data,
+		gfp_t priority)
+{
+	return __alloc_skb_header(size, data, priority, 0, -1);
+}
+
 struct sk_buff *__alloc_skb_head(gfp_t priority, int node);
 static inline struct sk_buff *alloc_skb_head(gfp_t priority)
 {
--- a/net/core/skbuff.c
+++ b/net/core/skbuff.c
@@ -283,6 +283,90 @@ nodata:
 EXPORT_SYMBOL(__alloc_skb);
 
 /**
+ *	__alloc_skb_header	-	allocate a network buffer
+ *	@size: size to allocate
+ *	@gfp_mask: allocation mask
+ *	@fclone: allocate from fclone cache instead of head cache
+ *		and allocate a cloned (child) skb
+ *
+ *	Allocate a new &sk_buff. The returned buffer has no headroom and a
+ *	tail room of size bytes. The object has a reference count of one.
+ *	The return is the buffer. On a failure the return is %NULL.
+ *
+ *	Buffers may only be allocated from interrupts using a @gfp_mask of
+ *	%GFP_ATOMIC.
+ */
+struct sk_buff *__alloc_skb_header(unsigned int size, void *data,
+				   gfp_t gfp_mask, int fclone, int node)
+{
+	struct kmem_cache *cache;
+	struct skb_shared_info *shinfo;
+	struct sk_buff *skb;
+
+	cache = fclone ? skbuff_fclone_cache : skbuff_head_cache;
+
+	if (size <= SKB_DATA_ALIGN(sizeof(struct skb_shared_info))) {
+		skb = NULL;
+		goto out;
+	}
+
+	/* Get the HEAD */
+	skb = kmem_cache_alloc_node(cache, gfp_mask & ~__GFP_DMA, node);
+	if (!skb)
+		goto out;
+	prefetchw(skb);
+
+	/* kmalloc might give us more room than requested.
+	 * Put skb_shared_info exactly at the end of allocated zone,
+	 * to allow max possible filling before reallocation.
+	 */
+	size = SKB_WITH_OVERHEAD(ksize(data));
+	prefetchw(data + size);
+
+	/* Only clear those fields we need to clear, not those that we will
+	 * actually initialise below. Hence, don't put any more fields after
+	 * the tail pointer in struct sk_buff!
+	 */
+	memset(skb, 0, offsetof(struct sk_buff, tail));
+	/* Account for allocated memory : skb + skb->head */
+	skb->truesize = SKB_TRUESIZE(size);
+	atomic_set(&skb->users, 1);
+	skb->head = data;
+	skb->data = data;
+	skb_reset_tail_pointer(skb);
+	skb->end = skb->tail + size;
+#ifdef NET_SKBUFF_DATA_USES_OFFSET
+	skb->mac_header = ~0U;
+#endif
+
+#if defined(CONFIG_COMCERTO_CUSTOM_SKB_LAYOUT)
+	skb->mspd_data = NULL;
+	skb->mspd_len = 0;
+#endif
+
+	/* make sure we initialize shinfo sequentially */
+	shinfo = skb_shinfo(skb);
+	memset(shinfo, 0, offsetof(struct skb_shared_info, dataref));
+	atomic_set(&shinfo->dataref, 1);
+	kmemcheck_annotate_variable(shinfo->destructor_arg);
+
+	if (fclone) {
+		struct sk_buff *child = skb + 1;
+		atomic_t *fclone_ref = (atomic_t *)(child + 1);
+
+		kmemcheck_annotate_bitfield(child, flags1);
+		kmemcheck_annotate_bitfield(child, flags2);
+		skb->fclone = SKB_FCLONE_ORIG;
+		atomic_set(fclone_ref, 1);
+
+		child->fclone = SKB_FCLONE_UNAVAILABLE;
+	}
+out:
+	return skb;
+}
+EXPORT_SYMBOL(__alloc_skb_header);
+
+/**
  * __build_skb - build a network buffer
  * @data: data buffer provided by caller
  * @frag_size: size of data, or 0 if head was kmalloced
